% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Data Science Workshops},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1.5in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}

\usepackage{xcolor}

\usepackage{graphicx}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{verbatim} 

% Title format
\usepackage{titling}
\pretitle{\Huge\sffamily}
\posttitle{\par\vskip 0.5em}
\predate{\LARGE\sffamily}
\postdate{\par}

\urlstyle{tt}

\graphicspath{{R/Rinstall/}{R/Rintro/}{R/Rmodels/}{R/Rgraphics/}{R/RDataWrangling/}{Python/PythonInstall/}{Python/PythonIntro/}{Python/PythonWebScrape/}{Stata/StataInstall/}{Stata/StataIntro/}{Stata/StataDatMan/}{Stata/StataMod/}{Stata/StataGraph/}}

\usepackage{tcolorbox}

\newtcolorbox{alert}{
  colback=cyan!5!white,
  colframe=cyan!75!black, 
  title={\mbox{}},
  boxsep=5pt,
  arc=4pt}


\usepackage{hyperref}

\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Data Science Workshops}
\author{}
\date{\vspace{-2.5em}August 2020}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
Materials for the software workshops held at the \href{http://dss.iq.harvard.edu/}{Institute for Quantitative Social Science} and \href{https://training.rcs.hbs.org}{Harvard Business School} at Harvard University.

\hypertarget{table-of-contents}{%
\chapter*{Table of Contents}\label{table-of-contents}}
\addcontentsline{toc}{chapter}{Table of Contents}

\begin{itemize}
\tightlist
\item
  \href{./DataScienceTools.html}{Data Science Tools}
\item
  \href{./Rinstall.html}{R Installation}
\item
  \href{./Rintro.html}{R Introduction}
\item
  \href{./Rmodels.html}{R Regression Models}
\item
  \href{./Rgraphics.html}{R Graphics}
\item
  \href{./RDataWrangling.html}{R Data Wrangling}
\item
  \href{./PythonInstall.html}{Python Installation}
\item
  \href{./PythonIntro.html}{Python Introduction}
\item
  \href{./PythonWebScrape.html}{Python Web-Scraping}
\item
  \href{./StataInstall.html}{Stata Installation}
\item
  \href{./StataIntro.html}{Stata Introduction}
\item
  \href{./StataDatMan.html}{Stata Data Management}
\item
  \href{./StataMod.html}{Stata Regression Models}
\item
  \href{./StataGraph.html}{Stata Graphics}
\end{itemize}

\hypertarget{contributors}{%
\section*{Contributors}\label{contributors}}
\addcontentsline{toc}{section}{Contributors}

The contents of these workshops are the result of a collaborative effort from members of the \href{http://dss.iq.harvard.edu}{Data Science Services} team at IQSS and the \href{https://training.rcs.hbs.org}{Research Computing Services} team at HBS. The main contributors are: Ista Zahn, Steve Worthington, Bob Freeman, Jinjie Liu, Yihan Wang, and Victoria Liublinska.

These workshops are a work-in-progress, please provide feedback! Email: \href{mailto:help@iq.harvard.edu}{\nolinkurl{help@iq.harvard.edu}}

\hypertarget{part-general}{%
\part{General}\label{part-general}}

\hypertarget{data-science-tools}{%
\chapter{Data Science Tools}\label{data-science-tools}}

\textbf{Topics}

\begin{itemize}
\tightlist
\item
  Data science tool selection
\item
  Data analysis pipelines
\item
  Programming languages comparison
\item
  Text editor and IDE comparison
\item
  Tools for creating reports
\end{itemize}

\hypertarget{tools-for-working-with-data}{%
\section{Tools for working with data}\label{tools-for-working-with-data}}

Working with data effectively requires learning at least one programming or scripting language. You can get by without this, but it would be like trying to cook with only a butter knife; not recommended! Compared to using a menu-driven interface (e.g., SPSS or SAS) or a spreadsheet (e.g., Excel), using a programming language allows you to:

\begin{itemize}
\tightlist
\item
  reproduce results,
\item
  correct errors and update output,
\item
  reuse code,
\item
  collaborate with others,
\item
  automate repetitive tasks, and
\item
  generate manuscripts, reports, and other documents from your code.
\end{itemize}

So, you need to learn a programming language for working with data, but which one should you learn? Since you'll be writing code you'll want to set up a comfortable environment for writing and editing that code. Which text editors are good for this? You'll probably also want to learn at least one markup language (e.g., LaTeX, Markdown) so that you can create reproducible manuscripts. What tools are good for this? These questions will guide our discussion, the goal of which is to help you decide which tools you should invest time in learning.

\hypertarget{the-puzzle-pieces}{%
\section{The puzzle pieces}\label{the-puzzle-pieces}}

As we've noted, working effectively with data requires using a number of tools.

\hypertarget{data-analysis-building-blocks}{%
\subsection{Data analysis building blocks}\label{data-analysis-building-blocks}}

The basic pieces are:

\begin{itemize}
\tightlist
\item
  a data storage and retrieval system,
\item
  an editor for writing code,
\item
  an interpreter or compiler for executing that code,
\item
  a system for presenting results, and
\item
  some ``glue'' to make all the pieces work together.
\end{itemize}

\hypertarget{examples}{%
\section{Examples}\label{examples}}

Before looking in detail at each of these building blocks we'll look at a few examples to get an intuitive feel for the basic elements.

\hypertarget{old-school-example}{%
\subsection{Old-school example}\label{old-school-example}}

In this example we're going to process data in a text file in a way that would be familiar to a statistician working forty years ago. Surprisingly, it's not much different from the way we would do it today. Programs come and go, but the basic ideas remain pretty much the same!

Specifically, we'll process the data in \texttt{1980\_census.txt} by writing \textbf{fortran} code in the \textbf{vi} text editor and running it through the \textbf{fortran} compiler. Then we'll take the results and put them in to a \textbf{TeX} file, again using the \textbf{vi} editor to create the report. For ``glue'' we will use a terminal emulator running the bash shell. All of these tools were available in 1980, though some features have been added since that time.

OLD SCHOOL DEMO:

\begin{longtable}[]{@{}llllll@{}}
\toprule
example & data storage & editor & program & report tool & glue\tabularnewline
\midrule
\endhead
old school & ASCII text file & vi & fortran & TeX & Bourne (compatable) shell\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{something-old-something-new}{%
\subsection{Something old \& something new}\label{something-old-something-new}}

Next we're going to do the same basic process, this time using a modern text editor (\textbf{Atom}), a different programming language (\textbf{Python}), and a modern report generation system (\textbf{LaTeX} processed via \textbf{xelatex}). For the glue we're still going to use a shell.

OLD AND NEW DEMO:

\begin{longtable}[]{@{}llllll@{}}
\toprule
example & data storage & editor & program & report tool & glue\tabularnewline
\midrule
\endhead
old school & ASCII text file & vi & fortran & TeX & Bourne (compatable) shell\tabularnewline
old and new & ASCII text file & Atom & python & LaTeX & Bash shell\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{a-modern-version}{%
\subsection{A modern version}\label{a-modern-version}}

Finally, we'll produce the same report using modern tools. Remember, the process is basically the same: we're just using different tools.

MODERN DEMO:

\begin{longtable}[]{@{}llllll@{}}
\toprule
example & data storage & editor & program & report tool & glue\tabularnewline
\midrule
\endhead
old school & ASCII text file & vi & fortran & TeX & Bourne (compatable) shell\tabularnewline
old and new & ASCII text file & Atom & python & LaTeX & Bash shell\tabularnewline
modern & SQLite database & Rstudio & R & R Markdown & Rstudio\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{data-storage-retrieval}{%
\section{Data storage \& retrieval}\label{data-storage-retrieval}}

Data storage and retrieval is a fairly dry topic, so we won't spend too much time on it. There are roughly four types of technology for storing and retrieving data.

\hypertarget{text-files}{%
\subsection{Text files}\label{text-files}}

Storing data in text files (e.g., comma separated values, other delimited text formats) is simple and makes the data easy to access from just about any program. It is also good for archiving data since no specialized software is needed to read it. The main downsides are that retrieval is slow and often all-or-nothing, and the fact that storing metadata in plain text files is cumbersome.

\hypertarget{binary-files}{%
\subsection{Binary files}\label{binary-files}}

Many statistics packages and programming languages have a ``native'' binary data storage format. For example, Stata stores data in \texttt{.dta} files, and R stores data in \texttt{.rds} or \texttt{.Rdata} files. These storage formats usually more efficient than text files, and usually provide faster read/write access. They usually include a mechanism for storing metadata. The down side is that specialized software is required to read them (will Stata exist in 50 years? Are you sure?) and the ability to read them using other programs may be limited.

\hypertarget{databases}{%
\subsection{Databases}\label{databases}}

Storing data in a database requires more up-front planning and set up, but has several advantages. Databases provide fast selective retrieval and facilitate efficient storage and flexible retrieval.

\hypertarget{distributed-file-storage}{%
\subsection{Distributed file storage}\label{distributed-file-storage}}

Data that is too large to fit on a single hard drive may be stored and analyzed on a distributed file system or database such as the \emph{Hadoop Distributed File System} or \emph{Cassandra}. When working with data on this scale considerable infrastructure and specialized tools will be required.

\hypertarget{programming-languages-statistics-packages}{%
\section{Programming languages \& statistics packages}\label{programming-languages-statistics-packages}}

There are tens of programs for statistics and data science available. Here we will focus only on the more popular programs that offer a wide range of features. Note that for specific applications a specialized program may be better, e.g., many people use Mplus for structural equation models and another program for everything else.

\hypertarget{programming-language-features}{%
\subsection{Programming language features}\label{programming-language-features}}

Things we want a statistics program to do include:

\begin{itemize}
\tightlist
\item
  read/write data from/to a variety of data storage systems,
\item
  manipulate data,
\item
  perform statistical methods,
\item
  visualize data and results,
\item
  export results in a variety of formats,
\item
  be easy to use,
\item
  be well documented,
\item
  have a large user community.
\end{itemize}

Note that this list is deceptively simple; each item may include a diversity of complicated features. For example,``read/write data from/to a variety of data storage systems'' may include reading from databases, image files, .pdf files, .html and .xml files from a website, and any number of proprietary data storage formats.

\hypertarget{program-comparison}{%
\subsection{Program comparison}\label{program-comparison}}

\begin{longtable}[]{@{}lllllll@{}}
\toprule
\begin{minipage}[b]{0.08\columnwidth}\raggedright
Program\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright
Statistics\strut
\end{minipage} & \begin{minipage}[b]{0.13\columnwidth}\raggedright
Visualization\strut
\end{minipage} & \begin{minipage}[b]{0.16\columnwidth}\raggedright
Machine learning\strut
\end{minipage} & \begin{minipage}[b]{0.11\columnwidth}\raggedright
Ease of use\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
Power/flexibility\strut
\end{minipage} & \begin{minipage}[b]{0.05\columnwidth}\raggedright
Fun\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.08\columnwidth}\raggedright
Stata\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
Good\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
Servicable\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
Limited\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\raggedright
Very easy\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Low\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedright
Some\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.08\columnwidth}\raggedright
SPSS\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
OK\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
Servicable\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
Limited\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\raggedright
Easy\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Low\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedright
None\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.08\columnwidth}\raggedright
SAS\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
Good\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
Not great\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
Good\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\raggedright
Moderate\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Moderate\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedright
None\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.08\columnwidth}\raggedright
Matlab\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
Good\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
Good\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
Good\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\raggedright
Moderate\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Good\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedright
Some\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.08\columnwidth}\raggedright
R\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
Excellent\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
Excellent\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
Good\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\raggedright
Moderate\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Excellent\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedright
Yes\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.08\columnwidth}\raggedright
Python\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
Good\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
Good\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
Excellent\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\raggedright
Moderate\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Excellent\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedright
Yes\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.08\columnwidth}\raggedright
Julia\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
OK\strut
\end{minipage} & \begin{minipage}[t]{0.13\columnwidth}\raggedright
Excellent\strut
\end{minipage} & \begin{minipage}[t]{0.16\columnwidth}\raggedright
Good\strut
\end{minipage} & \begin{minipage}[t]{0.11\columnwidth}\raggedright
Hard\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
Excellent\strut
\end{minipage} & \begin{minipage}[t]{0.05\columnwidth}\raggedright
Yes\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{examples-read-data-from-a-file-summarize}{%
\subsection{Examples: Read data from a file \& summarize}\label{examples-read-data-from-a-file-summarize}}

In this example we will compare the syntax for reading and summarizing data stored in a file.

\begin{itemize}
\tightlist
\item
  Stata
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{import delimited }\KeywordTok{using} \StringTok{"https://github.com/IQSS/dss{-}workshops/raw/master/R/Rgraphics/dataSets/EconomistData.csv"}
\KeywordTok{sum}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
set more off
 "EconomistData.csv"
Picked up _JAVA_OPTIONS: -Dawt.useSystemAAFontSettings=gasp -Dswing.aatext=true -Dsun.java2d.opengl=true
(6 vars, 173 obs)
sum

    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
          v1 |        173          87    50.08493          1        173
     country |          0
     hdirank |        173    95.28324    55.00767          1        187
         hdi |        173    .6580867    .1755888       .286       .943
         cpi |        173    4.052023    2.116782        1.5        9.5
-------------+---------------------------------------------------------
      region |          0
\end{verbatim}

\begin{itemize}
\tightlist
\item
  R
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cpi \textless{}{-}}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\StringTok{"https://github.com/IQSS/dss{-}workshops/raw/master/R/Rgraphics/dataSets/EconomistData.csv"}\NormalTok{)}
\KeywordTok{summary}\NormalTok{(cpi)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      X              Country       HDI.Rank           HDI        
Min.   :  1   Afghanistan:  1   Min.   :  1.00   Min.   :0.2860  
1st Qu.: 44   Albania    :  1   1st Qu.: 47.00   1st Qu.:0.5090  
Median : 87   Algeria    :  1   Median : 96.00   Median :0.6980  
Mean   : 87   Angola     :  1   Mean   : 95.28   Mean   :0.6581  
3rd Qu.:130   Argentina  :  1   3rd Qu.:143.00   3rd Qu.:0.7930  
Max.   :173   Armenia    :  1   Max.   :187.00   Max.   :0.9430  
              (Other)    :167                                    
     CPI                      Region  
Min.   :1.500   Americas         :31  
1st Qu.:2.500   Asia Pacific     :30  
Median :3.200   East EU Cemt Asia:18  
Mean   :4.052   EU W. Europe     :30  
3rd Qu.:5.100   MENA             :18  
Max.   :9.500   SSA              :46
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Matlab
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{tmpfile} \OperatorTok{=} \VariableTok{websave}\NormalTok{(}\VariableTok{tempname}\NormalTok{()}\OperatorTok{,} \SpecialStringTok{\textquotesingle{}https://github.com/IQSS/dss{-}workshops/raw/master/R/Rgraphics/dataSets/EconomistData.csv\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\VariableTok{cpi} \OperatorTok{=} \VariableTok{readtable}\NormalTok{(}\VariableTok{tmpfile}\NormalTok{)}\OperatorTok{;}
\VariableTok{summary}\NormalTok{(}\VariableTok{cpi}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
tmpfile = websave(tempname(), 'https://github.com/IQSS/dss-workshops/raw/master/R/Rgraphics/dataSets/EconomistData.csv');
cpi = readtable(tmpfile);
summary(cpi)

Variables:

    Var1: 173×1 cell array of character vectors

    Country: 173×1 cell array of character vectors

    HDI_Rank: 173×1 double

        Description:  Original column heading: 'HDI.Rank'
        Values:

            Min         1       
            Median     96       
            Max       187       

    HDI: 173×1 double

        Values:

            Min       0.286
            Median    0.698
            Max       0.943

    CPI: 173×1 double

        Values:

            Min       1.5  
            Median    3.2  
            Max       9.5  

    Region: 173×1 cell array of character vectors
'org_babel_eoe'

ans =

    'org_babel_eoe'
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Python
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\NormalTok{cpi }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{\textquotesingle{}https://github.com/IQSS/dss{-}workshops/raw/master/R/Rgraphics/dataSets/EconomistData.csv\textquotesingle{}}\NormalTok{)}
\NormalTok{cpi.describe(include }\OperatorTok{=} \StringTok{\textquotesingle{}all\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Python 3.6.2 (default, Jul 20 2017, 03:52:27) 
[GCC 7.1.1 20170630] on linux
Type "help", "copyright", "credits" or "license" for more information.
        Unnamed: 0 Country    HDI.Rank         HDI         CPI Region
count   173.000000     173  173.000000  173.000000  173.000000    173
unique         NaN     173         NaN         NaN         NaN      6
top            NaN    Oman         NaN         NaN         NaN    SSA
freq           NaN       1         NaN         NaN         NaN     46
mean     87.000000     NaN   95.283237    0.658087    4.052023    NaN
std      50.084928     NaN   55.007670    0.175589    2.116782    NaN
min       1.000000     NaN    1.000000    0.286000    1.500000    NaN
25%      44.000000     NaN   47.000000    0.509000    2.500000    NaN
50%      87.000000     NaN   96.000000    0.698000    3.200000    NaN
75%     130.000000     NaN  143.000000    0.793000    5.100000    NaN
max     173.000000     NaN  187.000000    0.943000    9.500000    NaN
\end{verbatim}

\hypertarget{examples-fit-a-linear-regression}{%
\subsection{Examples: Fit a linear regression}\label{examples-fit-a-linear-regression}}

Fitting statistical models is pretty straight-forward in all popular programs.

\begin{itemize}
\tightlist
\item
  Stata
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{regress}\NormalTok{ hdi cpi}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
regress hdi cpi

      Source |       SS           df       MS      Number of obs   =       173
-------------+----------------------------------   F(1, 171)       =    168.85
       Model |  2.63475703         1  2.63475703   Prob > F        =    0.0000
    Residual |   2.6682467       171  .015603782   R-squared       =    0.4968
-------------+----------------------------------   Adj R-squared   =    0.4939
       Total |  5.30300372       172  .030831417   Root MSE        =    .12492

------------------------------------------------------------------------------
         hdi |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         cpi |   .0584696   .0044996    12.99   0.000     .0495876    .0673515
       _cons |   .4211666   .0205577    20.49   0.000     .3805871    .4617462
------------------------------------------------------------------------------
\end{verbatim}

\begin{itemize}
\tightlist
\item
  R
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(}\KeywordTok{lm}\NormalTok{(HDI }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{CPI, }\DataTypeTok{data =}\NormalTok{ cpi))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Call:
lm(formula = HDI ~ CPI, data = cpi)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.28452 -0.08380  0.01372  0.09157  0.24104 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  0.42117    0.02056   20.49   <2e-16 ***
CPI          0.05847    0.00450   12.99   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1249 on 171 degrees of freedom
Multiple R-squared:  0.4968,    Adjusted R-squared:  0.4939 
F-statistic: 168.9 on 1 and 171 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Matlab
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{fitlm}\NormalTok{(}\VariableTok{cpi}\OperatorTok{,} \SpecialStringTok{\textquotesingle{}HDI\textasciitilde{}CPI\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
fitlm(cpi, 'HDI~CPI')

ans = 


Linear regression model:
    HDI ~ 1 + CPI

Estimated Coefficients:
                   Estimate       SE        tStat       pValue  
                   ________    _________    ______    __________

    (Intercept)    0.42117      0.020558    20.487    6.7008e-48
    CPI            0.05847     0.0044996    12.994    2.6908e-27


Number of observations: 173, Error degrees of freedom: 171
Root Mean Squared Error: 0.125
R-squared: 0.497,  Adjusted R-Squared 0.494
F-statistic vs. constant model: 169, p-value = 2.69e-27
'org_babel_eoe'

ans =

    'org_babel_eoe'
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Python
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ statsmodels.formula.api }\ImportTok{as}\NormalTok{ model}
\NormalTok{X }\OperatorTok{=}\NormalTok{ cpi[[}\StringTok{\textquotesingle{}CPI\textquotesingle{}}\NormalTok{]]}
\NormalTok{Y }\OperatorTok{=}\NormalTok{ cpi[[}\StringTok{\textquotesingle{}HDI\textquotesingle{}}\NormalTok{]]}
\NormalTok{model.OLS(Y, X).fit().summary()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<class 'statsmodels.iolib.summary.Summary'>
"""
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                    HDI   R-squared:                       0.885
Model:                            OLS   Adj. R-squared:                  0.884
Method:                 Least Squares   F-statistic:                     1325.
Date:                Thu, 31 Aug 2017   Prob (F-statistic):           9.89e-83
Time:                        23:16:45   Log-Likelihood:                 8.1584
No. Observations:                 173   AIC:                            -14.32
Df Residuals:                     172   BIC:                            -11.16
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
CPI            0.1402      0.004     36.401      0.000       0.133       0.148
==============================================================================
Omnibus:                       10.423   Durbin-Watson:                   1.616
Prob(Omnibus):                  0.005   Jarque-Bera (JB):               11.099
Skew:                          -0.599   Prob(JB):                      0.00389
Kurtosis:                       2.674   Cond. No.                         1.00
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
"""
\end{verbatim}

\hypertarget{examples-extract-links-for-.html-file}{%
\subsection{Examples: Extract links for .html file}\label{examples-extract-links-for-.html-file}}

Retrieving data from a website is a common task. Here we parse a simple web page containing links to files we wish to download.

\begin{itemize}
\tightlist
\item
  Stata
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{disp }\StringTok{"Ha ha ha! No, you do not want to use Stata for this!"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
disp "Ha ha ha! No, you do not want to use Stata for this!"
Ha ha ha! No, you do not want to use Stata for this!
\end{verbatim}

\begin{itemize}
\tightlist
\item
  R
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(xml2)}
\NormalTok{index\_page \textless{}{-}}\StringTok{ }\KeywordTok{read\_html}\NormalTok{(}\StringTok{"http://tutorials.iq.harvard.edu/example\_data/baby\_names/EW/"}\NormalTok{)}
\NormalTok{all\_anchors \textless{}{-}}\StringTok{ }\KeywordTok{xml\_find\_all}\NormalTok{(index\_page, }\StringTok{"//a"}\NormalTok{)}
\NormalTok{all\_hrefs \textless{}{-}}\StringTok{ }\KeywordTok{xml\_attr}\NormalTok{(all\_anchors, }\StringTok{"href"}\NormalTok{)}
\NormalTok{data\_hrefs \textless{}{-}}\StringTok{ }\KeywordTok{grep}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{.csv$"}\NormalTok{, all\_hrefs, }\DataTypeTok{value =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{data\_links \textless{}{-}}\StringTok{ }\KeywordTok{paste0}\NormalTok{(}\StringTok{"http://tutorials.iq.harvard.edu/example\_data/baby\_names/EW/"}\NormalTok{, data\_hrefs)}
\NormalTok{data\_links}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_1996.csv" 
 [2] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_1997.csv" 
 [3] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_1998.csv" 
 [4] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_1999.csv" 
 [5] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2000.csv" 
 [6] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2001.csv" 
 [7] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2002.csv" 
 [8] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2003.csv" 
 [9] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2004.csv" 
[10] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2005.csv" 
[11] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2006.csv" 
[12] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2007.csv" 
[13] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2008.csv" 
[14] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2009.csv" 
[15] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2010.csv" 
[16] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2011.csv" 
[17] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2012.csv" 
[18] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2013.csv" 
[19] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2014.csv" 
[20] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2015.csv" 
[21] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_1996.csv"
[22] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_1997.csv"
[23] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_1998.csv"
[24] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_1999.csv"
[25] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2000.csv"
[26] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2001.csv"
[27] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2002.csv"
[28] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2003.csv"
[29] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2004.csv"
[30] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2005.csv"
[31] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2006.csv"
[32] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2007.csv"
[33] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2008.csv"
[34] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2009.csv"
[35] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2010.csv"
[36] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2011.csv"
[37] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2012.csv"
[38] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2013.csv"
[39] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2014.csv"
[40] "http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2015.csv"
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Matlab
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{index\_page} \OperatorTok{=} \VariableTok{urlread}\NormalTok{(}\SpecialStringTok{\textquotesingle{}http://tutorials.iq.harvard.edu/example\_data/baby\_names/EW/\textquotesingle{}}\NormalTok{)}\OperatorTok{;}
\VariableTok{all\_hrefs} \OperatorTok{=} \VariableTok{regexp}\NormalTok{(}\VariableTok{index\_page}\OperatorTok{,} \SpecialStringTok{\textquotesingle{}\textless{}a href="([\^{}"]*\textbackslash{}.csv)"\textgreater{}\textquotesingle{}}\OperatorTok{,} \SpecialStringTok{\textquotesingle{}tokens\textquotesingle{}}\NormalTok{)}\OperatorTok{\textquotesingle{};}
\VariableTok{all\_hrefs} \OperatorTok{=}\NormalTok{ [}\VariableTok{all\_hrefs}\NormalTok{\{}\OperatorTok{:}\NormalTok{\}]}\OperatorTok{\textquotesingle{};}
\VariableTok{all\_links} \OperatorTok{=} \VariableTok{strcat}\NormalTok{(}\SpecialStringTok{\textquotesingle{}http://tutorials.iq.harvard.edu/example\_data/baby\_names/EW/\textquotesingle{}}\OperatorTok{,} \VariableTok{all\_hrefs}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
index_page = urlread('http://tutorials.iq.harvard.edu/example_data/baby_names/EW/');
all_hrefs = regexp(index_page, '<a href="([^"]*\.csv)">', 'tokens')';
all_hrefs = [all_hrefs{:}]';
all_links = strcat('http://tutorials.iq.harvard.edu/example_data/baby_names/EW/', all_hrefs)

all_links =

  40×1 cell array

    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_1996.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_1997.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_1998.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_1999.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2000.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2001.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2002.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2003.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2004.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2005.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2006.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2007.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2008.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2009.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2010.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2011.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2012.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2013.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2014.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2015.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_1996.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_1997.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_1998.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_1999.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2000.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2001.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2002.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2003.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2004.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2005.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2006.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2007.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2008.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2009.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2010.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2011.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2012.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2013.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2014.csv'
    'http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2015.csv'
'org_babel_eoe'

ans =

    'org_babel_eoe'
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Python
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ lxml }\ImportTok{import}\NormalTok{ etree}
\ImportTok{import}\NormalTok{ requests}

\NormalTok{index\_text }\OperatorTok{=}\NormalTok{ requests.get(}\StringTok{\textquotesingle{}http://tutorials.iq.harvard.edu/example\_data/baby\_names/EW/\textquotesingle{}}\NormalTok{).text}
\NormalTok{index\_page }\OperatorTok{=}\NormalTok{ etree.HTML(index\_text)}
\NormalTok{all\_hrefs }\OperatorTok{=}\NormalTok{ [a.values() }\ControlFlowTok{for}\NormalTok{ a }\KeywordTok{in}\NormalTok{ index\_page.findall(}\StringTok{".//a"}\NormalTok{)]}
\NormalTok{data\_links }\OperatorTok{=}\NormalTok{ [}\StringTok{\textquotesingle{}http://tutorials.iq.harvard.edu/example\_data/baby\_names/EW/\textquotesingle{}} \OperatorTok{+}
\NormalTok{              href[}\DecValTok{0}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ href }\KeywordTok{in}\NormalTok{ all\_hrefs }\ControlFlowTok{if} \StringTok{\textquotesingle{}csv\textquotesingle{}} \KeywordTok{in}\NormalTok{ href[}\DecValTok{0}\NormalTok{]]}
\ControlFlowTok{for}\NormalTok{ link }\KeywordTok{in}\NormalTok{ data\_links:}
    \BuiltInTok{print}\NormalTok{(link)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_1996.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_1997.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_1998.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_1999.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2000.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2001.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2002.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2003.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2004.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2005.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2006.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2007.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2008.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2009.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2010.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2011.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2012.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2013.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2014.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/boys_2015.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_1996.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_1997.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_1998.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_1999.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2000.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2001.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2002.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2003.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2004.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2005.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2006.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2007.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2008.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2009.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2010.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2011.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2012.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2013.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2014.csv
http://tutorials.iq.harvard.edu/example_data/baby_names/EW/girls_2015.csv
\end{verbatim}

\hypertarget{creating-reports}{%
\section{Creating reports}\label{creating-reports}}

Once you've analyzed your data you'll most likely want to communicate your results. For short informal projects this might take the form of a blog post or an email to your colleagues. For larger more formal projects you'll likely want to prepare a substantial report or manuscript for disseminating your findings via a journal publication or other means. Other common means of reporting research findings include posters or slides for a conference talk.

Regardless of the type of report, you may choose to use either a \emph{markup language} or a WYSIWYG application like Microsoft Word/Powerpoint of a desktop publishing application such as Adobe InDesign.

\hypertarget{markup-languages}{%
\subsection{Markup languages}\label{markup-languages}}

A markup language is a system for producing a formatted document from a text file using information by the markup. A major advantage of markup languages is that the formatting instructions can be easily generated by the program you use for analyzing your data.

Markup languages include \emph{HTML}, \emph{LaTeX}, \emph{Markdown} and many others. \emph{LaTeX} and \emph{Markdown} are currently popular among data scientists, although others are used as well.

\emph{Markdown} is easy to write and designed to be human-readable. It is newer and somewhat less feature-full compared to LaTeX. It's main advantage is simplicity. \emph{LaTeX} is more verbose but provides for just about any feature you'll ever need.

MARKDOWN DEMO LATEX DEMO

\hypertarget{word-processors}{%
\subsection{Word processors}\label{word-processors}}

Modern word processors are largely just graphical user interfaces that write a markup language (usually XML) for you. They are commonly used for creating reports, but care must be taken when doing so.

If you use a word processor to produce your reports you should

\begin{itemize}
\tightlist
\item
  use the structured outline feature,
\item
  link rather than embed external resources (figures, tables, etc.),
\item
  use cross-referencing features, and
\item
  use a bibliography management system.
\end{itemize}

WORD PROCESSOR DEMO

\hypertarget{text-editors-integrated-development-environments}{%
\section{Text editors \& Integrated Development Environments}\label{text-editors-integrated-development-environments}}

A text editor edits text obviously. But that is not all! At a minimum, a text editor will also have a mechanism for reading and writing text files. Most text editors do much more than this.

An IDE provides tools for working with code, such as syntax highlighting, code completion, jump-to-definition, execute/compile, package management, refactoring, etc. Of course an IDE includes a text editor.

Editors and IDE's are not really separate categories; as you add features to a text editor it becomes more like an IDE, and a simple IDE may provide little more than a text editor. For example, Emacs is commonly referred to as a text editor, but it provides nearly every feature you would expect an IDE to have.

A more useful distinction is between language-specific editors/IDEs and general purpose editors/IDEs. The former are typically easier to set up since they come pre-configured for use with a specific language. General purpose editors/IDEs typically provide language support via \emph{plugins} and may require extensive configuration for each language.

\hypertarget{language-specific-editors-ides}{%
\subsection{Language specific editors \& IDEs}\label{language-specific-editors-ides}}

\begin{longtable}[]{@{}llll@{}}
\toprule
Editor & Features & Ease of use & Language\tabularnewline
\midrule
\endhead
RStudio & Excellent & Easy & R\tabularnewline
Spyder & Excellent & Easy & Python\tabularnewline
Stata do file editor & OK & Easy & Stata\tabularnewline
SPSS syntax editor & OK & Easy & SPSS\tabularnewline
\bottomrule
\end{longtable}

LANGUAGE SPECIFIC IDE DEMO

\hypertarget{general-purpose-editors-ides}{%
\subsection{General purpose editors \& IDEs}\label{general-purpose-editors-ides}}

\begin{longtable}[]{@{}llll@{}}
\toprule
Editor & Features & Ease of use & Language support\tabularnewline
\midrule
\endhead
Vim & Excellent & Hard & Good\tabularnewline
Emacs & Excellent & Hard & Excellent\tabularnewline
VS code & Excellent & Easy & Very good\tabularnewline
Atom & Good & Moderate & Good\tabularnewline
Eclipse & Excellent & Easy & Good\tabularnewline
Sublime Text & Good & Easy & Good\tabularnewline
Notepad++ & OK & Easy & OK\tabularnewline
Textmate & Good & Moderate & Good\tabularnewline
Kate & OK & Easy & Good\tabularnewline
\bottomrule
\end{longtable}

GENERAL PURPOSE EDITOR DEMO

\hypertarget{literate-programming-notebooks}{%
\section{Literate programming \& notebooks}\label{literate-programming-notebooks}}

In one of the Early demos we say an example of embedding R code in a markdown document. A closely related approach is to create a \emph{notebook} that includes the prose of the report, the code used for the analysis, and the results produced by that code.

\hypertarget{literate-programming}{%
\subsection{Literate programming}\label{literate-programming}}

Literate programming is the practice of embedding computer code in a natural language document. For example, using \emph{RMarkdown} we can embed R code in a report authored using Markdown. Python and Stata have their own versions of literate programming using Markdown.

\hypertarget{notebooks}{%
\subsection{Notebooks}\label{notebooks}}

Notebooks go one step farther, and include the output produced by the original program directly in the notebook. Examples include \emph{Jupyter}, \emph{Appache Zeppelin}, and \emph{Emacs Org Mode}.

NOTEBOOKS DEMO

\hypertarget{big-data-annoying-data-computationally-intensive-methods}{%
\section{Big data, annoying data, \& computationally intensive methods}\label{big-data-annoying-data-computationally-intensive-methods}}

Thus far we've discussed popular programming languages, data storage and retrieval options, text editors, and reporting technology. These are the basic building blocks I recommend using just about any time you find yourself working with data. There are times however when more is needed. For example, you may wish to use distributed computing for large or resource intensive computations.

\hypertarget{computing-clusters-at-harvard}{%
\subsection{Computing clusters at Harvard}\label{computing-clusters-at-harvard}}

Harvard provides a number of computing clusters, including Odyssey and the Research Computing Environment. Using these systems will be much easier if you know the basic tools well. After all, you're still going to need data storage/retrieval, you'll still need a text editor write code, and a programming language to write it in. My advice is to master these basics, and learn the rest as you need it.

\hypertarget{wrap-up}{%
\section{Wrap up}\label{wrap-up}}

\hypertarget{feedback}{%
\subsection{Feedback}\label{feedback}}

These workshops are a work-in-progress, please provide any feedback to: \href{mailto:help@iq.harvard.edu}{\nolinkurl{help@iq.harvard.edu}}

\hypertarget{resources}{%
\subsection{Resources}\label{resources}}

\begin{itemize}
\tightlist
\item
  IQSS

  \begin{itemize}
  \tightlist
  \item
    Workshops: \url{https://dss.iq.harvard.edu/workshop-materials}
  \item
    Data Science Services: \url{https://dss.iq.harvard.edu/}
  \item
    Research Computing Environment: \url{https://iqss.github.io/dss-rce/}
  \end{itemize}
\item
  HBS

  \begin{itemize}
  \tightlist
  \item
    Research Computing Services workshops: \url{https://training.rcs.hbs.org/workshops}
  \item
    Other HBS RCS resources: \url{https://training.rcs.hbs.org/workshop-materials}
  \item
    RCS consulting email: \url{mailto:research@hbs.edu}
  \end{itemize}
\end{itemize}

\hypertarget{part-r}{%
\part{R}\label{part-r}}

\hypertarget{r-installation}{%
\chapter{R Installation}\label{r-installation}}

\begin{alert}

\textbf{Your professional conduct is greatly appreciated. Out of respect to your fellow workshop attendees and instructors, please arrive at your workshop on time, having pre-installed all necessary software and materials. This will likely take 15-20 minutes.}

\end{alert}

Before starting any of our R workshops, it is necessary to complete 4 tasks. Please make sure all these tasks are completed \textbf{before} you attend your workshop, as, depending on your internet speed, they may take a long time.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  download and unzip \textbf{class materials}
\item
  download and install \textbf{R}
\item
  download and install \textbf{RStudio}
\item
  install the \texttt{tidyverse} suite of \textbf{R packages}
\end{enumerate}

\includegraphics{R/Rinstall/images/install_software_R.png}

\hypertarget{troubleshooting-session}{%
\section{Troubleshooting session}\label{troubleshooting-session}}

We will hold a troubleshooting session during the 20 minutes prior to the start of the workshop.
\textbf{If you are unable to complete all of the tasks, please stop by the training room during this session.}
Once the workshop starts we will \textbf{NOT} be able to give you one-to-one assistance with troubleshooting installation problems. Likewise, if you arrive late, please do \textbf{NOT} expect one-to-one assistance for anything covered at the beginning of the workshop.

\hypertarget{materials}{%
\section{Materials}\label{materials}}

Download class materials for your workshop:

\begin{itemize}
\tightlist
\item
  R Introduction: \url{https://github.com/IQSS/dss-workshops/raw/master/R/Rintro.zip}
\item
  R Regression Models: \url{https://github.com/IQSS/dss-workshops/raw/master/R/Rmodels.zip}
\item
  R Graphics: \url{https://github.com/IQSS/dss-workshops/raw/master/R/Rgraphics.zip}
\item
  R Data Wrangling: \url{https://github.com/IQSS/dss-workshops/raw/master/R/RDataWrangling.zip}
\end{itemize}

Extract materials from the zipped directory (Right-click -\textgreater{} Extract All on Windows, double-click on Mac) and move them to your desktop.

It will be useful when you view the above materials for you to see the different file extensions on your computer. Here are instructions for enabling this:

\begin{itemize}
\tightlist
\item
  \href{https://support.apple.com/guide/mac-help/show-or-hide-filename-extensions-on-mac-mchlp2304/mac}{Mac OS}
\item
  \href{http://kb.winzip.com/kb/entry/26/}{Windows OS}
\end{itemize}

\hypertarget{software}{%
\section{Software}\label{software}}

You must install \textbf{both R and RStudio}; it is essential that you have these pre-installed so that we can start the workshop on time. It is also important that you have the \textbf{latest versions} of each software, which currently are:

\begin{itemize}
\tightlist
\item
  R version \textbf{4.0.2}
\item
  RStudio version \textbf{1.3.1073}
\end{itemize}

\textbf{Mac OS X:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Install R by downloading and running \href{http://cran.r-project.org/bin/macosx/R-latest.pkg}{this .pkg file} from \href{http://cran.r-project.org/index.html}{CRAN}.
\item
  Install the RStudio Desktop IDE by downloading and running \href{https://download1.rstudio.org/desktop/macos/RStudio-1.3.1073.dmg}{this .dmg file}.
\end{enumerate}

\textbf{Windows:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Install R by downloading and running \href{https://cran.r-project.org/bin/windows/base/release.htm}{this .exe file} from \href{http://cran.r-project.org/index.html}{CRAN}.
\item
  Install the RStudio Desktop IDE by downloading and running \href{https://download1.rstudio.org/desktop/windows/RStudio-1.3.1073.exe}{this .exe file}.
\end{enumerate}

\textbf{Linux:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Install R by downloading the binary files for your distribution from \href{http://cran.r-project.org/index.html}{CRAN}. Or you can use your package manager (e.g., for Debian/Ubuntu run \texttt{sudo\ apt-get\ install\ r-base} and for Fedora run \texttt{sudo\ yum\ install\ R}).
\item
  Install the RStudio Desktop IDE \href{https://rstudio.com/products/rstudio/download/\#download}{for your distribution}.
\end{enumerate}

\begin{alert}

\textbf{Success? After both installations, please launch RStudio. If you were successful with the installations, you should see a window similar to this (note that the R version reported may be newer):}

\end{alert}

\includegraphics{R/Rinstall/images/rstudio_successful_install.png}

\begin{alert}

\textbf{If you are having any difficulties with the installations or your RStudio screen does not look like this one, please stop by the training room 20 minutes prior to the start of the workshop.}

\end{alert}

\hypertarget{installing-the-tidyverse}{%
\section{\texorpdfstring{Installing the \texttt{tidyverse}}{Installing the tidyverse}}\label{installing-the-tidyverse}}

We will use the \texttt{tidyverse} suite of packages throughout these R workshops.
Here are the steps for installation:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Launch an R session within RStudio}

  On Windows, click the start button and search for RStudio then click on it. On Mac,
  RStudio will be in your applications folder --- double click on it.
\item
  \textbf{Install \texttt{tidyverse}}

  In the left-hand side window (called the \texttt{console}), at the command prompt (\texttt{\textgreater{}}) type the following and press enter:

  \texttt{install.packages("tidyverse")}

  \begin{itemize}
  \item
    If a choice appears that says something like:

    \texttt{Do\ you\ want\ to\ install\ from\ sources\ the\ package\ which\ needs\ compilation?}

    type \texttt{No} in the console.
  \item
    If you are running Windows OS, you may see a message that says:

    \texttt{WARNING:\ Rtools\ is\ required\ to\ build\ R\ packages,\ but\ is\ not\ currently\ installed.}

    You can safely ignore this warning.
  \end{itemize}

  A number of messages will scroll by, and there will be a long minute or two
  pause where nothing appears to happen (but the installation is actually occurring).
  At last, the output parade should end with a message like:

  \texttt{The\ downloaded\ source/binary\ packages\ are\ in....}
\item
  \textbf{Check that installation was successful}

  We can check that \texttt{tidyverse} has installed correctly by connecting it to our current R session.
  Type the following in the console at the command prompt (\texttt{\textgreater{}}) and press enter:

  \texttt{library(tidyverse)}

  \begin{alert}

  \textbf{Success? If so, you should see the following message in the console (note that the version numbers reported may be newer):}

  \end{alert}

  \includegraphics{R/Rinstall/images/tidyverse_install.png}

  \begin{alert}

  \textbf{If you do not see this message and encounter an error --- try troubleshooting this in the next section.}

  \end{alert}
\end{enumerate}

\hypertarget{troubleshooting-tidyverse-installation}{%
\subsection{\texorpdfstring{Troubleshooting \texttt{tidyverse} installation}{Troubleshooting tidyverse installation}}\label{troubleshooting-tidyverse-installation}}

Sometimes, you may run into problems installing the \texttt{tidyverse} suite of packages. Here are some commonly encountered errors and suggestions for how to fix them:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{\texttt{tidyverse} is not available for R version\ldots{}}

  \begin{itemize}
  \tightlist
  \item
    Solution: make sure you have the latest versions of both R (4.0.2) and RStudio (1.3.1073).
  \end{itemize}
\item
  \textbf{there is no package \texttt{rlang}\ldots{}}

  \begin{itemize}
  \tightlist
  \item
    Solution: run this command in the console at the command prompt (\texttt{\textgreater{}}):
  \item
    \texttt{install.packages("dplyr")}
  \item
    If a choice appears that says something like \texttt{Do\ you\ want\ to\ install\ from\ sources\ the\ package\ which\ needs\ compilation?}, type \texttt{No} in the console.
  \end{itemize}
\item
  \textbf{there is no package \texttt{broom}\ldots{}}

  \begin{itemize}
  \tightlist
  \item
    Solution: run these commands in the console at the command prompt (\texttt{\textgreater{}}), \textbf{in this order}:
  \item
    \texttt{install.packages("backports")}
  \item
    \texttt{install.packages("zeallot")}
  \item
    \texttt{install.packages("broom")}
  \item
    \texttt{install.packages("tidyverse")}
  \item
    If a choice appears at any point that says something like \texttt{Do\ you\ want\ to\ install\ from\ sources\ the\ package\ which\ needs\ compilation?}, type \texttt{No} in the console.
  \end{itemize}
\item
  \textbf{rlang and/or broom still do not work}

  \begin{itemize}
  \tightlist
  \item
    Solution: load individual packages that we need from the \texttt{tidyverse} suite, by running the following commands in the console at the command prompt (\texttt{\textgreater{}}):
  \item
    \texttt{library("dplyr")} \# for the pipe function \%\textgreater\% and other SQL commands
  \item
    \texttt{library("ggplot2")} \# modern data visualization
  \item
    \texttt{library("readr")} \# to load CSV data files
  \item
    \texttt{library("tidyr")} \# to reshape data frames with functions like gather or spread
  \end{itemize}
\end{enumerate}

\begin{alert}

\textbf{If you have still not successfully installed \texttt{tidyverse} (or at least \texttt{dplyr}, \texttt{ggplot2}, \texttt{readr}, and \texttt{tidyr}) after troubleshooting, please stop by the training room 20 minutes before the start of your workshop so we can help you. Without these packages, you will not be able to follow along with the workshop materials.}

\end{alert}

\hypertarget{installing-rmarkdown-optional}{%
\section{\texorpdfstring{Installing \texttt{rmarkdown} (optional)}{Installing rmarkdown (optional)}}\label{installing-rmarkdown-optional}}

We can also install the \texttt{rmarkdown} package, which will allow us to
combine our text and code into a formatted document at the end of
the workshops. Installing this package is optional and will not affect
your ability to follow along with the workshop.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Install \texttt{rmarkdown}}

  At the command prompt in the console (\texttt{\textgreater{}}), please run the following command and press enter:

  \texttt{install.packages("rmarkdown")}

  then wait for the stream of messages to end with:

  \texttt{The\ downloaded\ source/binary\ packages\ are\ in....}
\item
  \textbf{Check that installation was successful}

  We can check that \texttt{rmarkdown} has installed correctly by connecting it to our R session.
  Type the following in the console at the command prompt (\texttt{\textgreater{}}) and press enter:

  \texttt{library(rmarkdown)}

  \begin{alert}

  \textbf{Success? If so, in the console you should see just a command prompt (\texttt{\textgreater{}}) with no messages to the right of it.}

  \end{alert}

  \begin{alert}

  \textbf{If you see error or warning messages after the command prompt, the installation was not successful.}

  \end{alert}
\end{enumerate}

If all the above steps have been completed successfully, you should now
be ready to start your workshop. \textbf{If you ran into any problems, please
stop by the training room 20 minutes before the start of your workshop.}

\hypertarget{resources-1}{%
\section{Resources}\label{resources-1}}

\begin{itemize}
\tightlist
\item
  IQSS

  \begin{itemize}
  \tightlist
  \item
    Workshops: \url{https://dss.iq.harvard.edu/workshop-materials}
  \item
    Data Science Services: \url{https://dss.iq.harvard.edu/}
  \item
    Research Computing Environment: \url{https://iqss.github.io/dss-rce/}
  \end{itemize}
\item
  HBS

  \begin{itemize}
  \tightlist
  \item
    Research Computing Services workshops: \url{https://training.rcs.hbs.org/workshops}
  \item
    Other HBS RCS resources: \url{https://training.rcs.hbs.org/workshop-materials}
  \item
    RCS consulting email: \url{mailto:research@hbs.edu}
  \end{itemize}
\end{itemize}

\hypertarget{r-introduction}{%
\chapter{R Introduction}\label{r-introduction}}

\textbf{Topics}

\begin{itemize}
\tightlist
\item
  Functions
\item
  Objects
\item
  Assignment
\item
  Finding help
\item
  Importing packages
\item
  Basic data manipulation
\item
  Operations within groups of data
\item
  Saving data
\end{itemize}

\hypertarget{setup}{%
\section{Setup}\label{setup}}

\hypertarget{software-and-materials}{%
\subsection{Software and Materials}\label{software-and-materials}}

Follow the \href{./Rinstall.html}{R Installation} instructions and ensure that you can successfully start RStudio.

A handy \href{R/Rintro/base-r-cheat-sheet.pdf}{base R cheat-sheet} is available to help you look up and remember basic syntax.
In addition, a \href{R/Rintro/data-transformation-cheat-sheet.pdf}{data transformation cheat-sheet} provides a convenient summary of data manipulation syntax.

\hypertarget{class-structure}{%
\subsection{Class Structure}\label{class-structure}}

Informal - Ask questions at any time. Really!

Collaboration is encouraged - please spend a minute introducing yourself to your neighbors!

\hypertarget{prerequisites}{%
\subsection{Prerequisites}\label{prerequisites}}

This is an introductory R course:

\begin{itemize}
\tightlist
\item
  Assumes no prior knowledge of \textbf{how to use} R
\item
  We do assume you know \textbf{why} you want to learn R. If you don't, and want a comparison of R to other statistical software, see our \href{./DataScienceTools.html}{Data Science Tools} workshop
\item
  Relatively slow-paced
\end{itemize}

\hypertarget{goals}{%
\subsection{Goals}\label{goals}}

\begin{alert}

We will learn about the R language by analyzing a dataset of baby names.
In particular, our goals are to learn about:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What R is and how it works
\item
  How we can interact with R
\item
  Foundations of the language (functions, objects, assignment)
\item
  The \texttt{tidyverse} package ecosystem for data science
\item
  Basic data manipulation useful for cleaning datasets
\item
  Working with grouped data
\item
  Aggregating data to create summaries
\item
  Saving objects, data, and scripts
\end{enumerate}

This workshop will not cover how to iterate over collections of data, create
your own functions, produce publication quality graphics, or fit models to data.
These topics are covered in our \href{./RDataWrangling.html}{R Data Wrangling},
\href{./Rgraphics.html}{R Graphics}, and \href{./Rmodels.html}{R Regression Models} workshops.

\end{alert}

\hypertarget{r-basics}{%
\section{R basics}\label{r-basics}}

\begin{alert}

\textbf{GOAL: To learn about the foundations of the R language.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What R is and how it works
\item
  R interfaces
\item
  Functions
\item
  Objects
\item
  Assignment
\item
  Getting help
\item
  \texttt{tidyverse} package ecosystem for data science
\end{enumerate}

\end{alert}

\hypertarget{what-is-r}{%
\subsection{What is R?}\label{what-is-r}}

\begin{itemize}
\tightlist
\item
  R is a free language and environment for statistical computing and graphics
\item
  R is an interpreted language, not a compiled one, meaning that all commands
  typed on the keyboard are directly executed without requiring to build a complete
  program (this is like Python and unlike C, Fortran, Pascal, etc.)
\item
  R has existed for over 25 years
\item
  R is modular --- most functionality is from add-on packages. So the language can
  be thought of as a \emph{platform} for creating and running a large number of useful packages.
\end{itemize}

\hypertarget{why-use-r}{%
\subsection{Why use R?}\label{why-use-r}}

\begin{itemize}
\tightlist
\item
  The most popular software for data analysis
\item
  Extremely flexible: can be used to manipulate, analyze, and visualize
  any kind of data
\item
  Cutting edge statistical tools
\item
  Publication quality graphics
\item
  15,000+ add on packages covering all aspects of statistics and machine learning
\item
  Active community of users
\end{itemize}

\hypertarget{how-does-r-work}{%
\subsection{How does R work?}\label{how-does-r-work}}

While graphical-based statistical software (e.g., SPSS, GraphPad) immediately display
the results of an analysis, \textbf{R stores results in an \texttt{object} (a data structure)},
so that an analysis can be done with no result displayed. Such a feature is very
useful, since a user can extract only that part of the results that is of interest
and can pass results into further analyses.

For example, if you run a series of 20 regressions and want to compare the
different regression coefficients, R can display only the estimated coefficients:
thus the results may take a single line, whereas graphical-based software could
open 20 results windows. In addition, these regression coefficients can be passed
directly into further analyses --- such as generating predictions.

\includegraphics{R/Rintro/images/R_chain.png}

When R is running, variables, data, functions, results, etc., are \textbf{stored in memory}
on the computer in the form of \texttt{objects} that have a name. The user can
\textbf{perform actions} on these objects with \texttt{operators} (arithmetic, logical,
comparison, etc.) and \texttt{functions} (which are themselves objects). Here's a
schematic of how this all fits together:

\includegraphics{R/Rintro/images/R_works.png}

\hypertarget{interfaces}{%
\subsection{Interfaces}\label{interfaces}}

\hypertarget{text-editors-ides-notebooks}{%
\subsubsection{Text editors, IDEs, \& Notebooks}\label{text-editors-ides-notebooks}}

There are different ways of interacting with R. The two main ways are through:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{text editors} or \textbf{Integrated Development Environments (IDEs):} Text editors and IDEs are not really separate categories; as you add features to a text editor it becomes more like an IDE. Some editors/IDEs are language-specific while others are general purpose --- typically providing language support via plugins. For these workshops we will use \href{https://rstudio.com/}{RStudio}; it is a good R-specific IDE with many useful features. Here are a few popular editors/IDEs that can be used with R:

  \begin{longtable}[]{@{}llll@{}}
  \toprule
  Editor / IDE & Features & Ease of use & Language support\tabularnewline
  \midrule
  \endhead
  RStudio & Excellent & Easy & R only\tabularnewline
  Jupyter Lab & Good & Easy & Excellent\tabularnewline
  VS code & Excellent & Easy & Very good\tabularnewline
  Atom & Good & Moderate & Good\tabularnewline
  Vim & Excellent & Hard & Good\tabularnewline
  Emacs & Excellent & Hard & Excellent\tabularnewline
  \bottomrule
  \end{longtable}
\item
  \textbf{Notebooks:} Web-based applications that allow you to create and share documents that contain live code, equations, visualizations, and narrative text. A popular notebook is the open source \href{https://jupyter.org/}{Jupyter Notebook} that has support for 40+ languages.
\end{enumerate}

\hypertarget{source-code-literate-programming}{%
\subsubsection{Source code \& literate programming}\label{source-code-literate-programming}}

There are also several different \textbf{formats} available for writing code in R.
These basically boil down to a choice between:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Source code:} the practice of writing code, and possibly comments, in a plain text document. In R this is done by writing code in a text file with a \texttt{.R} or \texttt{.r} extension. Writing source code has the great advantage of being simple. Source code is the format of choice if you intend to run your code as a complete script - for example, from the command line.
\item
  \textbf{Literate programming:} the practice of embedding computer code in a natural language document. In R this is often done using \href{https://rmarkdown.rstudio.com/}{\textbf{Rmarkdown}}, which involves embedding R code in a document that is authored using \emph{Markdown} and which has a \texttt{.Rmd} extension. \emph{Markdown} is easy to write and designed to be human-readable. Markdown is the format of choice if you intend to run your code interactively, by running small pieces of code and looking at each output. Many researchers use Markdown to write their journal papers, dissertations, and statistics/math class notes, since it is easy to convert into other formats later, such as HTML (for a webpage), MS Word, or PDF (via LaTeX).
\end{enumerate}

Here are some resources for learning more about RMarkdown and RStudio:

\begin{itemize}
\tightlist
\item
  \url{https://rmarkdown.rstudio.com/authoring_quick_tour.html}
\item
  \url{https://cran.r-project.org/web/packages/rmarkdown/vignettes/rmarkdown.html}
\item
  \url{https://rstudio.com/wp-content/uploads/2019/01/Cheatsheets_2019.pdf}
\end{itemize}

\hypertarget{launch-a-session}{%
\subsection{Launch a session}\label{launch-a-session}}

Start RStudio and create a new project:

\begin{itemize}
\tightlist
\item
  On Windows click the start button and search for RStudio. On Mac
  RStudio will be in your applications folder.
\item
  In RStudio go to \texttt{File\ -\textgreater{}\ New\ Project}.
\item
  Choose \texttt{Existing\ Directory} and browse to the workshop materials directory on your desktop.
\item
  Choose \texttt{File\ -\textgreater{}\ Open\ File} and select the file with the word ``BLANK'' in the name.
\end{itemize}

\hypertarget{exercise-0}{%
\subsection{Exercise 0}\label{exercise-0}}

The purpose of this exercise is to give you an opportunity to explore
the interface provided by RStudio. You may not know how to do these things;
that's fine! This is an opportunity to figure it out.

Also keep in mind that we are living in a golden age of tab completion.
If you don't know the name of an R function, try guessing the first two
or three letters and pressing TAB. If you guessed correctly the function
you are looking for should appear in a pop up!

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Try to get R to add 2 plus 2.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\item
  Try to calculate the square root of 10.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\item
  R includes extensive documentation, including a manual named ``An
  introduction to R''. Use the RStudio help pane to locate this manual.
\end{enumerate}

{Click for Exercise 0 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  2 plus 2

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2} \OperatorTok{+}\StringTok{ }\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# or}
\KeywordTok{sum}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}
\item
  square root of 10

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sqrt}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.162278
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# or}
\DecValTok{10}\OperatorTok{\^{}}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.162278
\end{verbatim}
\item
  Find ``An Introduction to R''.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Go to the main help page by running \textquotesingle{}help.start() or using the GUI}
\CommentTok{\# menu, find and click on the link to "An Introduction to R".}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

\end{alert}

\hypertarget{syntax-rules}{%
\subsection{Syntax rules}\label{syntax-rules}}

\begin{itemize}
\tightlist
\item
  R is case sensitive
\item
  R ignores white space
\item
  Variable names should start with a letter (A-Z and a-z)
  and can include letters, digits (0-9), dots (.), and underscores (\_)
\item
  Comments can be inserted using a hash \texttt{\#} symbol
\item
  Functions must be written with parentheses, even
  if there is nothing within them; for example: \texttt{ls()}
\end{itemize}

\hypertarget{function-calls}{%
\subsection{Function calls}\label{function-calls}}

\textbf{Functions perform actions} --- they take some input, called \texttt{arguments} and return some
output (i.e., a result). Here's a schematic of how a function works:

\includegraphics{R/Rintro/images/function.png}

The general form for calling R functions is

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# FunctionName(arg.1 = value.1, arg.2 = value.2, ..., arg.n = value.n)}
\end{Highlighting}
\end{Shaded}

The arguments in a function can be objects (data, formulae, expressions, etc.),
some of which could be defined by default in the function; these default values may
be modified by the user by specifying options.

Arguments can be \textbf{matched by name}; unnamed arguments will be \textbf{matched by position}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(}\DataTypeTok{x =} \FloatTok{2.34}\NormalTok{, }\DataTypeTok{digits =} \DecValTok{1}\NormalTok{) }\CommentTok{\# match by name}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(}\FloatTok{2.34}\NormalTok{, }\DecValTok{1}\NormalTok{) }\CommentTok{\# match by position}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FloatTok{2.34}\NormalTok{) }\CommentTok{\# be careful when matching by position!}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(}\DataTypeTok{digits =} \DecValTok{1}\NormalTok{, }\DataTypeTok{x =} \FloatTok{2.34}\NormalTok{) }\CommentTok{\# matching by name is safer!}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.3
\end{verbatim}

\hypertarget{assignment}{%
\subsection{Assignment}\label{assignment}}

Objects (data structures) can be assigned names and used in subsequent operations:

\begin{itemize}
\tightlist
\item
  The \textbf{gets} \texttt{\textless{}-} operator (less than followed by a dash) is used to save objects
\item
  The name on the left \textbf{gets} the object on the right
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sqrt}\NormalTok{(}\DecValTok{10}\NormalTok{) }\CommentTok{\# calculate square root of 10; result is not stored anywhere}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.162278
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x \textless{}{-}}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\DecValTok{10}\NormalTok{) }\CommentTok{\# assign result to a variable named x}
\end{Highlighting}
\end{Shaded}

As mentioned in \textbf{Syntax rules} above, names should start with a letter, and contain only letters, numbers, underscores, and periods.

\hypertarget{asking-for-help}{%
\subsection{Asking for help}\label{asking-for-help}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  You can ask R for help using the \texttt{help} function, or the \texttt{?} shortcut.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{help}\NormalTok{(help)}
\NormalTok{?help}
\NormalTok{?sqrt}
\end{Highlighting}
\end{Shaded}

  The \texttt{help} function can be used to look up the documentation for a function, or
  to look up the documentation to a package. We can learn how to use the \texttt{stats}
  package by reading its documentation like this:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{help}\NormalTok{(}\DataTypeTok{package =} \StringTok{"stats"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\item
  If you know the name of the package you want to use, then Googling ``R \emph{package-name}'' will
  often get you to the documentation. Packages are hosted on several different repositories, including:

  \begin{itemize}
  \tightlist
  \item
    CRAN: \url{https://cran.r-project.org/web/packages/available_packages_by_name.html}
  \item
    Bioconductor: \url{https://www.bioconductor.org/packages/release/bioc/}
  \item
    Github: \url{http://rpkg.gepuro.net/}
  \item
    R-Forge: \url{https://r-forge.r-project.org/R/?group_id=1326}
  \end{itemize}
\item
  If you know the type of analysis you want to perform, you can Google ``CRAN Task Views'',
  where there are curated lists of packages \url{https://cran.r-project.org/web/views/}. If you want to
  know which packages are popular, you can look at \url{https://r-pkg.org}.
\end{enumerate}

\hypertarget{reading-data}{%
\subsection{Reading data}\label{reading-data}}

R has data reading functionality built-in -- see e.g.,
\texttt{help(read.table)}. However, faster and more robust tools are
available, and so to make things easier on ourselves we will use a
\emph{contributed package} instead. This requires that we
learn a little bit about packages in R.

\hypertarget{installing-using-packages}{%
\subsection{Installing \& using packages}\label{installing-using-packages}}

R is a modular environment that is extended by the use of \textbf{packages}.
Packages are collections of functions or commands that are designed to
perform specific tasks (e.g., fit a type of regression model). A large
number of contributed packages are available (\textgreater{} 15,000).

Using an R package is a \textbf{two step process}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Install the package onto your computer using the
  \texttt{install.packages()} function. This only needs to
  be done the \textbf{first time} you use the package.
\item
  Load the package into your R session's search path
  using the \texttt{library()} function. This needs to be done
  \textbf{each time} you use the package.
\end{enumerate}

\hypertarget{the-tidyverse}{%
\subsection{\texorpdfstring{The \texttt{tidyverse}}{The tidyverse}}\label{the-tidyverse}}

While R's built-in packages are powerful, in recent years there has
been a big surge in well-designed \emph{contributed packages} for R. In
particular, a collection of R packages called
\href{https://www.tidyverse.org/}{\texttt{tidyverse}} have been
designed specifically for data science. All packages included in
\texttt{tidyverse} share an underlying design philosophy, grammar, and
data structures. This philosophy is rooted in the idea of ``tidy data'':

\includegraphics{R/Rintro/images/tidy_data.png}

A typical workflow for using \texttt{tidyverse} packages looks like this:

\includegraphics{R/Rintro/images/tidy_workflow.png}

You should have already installed the \texttt{tidyverse} and \texttt{rmarkdown}
packages onto your computer before the workshop
--- see \href{./Rinstall.html}{R Installation}.
Now let's load these packages into the search path of our R session.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load packages tidyverse and rmarkdown using library() function}
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(rmarkdown)}
\end{Highlighting}
\end{Shaded}

\hypertarget{readers-for-common-file-types}{%
\subsection{Readers for common file types}\label{readers-for-common-file-types}}

To read data from a file, you have to know what kind of file
it is. The table below lists functions from the \texttt{readr} package, which
is part of \texttt{tidyverse}, that can import data from common plain-text formats.

\begin{longtable}[]{@{}ll@{}}
\toprule
Data Type & Function\tabularnewline
\midrule
\endhead
comma separated & \texttt{read\_csv()}\tabularnewline
tab separated & \texttt{read\_delim()}\tabularnewline
other delimited formats & \texttt{read\_table()}\tabularnewline
fixed width & \texttt{read\_fwf()}\tabularnewline
\bottomrule
\end{longtable}

\textbf{Note} You may notice that there exist similar functions
in one of the built-in packages in R called \texttt{utils},
e.g., \texttt{read.csv} and \texttt{read.delim}. These are legacy functions that
tend to be slower and less robust than the \texttt{readr} functions. One way
to tell them apart is that the faster more robust versions use
underscores in their names (e.g., \texttt{read\_csv}) while the older
functions use dots (e.g., \texttt{read.csv}). Our advice is to use the more
robust newer versions, i.e., the ones with underscores.

\hypertarget{baby-names-data}{%
\subsection{Baby names data}\label{baby-names-data}}

As an example project we will analyze the popularity of baby names in the US from 1960 through 2017. The data were retrieved from
\url{https://catalog.data.gov/dataset/baby-names-from-social-security-card-applications-national-level-data}.

Here are the questions we will use R to answer:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  In which year did your name (or another name) occur most frequently by \textbf{count}?
\item
  Which names have the highest popularity by \textbf{proportion} for each sex and year?
\item
  How does the percentage of babies given one of the top 10 names of the year change over time?
\end{enumerate}

\hypertarget{exercise-1}{%
\subsection{Exercise 1}\label{exercise-1}}

\textbf{Reading the baby names data}

Make sure you have installed the \texttt{tidyverse} suite of packages and attached them with \texttt{library(tidyverse)}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Open the \texttt{read\_csv()} help page to determine how to use it to read in data.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\item
  Read the baby names data using the \texttt{read\_csv()} function and assign the result
  with the name \texttt{baby\_names}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\item
  BONUS (optional): Save the \texttt{baby\_names} data as a Stata data set \texttt{babynames.dta}
  and as an R data set \texttt{babynames.rds}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

{Click for Exercise 1 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Open the \texttt{read\_csv()} help page to determine how to use it to read in data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?read\_csv}
\end{Highlighting}
\end{Shaded}
\item
  Read the baby names data using the \texttt{read\_csv()} function and assign the result with the name \texttt{baby\_names}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{baby\_names \textless{}{-}}\StringTok{ }\KeywordTok{read\_csv}\NormalTok{(}\StringTok{"babyNames.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\item
  BONUS (optional): Save the \texttt{baby\_names} data as a Stata data set \texttt{babynames.dta} and as an R data set \texttt{babynames.rds}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{write\_dta}\NormalTok{(baby\_names, }\DataTypeTok{version =} \DecValTok{15}\NormalTok{, }\DataTypeTok{path =}\NormalTok{ “babynames.dta”)}

\KeywordTok{write\_rds}\NormalTok{(baby\_names, }\DataTypeTok{file =}\NormalTok{ “babynames.rds”)}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

\end{alert}

\hypertarget{manipulating-data}{%
\section{Manipulating data}\label{manipulating-data}}

\begin{alert}

\textbf{GOAL: To learn about basic data manipulation used to clean datasets.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Filtering data by choosing rows --- using the \texttt{filter()} function
\item
  Selecting data by choosing columns --- using the \texttt{select()} function
\item
  Arranging data by reordering rows --- using the \texttt{arrange()} function
\item
  Using the pipe \texttt{\%\textgreater{}\%} operator to simplify sequential operations
\end{enumerate}

\end{alert}

In this section we will pull out specific names from the baby names data and
examine changes in their popularity over time.

The \texttt{baby\_names} object we created in the last exercise is a \texttt{data.frame}.
There are many other data structures in R, but for now we'll focus on
working with \texttt{data.frames}. Think of a \texttt{data.frame} as a spreadsheet.
If you want to know more about R data structures, you can see a summary
in our \href{./RDataWrangling.html\#data-types-and-structures}{R Data Wrangling} workshop.

R has decent data manipulation tools built-in -- see e.g.,
\texttt{help(Extract)}. But, \texttt{tidyverse} packages often provide
more intuitive syntax for accomplishing the same task. In
particular, we will use the \texttt{dplyr} package from \texttt{tidyverse}
to filter, select, and arrange data, as well as create new variables.

\includegraphics{R/Rintro/images/dplyr.png}

\hypertarget{filter-select-arrange}{%
\subsection{Filter, select, \& arrange}\label{filter-select-arrange}}

One way to find the year in which your name was the most popular
is to filter out just the rows corresponding to your name, and
then arrange (sort) by \texttt{Count}.

To demonstrate these techniques we'll try to determine whether
``Alex''" or ``Mark'' was more popular in 1992. We start by filtering the
data so that we keep only rows where Year is equal to \texttt{1992} and Name is
either ``Alex'' or ``Mark''.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Read in the baby names data if you haven\textquotesingle{}t already}
\NormalTok{baby\_names \textless{}{-}}\StringTok{ }\KeywordTok{read\_csv}\NormalTok{(}\StringTok{"babyNames.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Filter data, keeping "Alex" and "Mark" in year 1992, record in baby\_names\_alexmark}
\CommentTok{\# Use logical operators to specify the filtering condition}
\NormalTok{baby\_names\_alexmark \textless{}{-}}\StringTok{ }\KeywordTok{filter}\NormalTok{(baby\_names, }
\NormalTok{             Year }\OperatorTok{==}\StringTok{ }\DecValTok{1992} \OperatorTok{\&}\StringTok{ }\NormalTok{(Name }\OperatorTok{==}\StringTok{ "Alex"} \OperatorTok{|}\StringTok{ }\NormalTok{Name }\OperatorTok{==}\StringTok{ "Mark"}\NormalTok{))}

\KeywordTok{print}\NormalTok{(baby\_names\_alexmark) }\CommentTok{\# explicit printing}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 4
##   Name  Sex   Count  Year
##   <chr> <chr> <dbl> <dbl>
## 1 Alex  Girls   366  1992
## 2 Mark  Girls    20  1992
## 3 Mark  Boys   8743  1992
## 4 Alex  Boys   7348  1992
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{baby\_names\_alexmark }\CommentTok{\# implicit printing}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 4
##   Name  Sex   Count  Year
##   <chr> <chr> <dbl> <dbl>
## 1 Alex  Girls   366  1992
## 2 Mark  Girls    20  1992
## 3 Mark  Boys   8743  1992
## 4 Alex  Boys   7348  1992
\end{verbatim}

Notice that we can combine conditions using \texttt{\&} (AND)
and \texttt{\textbar{}} (OR).

In this case it's pretty easy to see that ``Mark'' is more popular,
but to make it even easier we can arrange the data so that the
most popular name is listed first.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Arrange the data by Count to see the most popular name first}
\KeywordTok{arrange}\NormalTok{(baby\_names\_alexmark, Count)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 4
##   Name  Sex   Count  Year
##   <chr> <chr> <dbl> <dbl>
## 1 Mark  Girls    20  1992
## 2 Alex  Girls   366  1992
## 3 Alex  Boys   7348  1992
## 4 Mark  Boys   8743  1992
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Arrange the data in descending order instead}
\KeywordTok{arrange}\NormalTok{(baby\_names\_alexmark, }\KeywordTok{desc}\NormalTok{(Count))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 4
##   Name  Sex   Count  Year
##   <chr> <chr> <dbl> <dbl>
## 1 Mark  Boys   8743  1992
## 2 Alex  Boys   7348  1992
## 3 Alex  Girls   366  1992
## 4 Mark  Girls    20  1992
\end{verbatim}

We can also use the \texttt{select()} function to subset the \texttt{data.frame}
by columns. We can then assign the output to a new object. If we
would just like to glance at the first few lines we can use the
\texttt{head()} function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Select columns Name and Count and assign to a new object "baby\_names\_subset"}
\NormalTok{baby\_names\_subset \textless{}{-}}\StringTok{ }\KeywordTok{select}\NormalTok{(baby\_names, Name, Count)}

\CommentTok{\# Use head() to glance at the first few lines}
\KeywordTok{head}\NormalTok{(baby\_names\_subset)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   Name  Count
##   <chr> <dbl>
## 1 Mary  51474
## 2 Susan 39200
## 3 Linda 37314
## 4 Karen 36376
## 5 Donna 34133
## 6 Lisa  33702
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(baby\_names\_subset, }\DataTypeTok{n =} \DecValTok{6}\NormalTok{) }\CommentTok{\# default is n = 6}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   Name  Count
##   <chr> <dbl>
## 1 Mary  51474
## 2 Susan 39200
## 3 Linda 37314
## 4 Karen 36376
## 5 Donna 34133
## 6 Lisa  33702
\end{verbatim}

\hypertarget{logical-relational-operators}{%
\subsection{Logical \& relational operators}\label{logical-relational-operators}}

In a previous example we used \texttt{==} to filter rows.
Here's a table of other commonly used relational operators:

\begin{longtable}[]{@{}ll@{}}
\toprule
Operator & Meaning\tabularnewline
\midrule
\endhead
\texttt{==} & equal to\tabularnewline
\texttt{!=} & not equal to\tabularnewline
\texttt{\textgreater{}} & greater than\tabularnewline
\texttt{\textgreater{}=} & greater than or equal to\tabularnewline
\texttt{\textless{}} & less than\tabularnewline
\texttt{\textless{}=} & less than or equal to\tabularnewline
\texttt{\%in\%} & contained in\tabularnewline
\bottomrule
\end{longtable}

These relational operators may be combined with logical operators, such as \texttt{\&} (and) or \texttt{\textbar{}} (or).
For example, we can create a \textbf{vector} (a \textbf{container for a collection of values}) and demonstrate
some ways to combine operators:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create a vector of consecutive values between 1 and 10}
\NormalTok{x \textless{}{-}}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{10} \CommentTok{\# a vector}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Which elements of x are above 7}
\NormalTok{x }\OperatorTok{\textgreater{}}\StringTok{ }\DecValTok{7} \CommentTok{\# a simple condition}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Which elements of x are above 7 or below 3}
\NormalTok{x }\OperatorTok{\textgreater{}}\StringTok{ }\DecValTok{7} \OperatorTok{|}\StringTok{ }\NormalTok{x }\OperatorTok{\textless{}}\StringTok{ }\DecValTok{3} \CommentTok{\# two conditions combined}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE
\end{verbatim}

If we want to match multiple elements from two vectors we can use the \texttt{\%in\%} operator:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# x \%in\% vector}
\CommentTok{\# elements of x matching numbers 1, 5, or 10 }
\NormalTok{x }\OperatorTok{\%in\%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE
\end{verbatim}

Notice that logical and relational operators return \textbf{logical vectors} of \texttt{TRUE} and \texttt{FALSE} values.
The logical vectors returned by these operators can themselves be operated on by functions:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Count the number of elements of x above 7}
\NormalTok{x }\OperatorTok{\textgreater{}}\StringTok{ }\DecValTok{7}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(x }\OperatorTok{\textgreater{}}\StringTok{ }\DecValTok{7}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3
\end{verbatim}

\hypertarget{exercise-2.1}{%
\subsection{Exercise 2.1}\label{exercise-2.1}}

\textbf{Peak popularity of your name}

In this exercise you will discover the year your name reached its maximum popularity.

Read in the ``babyNames.csv'' file if you have not already done so,
assigning the result to \texttt{baby\_names}. Make sure you have installed
the \texttt{tidyverse} suite of packages and attached them with \texttt{library(tidyverse)}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Use \texttt{filter} to extract data for your name (or another name of your choice).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\item
  Arrange the data you produced in step 1 above by \texttt{Count}.
  In which year was the name most popular?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\item
  BONUS (optional): Filter the data to extract \emph{only} the
  row containing the most popular boys name in 1999.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

{Click for Exercise 2.1 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Use \texttt{filter} to extract data for your name (or another name of your choice).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{baby\_names\_george \textless{}{-}}\StringTok{ }\KeywordTok{filter}\NormalTok{(baby\_names, Name }\OperatorTok{==}\StringTok{ "George"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\item
  Arrange the data you produced in step 1 above by \texttt{Count}. In which year was the name most popular?

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{arrange}\NormalTok{(baby\_names\_george, }\KeywordTok{desc}\NormalTok{(Count))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 97 x 4
##    Name   Sex   Count  Year
##    <chr>  <chr> <dbl> <dbl>
##  1 George Boys  14063  1960
##  2 George Boys  13638  1961
##  3 George Boys  12553  1962
##  4 George Boys  12084  1963
##  5 George Boys  11793  1964
##  6 George Boys  10683  1965
##  7 George Boys   9942  1966
##  8 George Boys   9702  1967
##  9 George Boys   9388  1968
## 10 George Boys   9203  1969
## # ... with 87 more rows
\end{verbatim}
\item
  BONUS (optional): Filter the data to extract \emph{only} the row containing the most popular boys name in 1999.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{baby\_names\_boys\_}\DecValTok{1999}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{filter}\NormalTok{(baby\_names,}
\NormalTok{                               Year }\OperatorTok{==}\StringTok{ }\DecValTok{1999} \OperatorTok{\&}\StringTok{ }\NormalTok{Sex }\OperatorTok{==}\StringTok{ "Boys"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{filter}\NormalTok{(baby\_names\_boys\_}\DecValTok{1999}\NormalTok{, Count }\OperatorTok{==}\StringTok{ }\KeywordTok{max}\NormalTok{(Count))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 4
##   Name  Sex   Count  Year
##   <chr> <chr> <dbl> <dbl>
## 1 Jacob Boys  35361  1999
\end{verbatim}
\end{enumerate}

\end{alert}

\hypertarget{pipe-operator}{%
\subsection{Pipe operator}\label{pipe-operator}}

There is one very special operator in R called a \textbf{pipe} operator that
looks like this: \texttt{\%\textgreater{}\%}. It allows us to ``chain'' several function calls and,
as each function returns an object, feed it into the next call in a single
statement, without needing extra variables to store the intermediate
results. The point of the pipe is to help you write code in a way that is
easier to read and understand as we will see below.

\includegraphics{R/Rintro/images/magrittr.png}

There is no need to load any additional packages as the operator is made
available via the \texttt{magrittr} package installed as part of \texttt{tidyverse}. Let's
rewrite the sequence of commands to output ordered counts for names
``Alex'' or ``Mark''.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Filter data keeping rows for "Alex" and "Mark" during year 1992, record in baby\_names\_alexmark}
\CommentTok{\# Arrange the result in a descending order by Count}
\CommentTok{\# unpiped version}
\NormalTok{baby\_names\_alexmark \textless{}{-}}\StringTok{ }\KeywordTok{filter}\NormalTok{(baby\_names, Year }\OperatorTok{==}\StringTok{ }\DecValTok{1992} \OperatorTok{\&}\StringTok{ }\NormalTok{(Name }\OperatorTok{==}\StringTok{ "Alex"} \OperatorTok{|}\StringTok{ }\NormalTok{Name }\OperatorTok{==}\StringTok{ "Mark"}\NormalTok{))}
\KeywordTok{arrange}\NormalTok{(baby\_names\_alexmark, }\KeywordTok{desc}\NormalTok{(Count))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 4
##   Name  Sex   Count  Year
##   <chr> <chr> <dbl> <dbl>
## 1 Mark  Boys   8743  1992
## 2 Alex  Boys   7348  1992
## 3 Alex  Girls   366  1992
## 4 Mark  Girls    20  1992
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# piped version}
\NormalTok{baby\_names }\OperatorTok{\%\textgreater{}\%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(Year }\OperatorTok{==}\StringTok{ }\DecValTok{1992} \OperatorTok{\&}\StringTok{ }\NormalTok{(Name }\OperatorTok{==}\StringTok{ "Alex"} \OperatorTok{|}\StringTok{ }\NormalTok{Name }\OperatorTok{==}\StringTok{ "Mark"}\NormalTok{)) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(Count))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 4
##   Name  Sex   Count  Year
##   <chr> <chr> <dbl> <dbl>
## 1 Mark  Boys   8743  1992
## 2 Alex  Boys   7348  1992
## 3 Alex  Girls   366  1992
## 4 Mark  Girls    20  1992
\end{verbatim}

Hint: try pronouncing ``then'' whenever you see \texttt{\%\textgreater{}\%}. Using pseudocode,
we can see what the pipe is doing:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# unpiped version}
\KeywordTok{filter}\NormalTok{(dataset, condition)}

\CommentTok{\# piped version}
\NormalTok{dataset }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{filter}\NormalTok{(condition)}

\CommentTok{\# what the pipe is doing}
\NormalTok{output\_of\_thing\_on\_left }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\NormalTok{becomes\_input\_of\_thing\_on\_right}
\end{Highlighting}
\end{Shaded}

Advantages of using the pipe:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We can avoid creating intermediate variables, such as \texttt{baby\_names\_alexmark}
\item
  Less to type
\item
  Easier to read and follow the logic (especially avoiding using nested functions)
\end{enumerate}

\hypertarget{exercise-2.2}{%
\subsection{Exercise 2.2}\label{exercise-2.2}}

Rewrite the solution to Exercise 2.1 using pipes. Remember that we were looking
for the year your name reached its maximum popularity. For that, we filtered
the data and then arranged by \texttt{Count}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Use filter to extract data for your name (or another name of your choice)}
\CommentTok{\# Arrange the data by Count}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 2.2 Solution}

\begin{alert}

Rewrite the solution to Exercise 2.1 using pipes.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Use filter to extract data for your name (or another name of your choice)}
\CommentTok{\# Arrange the data by Count}
\NormalTok{baby\_names }\OperatorTok{\%\textgreater{}\%}\StringTok{ }
\StringTok{    }\KeywordTok{filter}\NormalTok{(Name }\OperatorTok{==}\StringTok{ "George"}\NormalTok{) }\OperatorTok{\%\textgreater{}\%}
\StringTok{    }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(Count))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 97 x 4
##    Name   Sex   Count  Year
##    <chr>  <chr> <dbl> <dbl>
##  1 George Boys  14063  1960
##  2 George Boys  13638  1961
##  3 George Boys  12553  1962
##  4 George Boys  12084  1963
##  5 George Boys  11793  1964
##  6 George Boys  10683  1965
##  7 George Boys   9942  1966
##  8 George Boys   9702  1967
##  9 George Boys   9388  1968
## 10 George Boys   9203  1969
## # ... with 87 more rows
\end{verbatim}

\end{alert}

\hypertarget{plotting-data}{%
\section{Plotting data}\label{plotting-data}}

\begin{alert}

\textbf{GOAL: Plot baby name trends over time -- using the \texttt{qplot()} function}

\end{alert}

It can be difficult to spot trends when looking at summary tables.
Plotting the data makes it easier to identify interesting patterns.

R has decent plotting tools built-in -- see e.g., \texttt{help(plot)}.
However, again, we will make use of a \emph{contributed
package} from \texttt{tidyverse} called \texttt{ggplot2}.

For quick and simple plots we can use the \texttt{qplot()} function from \texttt{ggplot2}. For example,
we can plot the number of babies given the name ``Diana'' over time like this:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Filter data keeping rows for name "Diana" and assign to a new object called baby\_names\_diana}
\NormalTok{baby\_names\_diana \textless{}{-}}\StringTok{ }\KeywordTok{filter}\NormalTok{(baby\_names, Name }\OperatorTok{==}\StringTok{ "Diana"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Use qplot() function to plot Counts (y) by Year (x)}
\KeywordTok{qplot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Year, }\DataTypeTok{y =}\NormalTok{ Count,}
     \DataTypeTok{data =}\NormalTok{ baby\_names\_diana)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rintro/figures/unnamed-chunk-42-1.pdf}

Interestingly, there are usually some gender-atypical names, even for very strongly
gendered names like ``Diana''. Splitting these trends out by \texttt{Sex} is very easy:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Use qplot() function to plot Counts (y) by Year (x). Split trends by Sex using color.}
\KeywordTok{qplot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Year, }\DataTypeTok{y =}\NormalTok{ Count, }\DataTypeTok{color =}\NormalTok{ Sex,}
      \DataTypeTok{data =}\NormalTok{ baby\_names\_diana)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rintro/figures/unnamed-chunk-43-1.pdf}

\hypertarget{exercise-3}{%
\subsection{Exercise 3}\label{exercise-3}}

\textbf{Plot peak popularity of your name}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Use \texttt{filter} to extract data for your name (same as previous exercise)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\item
  Plot the data you produced in step 1 above, with \texttt{Year} on the x-axis
  and \texttt{Count} on the y-axis.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\item
  Adjust the plot so that is shows boys and girls in different colors.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\item
  BONUS (Optional): Adjust the plot to use lines instead of points.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

{Click for Exercise 3 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Use \texttt{filter()} to extract data for your name (same as previous exercise).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{baby\_names\_george \textless{}{-}}\StringTok{ }\KeywordTok{filter}\NormalTok{(baby\_names, Name }\OperatorTok{==}\StringTok{ "George"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\item
  Plot the data you produced in step 1 above, with \texttt{Year} on the x-axis and \texttt{Count} on the y-axis.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qplot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Year, }\DataTypeTok{y =}\NormalTok{ Count, }\DataTypeTok{data =}\NormalTok{ baby\_names\_george)}
\end{Highlighting}
\end{Shaded}

  \includegraphics{R/Rintro/figures/unnamed-chunk-49-1.pdf}
\item
  Adjust the plot so that is shows boys and girls in different colors.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qplot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Year, }\DataTypeTok{y =}\NormalTok{ Count, }\DataTypeTok{color =}\NormalTok{ Sex, }\DataTypeTok{data =}\NormalTok{ baby\_names\_george)}
\end{Highlighting}
\end{Shaded}

  \includegraphics{R/Rintro/figures/unnamed-chunk-50-1.pdf}
\item
  BONUS (Optional): Adjust the plot to use lines instead of points.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qplot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Year, }\DataTypeTok{y =}\NormalTok{ Count, }\DataTypeTok{color =}\NormalTok{ Sex, }\DataTypeTok{data =}\NormalTok{ baby\_names\_george, }\DataTypeTok{geom =} \StringTok{"line"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

  \includegraphics{R/Rintro/figures/unnamed-chunk-51-1.pdf}
\end{enumerate}

\end{alert}

\hypertarget{creating-variables}{%
\section{Creating variables}\label{creating-variables}}

\begin{alert}

\textbf{GOAL: To learn how to create new variables with and without grouped data.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Creating new variables (columns) --- using the \texttt{mutate()} function
\item
  Creating new variables within groups --- by combining the \texttt{mutate()} and \texttt{group\_by()} functions
\item
  Recode existing variables --- by combining the \texttt{mutate()} and \texttt{case\_when()} functions
\end{enumerate}

\end{alert}

We want to use these skills to find out which names have been the most popular.

\hypertarget{create-or-modify-columns}{%
\subsection{Create or modify columns}\label{create-or-modify-columns}}

So far we've used \texttt{Count} as a measure of popularity. A better
approach is to use proportion to avoid confounding
popularity with the number of babies born in a given year.

The \texttt{mutate()} function makes it easy to add or modify the columns
of a \texttt{data.frame}. For example, we can use it to rescale the count
of each name in each year:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Use piping to add a new column to the data, called Count\_1k, that rescales counts to thousands}
\NormalTok{baby\_names \textless{}{-}}\StringTok{ }\NormalTok{baby\_names }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{Count\_1k =}\NormalTok{ Count}\OperatorTok{/}\DecValTok{1000}\NormalTok{)}
\KeywordTok{head}\NormalTok{(baby\_names) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 5
##   Name  Sex   Count  Year Count_1k
##   <chr> <chr> <dbl> <dbl>    <dbl>
## 1 Mary  Girls 51474  1960     51.5
## 2 Susan Girls 39200  1960     39.2
## 3 Linda Girls 37314  1960     37.3
## 4 Karen Girls 36376  1960     36.4
## 5 Donna Girls 34133  1960     34.1
## 6 Lisa  Girls 33702  1960     33.7
\end{verbatim}

\hypertarget{operating-by-group}{%
\subsection{Operating by group}\label{operating-by-group}}

Because of the nested nature of our data, we want to compute proportion
or rank \textbf{within} each \texttt{Sex} by \texttt{Year} group. The \texttt{dplyr}
package has a \texttt{group\_by()} function that makes this relatively
straightforward. Here's the logic behind this process:

\includegraphics{R/Rintro/images/mutate_group_by.png}

Note that the \texttt{group\_by()} function converts a \textbf{data frame} into a
\textbf{grouped data frame} --- that is, a data frame with metadata identifying
the groups. The data remain grouped until you change the groups by
running \texttt{group\_by()} again or remove the grouping metadata using
\texttt{ungroup()}.

Here's the code that implements the calculation:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Group baby\_names by Year and Sex and rank Count\_1k within each group (calling the resulting new column "Rank"). }
\CommentTok{\# Remember to ungroup at the end!}
\NormalTok{baby\_names \textless{}{-}}
\StringTok{  }\NormalTok{baby\_names }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{group\_by}\NormalTok{(Year, Sex) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{Rank =} \KeywordTok{rank}\NormalTok{(Count\_1k)) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{()}

\KeywordTok{head}\NormalTok{(baby\_names)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 6
##   Name  Sex   Count  Year Count_1k  Rank
##   <chr> <chr> <dbl> <dbl>    <dbl> <dbl>
## 1 Mary  Girls 51474  1960     51.5  7331
## 2 Susan Girls 39200  1960     39.2  7330
## 3 Linda Girls 37314  1960     37.3  7329
## 4 Karen Girls 36376  1960     36.4  7328
## 5 Donna Girls 34133  1960     34.1  7327
## 6 Lisa  Girls 33702  1960     33.7  7326
\end{verbatim}

\hypertarget{recoding-variables}{%
\subsection{Recoding variables}\label{recoding-variables}}

It's often necessary to create a new variable that is a recoded version of an existing variable.
For example, we might want to take our \texttt{Count\_1k} variable and create a new variable that divides
it into \texttt{low}, \texttt{medium}, and \texttt{high} categories. To do this, we can use the \texttt{case\_when()}
function within the \texttt{mutate()} function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Use case\_when() to recode the newly created Rank column into low (\textless{}=10), high (\textgreater{}40), and medium (all others).}
\CommentTok{\# Call the resulting column "Count\_levels".}
\NormalTok{baby\_names \textless{}{-}}
\StringTok{  }\NormalTok{baby\_names }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{Count\_levels =} \KeywordTok{case\_when}\NormalTok{(}
\NormalTok{                            Count\_1k }\OperatorTok{\textless{}=}\StringTok{ }\DecValTok{10}                  \OperatorTok{\textasciitilde{}}\StringTok{ "low"}\NormalTok{,}
\NormalTok{                            Count\_1k  }\OperatorTok{\textgreater{}}\StringTok{ }\DecValTok{10} \OperatorTok{\&}\StringTok{ }\NormalTok{Count\_1k }\OperatorTok{\textless{}=}\StringTok{ }\DecValTok{40} \OperatorTok{\textasciitilde{}}\StringTok{ "medium"}\NormalTok{,}
\NormalTok{                            Count\_1k  }\OperatorTok{\textgreater{}}\StringTok{ }\DecValTok{40}                  \OperatorTok{\textasciitilde{}}\StringTok{ "high"}
\NormalTok{                            ))}

\KeywordTok{head}\NormalTok{(baby\_names)                            }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 7
##   Name  Sex   Count  Year Count_1k  Rank Count_levels
##   <chr> <chr> <dbl> <dbl>    <dbl> <dbl> <chr>       
## 1 Mary  Girls 51474  1960     51.5  7331 high        
## 2 Susan Girls 39200  1960     39.2  7330 medium      
## 3 Linda Girls 37314  1960     37.3  7329 medium      
## 4 Karen Girls 36376  1960     36.4  7328 medium      
## 5 Donna Girls 34133  1960     34.1  7327 medium      
## 6 Lisa  Girls 33702  1960     33.7  7326 medium
\end{verbatim}

\hypertarget{exercise-4}{%
\subsection{Exercise 4}\label{exercise-4}}

\textbf{Most popular names}

In this exercise your goal is to identify the most popular names for each year.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Use \texttt{mutate()} and \texttt{group\_by()} to create a column named \texttt{Proportion}
  where \texttt{Proportion\ =\ Count/sum(Count)} for each \texttt{Year\ X\ Sex} group.
  Use pipes wherever it makes sense.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\item
  Use \texttt{mutate()} and \texttt{group\_by()} to create a column named \texttt{Rank} where
  \texttt{Rank\ =\ rank(desc(Count))} for each \texttt{Year\ X\ Sex} group.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\item
  Filter the baby names data to display only the most popular name
  for each \texttt{Year\ X\ Sex} group. Keep only the columns: \texttt{Year}, \texttt{Name},
  \texttt{Sex}, and \texttt{Proportion}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\item
  Plot the data produced in step 3, putting \texttt{Year} on the x-axis
  and \texttt{Proportion} on the y-axis. How has the proportion of babies
  given the most popular name changed over time?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\item
  BONUS (optional): Which names are the most popular for both boys and girls?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

{Click for Exercise 4 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Use \texttt{mutate()} and \texttt{group\_by()} to create a column named \texttt{Proportion} where \texttt{Proportion\ =\ Count/sum(Count)} for each \texttt{Year\ X\ Sex} group.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{baby\_names \textless{}{-}}\StringTok{ }
\StringTok{  }\NormalTok{baby\_names }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{group\_by}\NormalTok{(Year, Sex) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{Proportion =}\NormalTok{ Count}\OperatorTok{/}\KeywordTok{sum}\NormalTok{(Count)) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{()}

\KeywordTok{head}\NormalTok{(baby\_names) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 8
##   Name  Sex   Count  Year Count_1k  Rank Count_levels Proportion
##   <chr> <chr> <dbl> <dbl>    <dbl> <dbl> <chr>             <dbl>
## 1 Mary  Girls 51474  1960     51.5  7331 high             0.0255
## 2 Susan Girls 39200  1960     39.2  7330 medium           0.0194
## 3 Linda Girls 37314  1960     37.3  7329 medium           0.0185
## 4 Karen Girls 36376  1960     36.4  7328 medium           0.0180
## 5 Donna Girls 34133  1960     34.1  7327 medium           0.0169
## 6 Lisa  Girls 33702  1960     33.7  7326 medium           0.0167
\end{verbatim}
\item
  Use \texttt{mutate()} and \texttt{group\_by()} to create a column named \texttt{Rank} where \texttt{Rank\ =\ rank(desc(Count))} for each \texttt{Year\ X\ Sex} group.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{baby\_names \textless{}{-}}\StringTok{ }
\StringTok{  }\NormalTok{baby\_names }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{group\_by}\NormalTok{(Year, Sex) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{Rank =} \KeywordTok{rank}\NormalTok{(}\KeywordTok{desc}\NormalTok{(Count))) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{()}

\KeywordTok{head}\NormalTok{(baby\_names)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 8
##   Name  Sex   Count  Year Count_1k  Rank Count_levels Proportion
##   <chr> <chr> <dbl> <dbl>    <dbl> <dbl> <chr>             <dbl>
## 1 Mary  Girls 51474  1960     51.5     1 high             0.0255
## 2 Susan Girls 39200  1960     39.2     2 medium           0.0194
## 3 Linda Girls 37314  1960     37.3     3 medium           0.0185
## 4 Karen Girls 36376  1960     36.4     4 medium           0.0180
## 5 Donna Girls 34133  1960     34.1     5 medium           0.0169
## 6 Lisa  Girls 33702  1960     33.7     6 medium           0.0167
\end{verbatim}
\item
  Filter the baby names data to display only the most popular name for each \texttt{Year\ X\ Sex} group.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top1 \textless{}{-}}\StringTok{ }
\StringTok{  }\NormalTok{baby\_names }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(Rank }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{select}\NormalTok{(Year, Name, Sex, Proportion)}

\KeywordTok{head}\NormalTok{(top1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 4
##    Year Name    Sex   Proportion
##   <dbl> <chr>   <chr>      <dbl>
## 1  1960 Mary    Girls     0.0255
## 2  1960 David   Boys      0.0403
## 3  1961 Mary    Girls     0.0236
## 4  1961 Michael Boys      0.0409
## 5  1962 Lisa    Girls     0.0234
## 6  1962 Michael Boys      0.0411
\end{verbatim}
\item
  Plot the data produced in step 3, putting \texttt{Year} on the x-axis and \texttt{Proportion} on the y-axis. How has the proportion of babies given the most popular name changed over time?

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qplot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Year, }
      \DataTypeTok{y =}\NormalTok{ Proportion, }
      \DataTypeTok{color =}\NormalTok{ Sex, }
      \DataTypeTok{data =}\NormalTok{ top1, }
      \DataTypeTok{geom =} \StringTok{"line"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

  \includegraphics{R/Rintro/figures/unnamed-chunk-63-1.pdf}
\item
  BONUS (optional): Which names are the most popular for both boys and girls?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{girls\_and\_boys \textless{}{-}}\StringTok{ }\KeywordTok{inner\_join}\NormalTok{(}\KeywordTok{filter}\NormalTok{(baby\_names, Sex }\OperatorTok{==}\StringTok{ "Boys"}\NormalTok{), }
                            \KeywordTok{filter}\NormalTok{(baby\_names, Sex }\OperatorTok{==}\StringTok{ "Girls"}\NormalTok{),}
                            \DataTypeTok{by =} \KeywordTok{c}\NormalTok{(}\StringTok{"Year"}\NormalTok{, }\StringTok{"Name"}\NormalTok{))}

\NormalTok{girls\_and\_boys \textless{}{-}}\StringTok{ }\KeywordTok{mutate}\NormalTok{(girls\_and\_boys,}
                        \DataTypeTok{Product =}\NormalTok{ Count.x }\OperatorTok{*}\StringTok{ }\NormalTok{Count.y,}
                        \DataTypeTok{Rank =} \KeywordTok{rank}\NormalTok{(}\KeywordTok{desc}\NormalTok{(Product)))}

\KeywordTok{filter}\NormalTok{(girls\_and\_boys, Rank }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 16
##   Name  Sex.x Count.x  Year Count_1k.x Rank.x Count_levels.x Proportion.x Sex.y
##   <chr> <chr>   <dbl> <dbl>      <dbl>  <dbl> <chr>                 <dbl> <chr>
## 1 Tayl~ Boys     7688  1993       7.69     51 low                 0.00392 Girls
## # ... with 7 more variables: Count.y <dbl>, Count_1k.y <dbl>, Rank.y <dbl>,
## #   Count_levels.y <chr>, Proportion.y <dbl>, Product <dbl>, Rank <dbl>
\end{verbatim}
\end{enumerate}

\end{alert}

\hypertarget{aggregating-variables}{%
\section{Aggregating variables}\label{aggregating-variables}}

\begin{alert}

\textbf{GOAL: To learn how to aggregate data to create summaries with and without grouped data.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Collapsing data into summaries --- using the \texttt{summarize()} function
\item
  Creating summaries within groups --- by combining the \texttt{summarize()} and \texttt{group\_by()} functions
\end{enumerate}

\end{alert}

You may have noticed that the percentage of babies given the most
popular name of the year appears to have decreased over time. We can
compute a more robust measure of the popularity of the most popular
names by calculating the number of babies given one of the top 10 girl
or boy names of the year.

To compute this measure we need to operate within groups, as
we did using \texttt{mutate()} above, but this time we need to collapse each
group into a single summary statistic. We can achieve this using the
\texttt{summarize()} function.

First, let's see how this function works without grouping. The following
code outputs the total number of girls and boys in the data:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Use summarize() to output the total number of boys and girls in the sample}
\NormalTok{baby\_names }\OperatorTok{\%\textgreater{}\%}\StringTok{ }
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{Girls\_n =} \KeywordTok{sum}\NormalTok{(Sex}\OperatorTok{==}\StringTok{"Girls"}\NormalTok{),}
            \DataTypeTok{Boys\_n =} \KeywordTok{sum}\NormalTok{(Sex}\OperatorTok{==}\StringTok{"Boys"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 2
##   Girls_n Boys_n
##     <int>  <int>
## 1  641084 407491
\end{verbatim}

Next, using \texttt{group\_by()} and \texttt{summarize()} together, we can calculate the
number of babies born each year. Here's the logic behind this process:

\includegraphics{R/Rintro/images/summarize_group_by.png}

Note that, unlike with the \texttt{mutate()} function, the \texttt{summarize()} function returns a data frame
with fewer rows than the original, because of aggregation.

Here's the code that implements the calculation:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Group baby\_names by Year and calculate the sum of Count (record in a column called Total). }
\CommentTok{\# Assign the result to bn\_by\_year and remember to ungroup!}
\NormalTok{bn\_by\_year \textless{}{-}}
\StringTok{  }\NormalTok{baby\_names }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{group\_by}\NormalTok{(Year) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{Total =} \KeywordTok{sum}\NormalTok{(Count)) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{()}

\KeywordTok{head}\NormalTok{(bn\_by\_year)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##    Year   Total
##   <dbl>   <dbl>
## 1  1960 4154377
## 2  1961 4140244
## 3  1962 4035234
## 4  1963 3958791
## 5  1964 3887800
## 6  1965 3626029
\end{verbatim}

\hypertarget{exercise-5}{%
\subsection{Exercise 5}\label{exercise-5}}

\textbf{Popularity of the most popular names}

In this exercise we will plot trends in the proportion of boys and girls
given one of the 10 most popular names each year.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Filter the \texttt{baby\_names} data, retaining only the 10 most popular girl
  and boy names for each year.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\item
  Summarize the data produced in step one to calculate the total
  Proportion of boys and girls given one of the top 10 names
  each year.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\item
  Plot the data produced in step 2, with year on the x-axis
  and total proportion on the y axis. Color by \texttt{Sex} and notice
  the trend.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}
\end{enumerate}

{Click for Exercise 5 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Filter the baby\_names data, retaining only the 10 most popular girl and boy names for each year.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{most\_popular \textless{}{-}}\StringTok{ }
\StringTok{  }\NormalTok{baby\_names }\OperatorTok{\%\textgreater{}\%}\StringTok{ }
\StringTok{  }\KeywordTok{group\_by}\NormalTok{(Year, Sex) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(Rank }\OperatorTok{\textless{}=}\StringTok{ }\DecValTok{10}\NormalTok{)}

\KeywordTok{head}\NormalTok{(most\_popular, }\DataTypeTok{n =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 8
## # Groups:   Year, Sex [1]
##    Name     Sex   Count  Year Count_1k  Rank Count_levels Proportion
##    <chr>    <chr> <dbl> <dbl>    <dbl> <dbl> <chr>             <dbl>
##  1 Mary     Girls 51474  1960     51.5     1 high             0.0255
##  2 Susan    Girls 39200  1960     39.2     2 medium           0.0194
##  3 Linda    Girls 37314  1960     37.3     3 medium           0.0185
##  4 Karen    Girls 36376  1960     36.4     4 medium           0.0180
##  5 Donna    Girls 34133  1960     34.1     5 medium           0.0169
##  6 Lisa     Girls 33702  1960     33.7     6 medium           0.0167
##  7 Patricia Girls 32102  1960     32.1     7 medium           0.0159
##  8 Debra    Girls 26737  1960     26.7     8 medium           0.0132
##  9 Cynthia  Girls 26725  1960     26.7     9 medium           0.0132
## 10 Deborah  Girls 25264  1960     25.3    10 medium           0.0125
\end{verbatim}
\item
  Summarize the data produced in step one to calculate the total Proportion of boys and girls given one of the top 10 names each year.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top10 \textless{}{-}}\StringTok{ }
\StringTok{  }\NormalTok{most\_popular }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\CommentTok{\# it is already grouped by Year and Sex}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{TotalProportion =} \KeywordTok{sum}\NormalTok{(Proportion))}
\end{Highlighting}
\end{Shaded}
\item
  Plot the data produced in step 2, with year on the x-axis and total proportion on the y axis. Color by \texttt{Sex} and notice
  the trend.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{qplot}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Year, }
      \DataTypeTok{y =}\NormalTok{ TotalProportion, }
      \DataTypeTok{color =}\NormalTok{ Sex,}
      \DataTypeTok{data =}\NormalTok{ top10,}
      \DataTypeTok{geom =} \StringTok{"line"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

  \includegraphics{R/Rintro/figures/unnamed-chunk-72-1.pdf}
\end{enumerate}

\end{alert}

\hypertarget{saving-work}{%
\section{Saving work}\label{saving-work}}

\begin{alert}

\textbf{GOAL: To learn how to save objects, data, and scripts for later use.}

\end{alert}

Now that we have made some changes to our data set, we might want to
save those changes to a file.

\hypertarget{saving-individual-datasets}{%
\subsection{Saving individual datasets}\label{saving-individual-datasets}}

You might find functions \texttt{write\_csv()} and \texttt{write\_rds()} from package
\texttt{readr} handy!

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# write baby\_names to a .csv file}
\KeywordTok{write\_csv}\NormalTok{(baby\_names, }\StringTok{"babyNames.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# write baby\_names to an R file}
\KeywordTok{write\_rds}\NormalTok{(baby\_names, }\StringTok{"babyNames.rds"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{saving-multiple-datasets}{%
\subsection{Saving multiple datasets}\label{saving-multiple-datasets}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ls}\NormalTok{() }\CommentTok{\# list objects in our workspace}
\CommentTok{\# Use save() function from the base R package to record some objects into a file named "myDataFiles.RData"}
\KeywordTok{save}\NormalTok{(baby\_names\_diana, bn\_by\_year, baby\_names\_subset, }\DataTypeTok{file=}\StringTok{"myDataFiles.RData"}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load the "myDataFiles.RData"}
\CommentTok{\# load("myDataFiles.RData") }
\end{Highlighting}
\end{Shaded}

\hypertarget{wrap-up-1}{%
\section{Wrap-up}\label{wrap-up-1}}

\hypertarget{feedback-1}{%
\subsection{Feedback}\label{feedback-1}}

These workshops are a work-in-progress, please provide any feedback to: \href{mailto:help@iq.harvard.edu}{\nolinkurl{help@iq.harvard.edu}}

\hypertarget{resources-2}{%
\subsection{Resources}\label{resources-2}}

\begin{itemize}
\tightlist
\item
  IQSS

  \begin{itemize}
  \tightlist
  \item
    Workshops: \url{https://dss.iq.harvard.edu/workshop-materials}
  \item
    Data Science Services: \url{https://dss.iq.harvard.edu/}
  \item
    Research Computing Environment: \url{https://iqss.github.io/dss-rce/}
  \end{itemize}
\item
  HBS

  \begin{itemize}
  \tightlist
  \item
    Research Computing Services workshops: \url{https://training.rcs.hbs.org/workshops}
  \item
    Other HBS RCS resources: \url{https://training.rcs.hbs.org/workshop-materials}
  \item
    RCS consulting email: \url{mailto:research@hbs.edu}
  \end{itemize}
\item
  Software (all free!):

  \begin{itemize}
  \tightlist
  \item
    R and R package download: \url{http://cran.r-project.org}
  \item
    RStudio download: \url{http://rstudio.org}
  \item
    ESS (Emacs R package): \url{http://ess.r-project.org/}
  \end{itemize}
\item
  Cheatsheets

  \begin{itemize}
  \tightlist
  \item
    \url{https://rstudio.com/wp-content/uploads/2019/01/Cheatsheets_2019.pdf}
  \end{itemize}
\item
  Online tutorials

  \begin{itemize}
  \tightlist
  \item
    \url{https://swirlstats.com/}
  \item
    \url{https://r4ds.had.co.nz/}
  \item
    \url{https://hbs-rcs.github.io/R_Intro-gapminder/base-r/}
  \item
    \url{https://www.pluralsight.com/search?q=R}
  \item
    \url{https://www.datacamp.com/}
  \item
    \url{https://rmarkdown.rstudio.com/lesson-1.html}
  \end{itemize}
\item
  Getting help:

  \begin{itemize}
  \tightlist
  \item
    Documentation and tutorials: \url{http://cran.r-project.org/other-docs.html}
  \item
    Recommended R packages by topic: \url{http://cran.r-project.org/web/views/}
  \item
    Mailing list: \url{https://stat.ethz.ch/mailman/listinfo/r-help}
  \item
    StackOverflow: \url{http://stackoverflow.com/questions/tagged/r}
  \item
    R-Bloggers: \url{https://www.r-bloggers.com/}
  \end{itemize}
\item
  Coming from \ldots{}

  \begin{itemize}
  \tightlist
  \item
    Stata: \url{http://www.princeton.edu/~otorres/RStata.pdf}
  \item
    SAS/SPSS: \url{http://r4stats.com/books/free-version/}
  \item
    Matlab: \url{http://www.math.umaine.edu/~hiebeler/comp/matlabR.pdf}
  \item
    Python: \url{http://mathesaurus.sourceforge.net/matlab-python-xref.pdf}
  \end{itemize}
\end{itemize}

\hypertarget{r-regression-models}{%
\chapter{R Regression Models}\label{r-regression-models}}

\textbf{Topics}

\begin{itemize}
\tightlist
\item
  Formula interface for model specification
\item
  Function methods for extracting quantities of interest from models
\item
  Contrasts to test specific hypotheses
\item
  Model comparisons
\item
  Predicted marginal effects
\end{itemize}

\hypertarget{setup-1}{%
\section{Setup}\label{setup-1}}

\hypertarget{software-and-materials-1}{%
\subsection{Software and Materials}\label{software-and-materials-1}}

Follow the \href{./Rinstall.html}{R Installation} instructions and ensure that you can successfully start RStudio.

\hypertarget{class-structure-1}{%
\subsection{Class Structure}\label{class-structure-1}}

Informal - Ask questions at any time. Really!

Collaboration is encouraged - please spend a minute introducing yourself to your neighbors!

\hypertarget{prerequisites-1}{%
\subsection{Prerequisites}\label{prerequisites-1}}

This is an intermediate R course:

\begin{itemize}
\tightlist
\item
  Assumes working knowledge of R
\item
  Relatively fast-paced
\item
  This is not a statistics course! We will teach you \emph{how} to fit models in R,
  but we assume you know the theory behind the models.
\end{itemize}

\hypertarget{goals-1}{%
\subsection{Goals}\label{goals-1}}

\begin{alert}

We will learn about the R modeling ecosystem by fitting a variety of statistical models to
different datasets. In particular, our goals are to learn about:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Modeling workflow
\item
  Visualizing and summarizing data before modeling
\item
  Modeling continuous outcomes
\item
  Modeling binary outcomes
\item
  Modeling clustered data
\end{enumerate}

We will not spend much time \emph{interpreting} the models we fit, since this is not a statistics workshop.
But, we will walk you through how model results are organized and orientate you to where you can find
typical quantities of interest.

\end{alert}

\hypertarget{launch-an-r-session}{%
\subsection{Launch an R session}\label{launch-an-r-session}}

Start RStudio and create a new project:

\begin{itemize}
\tightlist
\item
  On Windows click the start button and search for RStudio. On Mac
  RStudio will be in your applications folder.
\item
  In Rstudio go to \texttt{File\ -\textgreater{}\ New\ Project}.
\item
  Choose \texttt{Existing\ Directory} and browse to the workshop materials directory on your desktop.
\item
  Choose \texttt{File\ -\textgreater{}\ Open\ File} and select the file with the word ``BLANK'' in the name.
\end{itemize}

\hypertarget{packages}{%
\subsection{Packages}\label{packages}}

You should have already installed the \texttt{tidyverse} and \texttt{rmarkdown}
packages onto your computer before the workshop
--- see \href{./Rinstall.html}{R Installation}.
Now let's load these packages into the search path of our R session.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(rmarkdown)}
\end{Highlighting}
\end{Shaded}

Finally, lets install some packages that will help with modeling:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages("lme4")}
\KeywordTok{library}\NormalTok{(lme4)  }\CommentTok{\# for mixed models}

\CommentTok{\# install.packages("emmeans")}
\KeywordTok{library}\NormalTok{(emmeans)  }\CommentTok{\# for marginal effects}

\CommentTok{\# install.packages("effects")}
\KeywordTok{library}\NormalTok{(effects)  }\CommentTok{\# for predicted marginal means}
\end{Highlighting}
\end{Shaded}

\hypertarget{modeling-workflow}{%
\section{Modeling workflow}\label{modeling-workflow}}

Before we delve into the details of how to fit models in R, it's worth taking a step
back and thinking more broadly about the components of the modeling process. These
can roughly be divided into 3 stages:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Pre-estimation
\item
  Estimation
\item
  Post-estimaton
\end{enumerate}

At each stage, the goal is to complete a different task (e.g., to clean data, fit a model, test a hypothesis),
but the process is sequential --- we move through the stages in order (though often many times in one project!)

\includegraphics{R/Rmodels/images/R_model_pipeline.png}

Throughout this workshop we will go through these stages several times as we fit different types of model.

\hypertarget{r-modeling-ecosystem}{%
\section{R modeling ecosystem}\label{r-modeling-ecosystem}}

There are literally hundreds of R packages that provide model fitting functionality.
We're going to focus on just two during this workshop --- \texttt{stats}, from Base R, and
\texttt{lme4}. It's a good idea to look at \href{https://cran.r-project.org/web/views/}{CRAN Task Views}
when trying to find a modeling package for your needs, as they provide an extensive
curated list. But, here's a more digestable table showing some of the most popular
packages for particular types of model.

\begin{longtable}[]{@{}ll@{}}
\toprule
Models & Packages\tabularnewline
\midrule
\endhead
Generalized linear & \texttt{stats}, \texttt{biglm}, \texttt{MASS}, \texttt{robustbase}\tabularnewline
Mixed effects & \texttt{lme4}, \texttt{nlme}, \texttt{glmmTMB}, \texttt{MASS}\tabularnewline
Econometric & \texttt{pglm}, \texttt{VGAM}, \texttt{pscl}, \texttt{survival}\tabularnewline
Bayesian & \texttt{brms}, \texttt{blme}, \texttt{MCMCglmm}, \texttt{rstan}\tabularnewline
Machine learning & \texttt{mlr}, \texttt{caret}, \texttt{h2o}, \texttt{tensorflow}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{before-fitting-a-model}{%
\section{Before fitting a model}\label{before-fitting-a-model}}

\begin{alert}

\textbf{GOAL: To learn about the data by creating summaries and visualizations.}

\end{alert}

One important part of the pre-estimation stage of model fitting, is gaining an understanding
of the data we wish to model by creating plots and summaries. Let's do this now.

\hypertarget{load-the-data}{%
\subsection{Load the data}\label{load-the-data}}

List the data files we're going to work with:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{list.files}\NormalTok{(}\StringTok{"dataSets"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Exam.rds"          "NatHealth2008MI"   "NatHealth2011.rds"
## [4] "states.rds"
\end{verbatim}

We're going to use the \texttt{states} data first, which originally appeared in \emph{Statistics with Stata} by Lawrence C. Hamilton.

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# read the states data}
\NormalTok{  states\_data \textless{}{-}}\StringTok{ }\KeywordTok{read\_rds}\NormalTok{(}\StringTok{"dataSets/states.rds"}\NormalTok{)}

  \CommentTok{\# look at the last few rows}
  \KeywordTok{tail}\NormalTok{(states\_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            state  region     pop  area density metro waste energy miles toxic
## 46       Vermont N. East  563000  9249   60.87  23.4  0.69    232  10.4  1.81
## 47      Virginia   South 6187000 39598  156.25  72.5  1.45    306   9.7 12.87
## 48    Washington    West 4867000 66582   73.10  81.7  1.05    389   9.2  8.51
## 49 West Virginia   South 1793000 24087   74.44  36.4  0.95    415   8.6 21.30
##    green house senate csat vsat msat percent expense income high college
## 46 15.17    85     94  890  424  466      68    6738 34.717 80.8    24.3
## 47 18.72    33     54  890  424  466      60    4836 38.838 75.2    24.5
## 48 16.51    52     64  913  433  480      49    5000 36.338 83.8    22.9
## 49 51.14    48     57  926  441  485      17    4911 24.233 66.0    12.3
##  [ reached 'max' / getOption("max.print") -- omitted 2 rows ]
\end{verbatim}

\begin{longtable}[]{@{}ll@{}}
\toprule
Variable & Description\tabularnewline
\midrule
\endhead
csat & Mean composite SAT score\tabularnewline
expense & Per pupil expenditures\tabularnewline
percent & \% HS graduates taking SAT\tabularnewline
income & Median household income, \$1,000\tabularnewline
region & Geographic region: West, N. East, South, Midwest\tabularnewline
house & House '91 environ. voting, \%\tabularnewline
senate & Senate '91 environ. voting, \%\tabularnewline
energy & Per capita energy consumed, Btu\tabularnewline
metro & Metropolitan area population, \%\tabularnewline
waste & Per capita solid waste, tons\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{examine-the-data}{%
\subsection{Examine the data}\label{examine-the-data}}

Start by examining the data to check for problems.

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# summary of expense and csat columns, all rows}
\NormalTok{  sts\_ex\_sat \textless{}{-}}\StringTok{ }
\StringTok{      }\NormalTok{states\_data }\OperatorTok{\%\textgreater{}\%}\StringTok{ }
\StringTok{      }\KeywordTok{select}\NormalTok{(expense, csat)}
  
  \KeywordTok{summary}\NormalTok{(sts\_ex\_sat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     expense          csat       
##  Min.   :2960   Min.   : 832.0  
##  1st Qu.:4352   1st Qu.: 888.0  
##  Median :5000   Median : 926.0  
##  Mean   :5236   Mean   : 944.1  
##  3rd Qu.:5794   3rd Qu.: 997.0  
##  Max.   :9259   Max.   :1093.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# correlation between expense and csat}
  \KeywordTok{cor}\NormalTok{(sts\_ex\_sat, }\DataTypeTok{use =} \StringTok{"pairwise"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            expense       csat
## expense  1.0000000 -0.4662978
## csat    -0.4662978  1.0000000
\end{verbatim}

\hypertarget{plot-the-data}{%
\subsection{Plot the data}\label{plot-the-data}}

Plot the data to look for multivariate outliers, non-linear relationships etc.

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# scatter plot of expense vs csat}
  \KeywordTok{plot}\NormalTok{(sts\_ex\_sat)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rmodels/figures/unnamed-chunk-83-1.pdf}

Obviously, in a real project, you would want to spend more time investigating the data,
but we'll now move on to modeling.

\hypertarget{models-with-continuous-outcomes}{%
\section{Models with continuous outcomes}\label{models-with-continuous-outcomes}}

\begin{alert}

\textbf{GOAL: To learn about the R modeling ecosystem by fitting ordinary least squares (OLS) models.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Formula representation of a model specification
\item
  Model classes
\item
  Function methods
\item
  Model comparison
\end{enumerate}

\end{alert}

Once the data have been inspected and cleaned, we can start estimating models.
The simplest models (but those with the most assumptions) are those for continuous and unbounded outcomes.
Typically, for these outcomes, we'd use a model estimated using Ordinary Least Lquares (OLS),
which in R can be fit with the \texttt{lm()} (linear model) function.

To fit a model in R, we first have to convert our theoretical model into
a \texttt{formula} --- a symbolic representation of the model in R syntax:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# formula for model specification}
\NormalTok{outcome }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{pred1 }\OperatorTok{+}\StringTok{ }\NormalTok{pred2 }\OperatorTok{+}\StringTok{ }\NormalTok{pred3}

\CommentTok{\# }\AlertTok{NOTE}\CommentTok{ the \textasciitilde{} is a tilde}
\end{Highlighting}
\end{Shaded}

For example, the following theoretical model predicts SAT scores based on per-pupil expenditures:

\begin{alert}

\[
SATscores_i = \beta_{0}1 + \beta_1expenditures_i + \epsilon_i
\]

\end{alert}

We can use \texttt{lm()} to fit this model:

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# fit our regression model}
\NormalTok{  sat\_mod \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(csat }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{expense, }\CommentTok{\# regression formula}
                \DataTypeTok{data =}\NormalTok{ states\_data) }\CommentTok{\# data }

  \CommentTok{\# look at the basic printed output}
\NormalTok{  sat\_mod}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = csat ~ 1 + expense, data = states_data)
## 
## Coefficients:
## (Intercept)      expense  
##  1060.73244     -0.02228
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# get more informative summary information }
  \CommentTok{\# about coefficients and goodness{-}of{-}fit}
  \KeywordTok{summary}\NormalTok{(sat\_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = csat ~ 1 + expense, data = states_data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -131.811  -38.085    5.607   37.852  136.495 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  1.061e+03  3.270e+01   32.44  < 2e-16 ***
## expense     -2.228e-02  6.037e-03   -3.69 0.000563 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 59.81 on 49 degrees of freedom
## Multiple R-squared:  0.2174, Adjusted R-squared:  0.2015 
## F-statistic: 13.61 on 1 and 49 DF,  p-value: 0.0005631
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# show only the regression coefficients table }
  \KeywordTok{summary}\NormalTok{(sat\_mod) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{coef}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                  Estimate   Std. Error   t value     Pr(>|t|)
## (Intercept) 1060.73244395 32.700896736 32.437412 8.878411e-35
## expense       -0.02227565  0.006037115 -3.689783 5.630902e-04
\end{verbatim}

\hypertarget{why-is-the-association-between-expense-sat-scores-negative}{%
\subsection{\texorpdfstring{Why is the association between expense \& SAT scores \emph{negative}?}{Why is the association between expense \& SAT scores negative?}}\label{why-is-the-association-between-expense-sat-scores-negative}}

Many people find it surprising that the per-capita expenditure on students is negatively related to SAT scores. The beauty of multiple regression is that we can try to pull these apart. What would the association between expense and SAT scores be if there were no difference among the states in the percentage of students taking the SAT?

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{lm}\NormalTok{(csat }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{expense }\OperatorTok{+}\StringTok{ }\NormalTok{percent, }\DataTypeTok{data =}\NormalTok{ states\_data) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }
\StringTok{  }\KeywordTok{summary}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = csat ~ 1 + expense + percent, data = states_data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -62.921 -24.318   1.741  15.502  75.623 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 989.807403  18.395770  53.806  < 2e-16 ***
## expense       0.008604   0.004204   2.046   0.0462 *  
## percent      -2.537700   0.224912 -11.283 4.21e-15 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 31.62 on 48 degrees of freedom
## Multiple R-squared:  0.7857, Adjusted R-squared:  0.7768 
## F-statistic: 88.01 on 2 and 48 DF,  p-value: < 2.2e-16
\end{verbatim}

\hypertarget{the-lm-class-methods}{%
\subsection{\texorpdfstring{The \texttt{lm} class \& methods}{The lm class \& methods}}\label{the-lm-class-methods}}

Okay, we fitted our model. Now what? Typically, the main goal in the \textbf{post-estimation stage} of analysis
is to extract \textbf{quantities of interest} from our fitted model. These quantities could be things like:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Testing whether one group is different on average from another group
\item
  Generating average response values from the model for interesting combinations of predictor values
\item
  Calculating interval estimates for particular coefficients
\end{enumerate}

But before we can do any of that, we need to know more about \textbf{what a fitted model actually is,}
\textbf{what information it contains, and how we can extract from it information that we want to report}.

Let's start by examining the model object:

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{class}\NormalTok{(sat\_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "lm"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{str}\NormalTok{(sat\_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## List of 12
##  $ coefficients : Named num [1:2] 1060.7324 -0.0223
##   ..- attr(*, "names")= chr [1:2] "(Intercept)" "expense"
##  $ residuals    : Named num [1:51] 11.1 44.8 -32.7 26.7 -63.7 ...
##   ..- attr(*, "names")= chr [1:51] "1" "2" "3" "4" ...
##  $ effects      : Named num [1:51] -6742.2 220.7 -31.7 29.7 -63.2 ...
##   ..- attr(*, "names")= chr [1:51] "(Intercept)" "expense" "" "" ...
##  $ rank         : int 2
##  $ fitted.values: Named num [1:51] 980 875 965 978 961 ...
##   ..- attr(*, "names")= chr [1:51] "1" "2" "3" "4" ...
##  $ assign       : int [1:2] 0 1
##  $ qr           :List of 5
##   ..$ qr   : num [1:51, 1:2] -7.14 0.14 0.14 0.14 0.14 ...
##   .. ..- attr(*, "dimnames")=List of 2
##   .. .. ..$ : chr [1:51] "1" "2" "3" "4" ...
##   .. .. ..$ : chr [1:2] "(Intercept)" "expense"
##   .. ..- attr(*, "assign")= int [1:2] 0 1
##   ..$ qraux: num [1:2] 1.14 1.33
##   ..$ pivot: int [1:2] 1 2
##   ..$ tol  : num 1e-07
##   ..$ rank : int 2
##   ..- attr(*, "class")= chr "qr"
##  $ df.residual  : int 49
##  $ xlevels      : Named list()
##  $ call         : language lm(formula = csat ~ 1 + expense, data = states_data)
##  $ terms        :Classes 'terms', 'formula'  language csat ~ 1 + expense
##   .. ..- attr(*, "variables")= language list(csat, expense)
##   .. ..- attr(*, "factors")= int [1:2, 1] 0 1
##   .. .. ..- attr(*, "dimnames")=List of 2
##   .. .. .. ..$ : chr [1:2] "csat" "expense"
##   .. .. .. ..$ : chr "expense"
##   .. ..- attr(*, "term.labels")= chr "expense"
##   .. ..- attr(*, "order")= int 1
##   .. ..- attr(*, "intercept")= int 1
##   .. ..- attr(*, "response")= int 1
##   .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv> 
##   .. ..- attr(*, "predvars")= language list(csat, expense)
##   .. ..- attr(*, "dataClasses")= Named chr [1:2] "numeric" "numeric"
##   .. .. ..- attr(*, "names")= chr [1:2] "csat" "expense"
##  $ model        :'data.frame':   51 obs. of  2 variables:
##   ..$ csat   : int [1:51] 991 920 932 1005 897 959 897 892 840 882 ...
##   ..$ expense: int [1:51] 3627 8330 4309 3700 4491 5064 7602 5865 9259 5276 ...
##   ..- attr(*, "terms")=Classes 'terms', 'formula'  language csat ~ 1 + expense
##   .. .. ..- attr(*, "variables")= language list(csat, expense)
##   .. .. ..- attr(*, "factors")= int [1:2, 1] 0 1
##   .. .. .. ..- attr(*, "dimnames")=List of 2
##   .. .. .. .. ..$ : chr [1:2] "csat" "expense"
##   .. .. .. .. ..$ : chr "expense"
##   .. .. ..- attr(*, "term.labels")= chr "expense"
##   .. .. ..- attr(*, "order")= int 1
##   .. .. ..- attr(*, "intercept")= int 1
##   .. .. ..- attr(*, "response")= int 1
##   .. .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv> 
##   .. .. ..- attr(*, "predvars")= language list(csat, expense)
##   .. .. ..- attr(*, "dataClasses")= Named chr [1:2] "numeric" "numeric"
##   .. .. .. ..- attr(*, "names")= chr [1:2] "csat" "expense"
##  - attr(*, "class")= chr "lm"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{names}\NormalTok{(sat\_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "coefficients"  "residuals"     "effects"       "rank"         
##  [5] "fitted.values" "assign"        "qr"            "df.residual"  
##  [9] "xlevels"       "call"          "terms"         "model"
\end{verbatim}

We can list all the functions that extract particular quantities of interest (called \texttt{extractor\ functions}) by using the \texttt{methods()} function with the \texttt{class} argument set to the class of the model object:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{methods}\NormalTok{(}\DataTypeTok{class =} \KeywordTok{class}\NormalTok{(sat\_mod))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] add1           alias          anova          case.names     coerce        
##  [6] confint        cooks.distance deviance       dfbeta         dfbetas       
## [11] drop1          dummy.coef     Effect         effects        emm_basis     
## [16] extractAIC     family         formula        fortify        hatvalues     
## [21] influence      initialize     kappa          labels         logLik        
## [26] model.frame    model.matrix   nobs           plot           predict       
## [31] print          proj           qqnorm         qr             recover_data  
## [36] residuals      rstandard      rstudent       show           simulate      
## [41] slotsFromS3    summary        variable.names vcov          
## see '?methods' for accessing help and source code
\end{verbatim}

We can also use \texttt{function\ methods} to get more information about the fit:

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{summary}\NormalTok{(sat\_mod) }\CommentTok{\# summary table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = csat ~ 1 + expense, data = states_data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -131.811  -38.085    5.607   37.852  136.495 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  1.061e+03  3.270e+01   32.44  < 2e-16 ***
## expense     -2.228e-02  6.037e-03   -3.69 0.000563 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 59.81 on 49 degrees of freedom
## Multiple R-squared:  0.2174, Adjusted R-squared:  0.2015 
## F-statistic: 13.61 on 1 and 49 DF,  p-value: 0.0005631
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{confint}\NormalTok{(sat\_mod) }\CommentTok{\# confidence intervals}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                    2.5 %        97.5 %
## (Intercept) 995.01753164 1126.44735626
## expense      -0.03440768   -0.01014361
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{anova}\NormalTok{(sat\_mod) }\CommentTok{\# ANOVA table  }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Response: csat
##           Df Sum Sq Mean Sq F value    Pr(>F)    
## expense    1  48708   48708  13.614 0.0005631 ***
## Residuals 49 175306    3578                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

How does R know which method to call for a given object? R uses \texttt{generic\ functions}, which provide access to \texttt{methods}. Method dispatch takes place based on the \texttt{class} of the first argument to the generic function. For example, for the generic function \texttt{summary()} and an object of class \texttt{lm}, the method dispatched will be \texttt{summary.lm()}. Function methods always take the form \texttt{generic.method()}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{methods}\NormalTok{(}\StringTok{"summary"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   [1] summary,ANY-method             summary,DBIObject-method      
##   [3] summary,diagonalMatrix-method  summary,sparseMatrix-method   
##   [5] summary.aareg*                 summary.allFit*               
##   [7] summary.aov                    summary.aovlist*              
##   [9] summary.aspell*                summary.cch*                  
##  [11] summary.check_packages_in_dir* summary.connection            
##  [13] summary.corAR1*                summary.corARMA*              
##  [15] summary.corCAR1*               summary.corCompSymm*          
##  [17] summary.corExp*                summary.corGaus*              
##  [19] summary.corIdent*              summary.corLin*               
##  [21] summary.corNatural*            summary.corRatio*             
##  [23] summary.corSpher*              summary.corStruct*            
##  [25] summary.corSymm*               summary.coxph*                
##  [27] summary.coxph.penal*           summary.data.frame            
##  [29] summary.Date                   summary.DBIrepdesign*         
##  [31] summary.DBIsvydesign*          summary.default               
##  [33] summary.Duration*              summary.ecdf*                 
##  [35] summary.eff*                   summary.efflatent*            
##  [37] summary.efflist*               summary.effpoly*              
##  [39] summary.emm_list*              summary.emmGrid*              
##  [41] summary.factor                 summary.ggplot*               
##  [43] summary.glht*                  summary.glht_list*            
##  [45] summary.glm                    summary.gls*                  
##  [47] summary.haven_labelled*        summary.hcl_palettes*         
##  [49] summary.infl*                  summary.Interval*             
##  [51] summary.lm                     summary.lme*                  
##  [53] summary.lmList*                summary.lmList4*              
##  [55] summary.loess*                 summary.loglm*                
##  [57] summary.manova                 summary.matrix                
##  [59] summary.mcmc*                  summary.mcmc.list*            
##  [61] summary.merMod*                summary.MIresult*             
##  [63] summary.mlm*                   summary.mlm.efflist*          
##  [65] summary.modelStruct*           summary.multinom*             
##  [67] summary.negbin*                summary.nls*                  
##  [69] summary.nlsList*               summary.nnet*                 
##  [71] summary.packageStatus*         summary.pdBlocked*            
##  [73] summary.pdCompSymm*            summary.pdDiag*               
##  [75] summary.pdIdent*               summary.pdLogChol*            
##  [77] summary.pdMat*                 summary.pdNatural*            
##  [79] summary.pdSymm*                summary.Period*               
##  [81] summary.polr*                  summary.POSIXct               
##  [83] summary.POSIXlt                summary.ppr*                  
##  [85] summary.pps*                   summary.prcomp*               
##  [87] summary.prcomplist*            summary.predictorefflist*     
##  [89] summary.princomp*              summary.proc_time             
##  [91] summary.pyears*                summary.ratetable*            
##  [93] summary.reStruct*              summary.rlang_error*          
##  [95] summary.rlang_trace*           summary.rlm*                  
##  [97] summary.shingle*               summary.srcfile               
##  [99] summary.srcref                 summary.stepfun               
##  [ reached getOption("max.print") -- omitted 37 entries ]
## see '?methods' for accessing help and source code
\end{verbatim}

\includegraphics{R/Rmodels/images/methods.png}

It's always worth examining whether the class of model you're fitting has a method for a particular extractor function.
Here's a summary table of some of the most often used extractor functions, which have methods for a wide range of model classes. These are post-estimation tools you will want in your toolbox:

\begin{longtable}[]{@{}lll@{}}
\toprule
\begin{minipage}[b]{0.16\columnwidth}\raggedright
Function\strut
\end{minipage} & \begin{minipage}[b]{0.17\columnwidth}\raggedright
Package\strut
\end{minipage} & \begin{minipage}[b]{0.59\columnwidth}\raggedright
Output\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.16\columnwidth}\raggedright
\texttt{summary()}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\texttt{stats} base R\strut
\end{minipage} & \begin{minipage}[t]{0.59\columnwidth}\raggedright
standard errors, test statistics, p-values, GOF stats\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.16\columnwidth}\raggedright
\texttt{confint()}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\texttt{stats} base R\strut
\end{minipage} & \begin{minipage}[t]{0.59\columnwidth}\raggedright
confidence intervals\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.16\columnwidth}\raggedright
\texttt{anova()}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\texttt{stats} base R\strut
\end{minipage} & \begin{minipage}[t]{0.59\columnwidth}\raggedright
anova table (one model), model comparison (\textgreater{} one model)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.16\columnwidth}\raggedright
\texttt{coef()}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\texttt{stats} base R\strut
\end{minipage} & \begin{minipage}[t]{0.59\columnwidth}\raggedright
point estimates\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.16\columnwidth}\raggedright
\texttt{drop1()}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\texttt{stats} base R\strut
\end{minipage} & \begin{minipage}[t]{0.59\columnwidth}\raggedright
model comparison\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.16\columnwidth}\raggedright
\texttt{predict()}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\texttt{stats} base R\strut
\end{minipage} & \begin{minipage}[t]{0.59\columnwidth}\raggedright
predicted response values\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.16\columnwidth}\raggedright
\texttt{fitted()}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\texttt{stats} base R\strut
\end{minipage} & \begin{minipage}[t]{0.59\columnwidth}\raggedright
predicted response values (for observed data)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.16\columnwidth}\raggedright
\texttt{residuals()}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\texttt{stats} base R\strut
\end{minipage} & \begin{minipage}[t]{0.59\columnwidth}\raggedright
residuals\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.16\columnwidth}\raggedright
\texttt{fixef()}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\texttt{lme4}\strut
\end{minipage} & \begin{minipage}[t]{0.59\columnwidth}\raggedright
fixed effect point estimates (mixed models only)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.16\columnwidth}\raggedright
\texttt{ranef()}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\texttt{lme4}\strut
\end{minipage} & \begin{minipage}[t]{0.59\columnwidth}\raggedright
random effect point estimates (mixed models only)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.16\columnwidth}\raggedright
\texttt{coef()}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\texttt{lme4}\strut
\end{minipage} & \begin{minipage}[t]{0.59\columnwidth}\raggedright
empirical Bayes estimates (mixed models only)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.16\columnwidth}\raggedright
\texttt{allEffects()}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\texttt{effects}\strut
\end{minipage} & \begin{minipage}[t]{0.59\columnwidth}\raggedright
predicted marginal means\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.16\columnwidth}\raggedright
\texttt{emmeans()}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\texttt{emmeans}\strut
\end{minipage} & \begin{minipage}[t]{0.59\columnwidth}\raggedright
predicted marginal means \& marginal effects\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.16\columnwidth}\raggedright
\texttt{margins()}\strut
\end{minipage} & \begin{minipage}[t]{0.17\columnwidth}\raggedright
\texttt{margins}\strut
\end{minipage} & \begin{minipage}[t]{0.59\columnwidth}\raggedright
predicted marginal means \& marginal effects\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{ols-regression-assumptions}{%
\subsection{OLS regression assumptions}\label{ols-regression-assumptions}}

OLS regression relies on several assumptions, including:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The model includes all relevant variables (i.e., no omitted variable bias).
\item
  The model is linear in the parameters (i.e., the coefficients and error term).
\item
  The error term has an expected value of zero.
\item
  All right-hand-side variables are uncorrelated with the error term.
\item
  No right-hand-side variables are a perfect linear function of other RHS variables.
\item
  Observations of the error term are uncorrelated with each other.
\item
  The error term has constant variance (i.e., homoscedasticity).
\item
  (Optional - only needed for inference). The error term is normally distributed.
\end{enumerate}

Investigate assumptions \#7 and \#8 visually by plotting your model:

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{)) }\CommentTok{\# splits the plotting window into 4 panels}
  \KeywordTok{plot}\NormalTok{(sat\_mod)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rmodels/figures/unnamed-chunk-91-1.pdf}

\hypertarget{comparing-models}{%
\subsection{Comparing models}\label{comparing-models}}

Do congressional voting patterns predict SAT scores over and above expense? Fit two models and compare them:

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# fit another model, adding house and senate as predictors}
\NormalTok{  sat\_voting\_mod \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(csat }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{expense }\OperatorTok{+}\StringTok{ }\NormalTok{house }\OperatorTok{+}\StringTok{ }\NormalTok{senate,}
                        \DataTypeTok{data =} \KeywordTok{na.omit}\NormalTok{(states\_data))}

  \KeywordTok{summary}\NormalTok{(sat\_voting\_mod) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{coef}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                  Estimate   Std. Error    t value     Pr(>|t|)
## (Intercept) 1082.93438041 38.633812740 28.0307405 1.067795e-29
## expense       -0.01870832  0.009691494 -1.9303852 6.001998e-02
## house         -1.44243754  0.600478382 -2.4021473 2.058666e-02
## senate         0.49817861  0.513561356  0.9700469 3.373256e-01
\end{verbatim}

Why are we using \texttt{na.omit()}? Let's see what \texttt{na.omit()} does.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fake data}
\NormalTok{dat \textless{}{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
  \DataTypeTok{x =} \DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{,}
  \DataTypeTok{y =} \KeywordTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\OtherTok{NA}\NormalTok{, }\DecValTok{5}\NormalTok{),}
  \DataTypeTok{z =} \KeywordTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\OtherTok{NA}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{3}\NormalTok{))}
\NormalTok{dat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   x  y  z
## 1 1  3  6
## 2 2  2 NA
## 3 3  1  2
## 4 4 NA  7
## 5 5  5  3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{na.omit}\NormalTok{(dat) }\CommentTok{\# listwise deletion of observations}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   x y z
## 1 1 3 6
## 3 3 1 2
## 5 5 5 3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# also see}
\CommentTok{\# ?complete.cases}
\NormalTok{dat[}\KeywordTok{with}\NormalTok{(dat, }\KeywordTok{complete.cases}\NormalTok{(x, y, z)), ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   x y z
## 1 1 3 6
## 3 3 1 2
## 5 5 5 3
\end{verbatim}

To compare models, we must fit them to the same data. This is why we need \texttt{na.omit()}.
Now let's update our first model using \texttt{na.omit()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  sat\_mod \textless{}{-}}\StringTok{ }
\StringTok{      }\NormalTok{sat\_mod }\OperatorTok{\%\textgreater{}\%}
\StringTok{      }\KeywordTok{update}\NormalTok{(}\DataTypeTok{data =} \KeywordTok{na.omit}\NormalTok{(states\_data))}

  \CommentTok{\# compare using an F{-}test with the anova() function}
  \KeywordTok{anova}\NormalTok{(sat\_mod, sat\_voting\_mod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Model 1: csat ~ 1 + expense
## Model 2: csat ~ 1 + expense + house + senate
##   Res.Df    RSS Df Sum of Sq      F  Pr(>F)  
## 1     46 169050                              
## 2     44 149284  2     19766 2.9128 0.06486 .
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\hypertarget{exercise-0-1}{%
\subsection{Exercise 0}\label{exercise-0-1}}

\textbf{Ordinary least squares regression}

Use the \emph{states.rds} data set. Fit a model predicting energy consumed per capita (energy) from the percentage of residents living in metropolitan areas (\texttt{metro}). Be sure to

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Examine/plot the data before fitting the model
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Print and interpret the model \texttt{summary()}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \texttt{plot()} the model to look for deviations from modeling assumptions
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Select one or more additional predictors to add to your model and repeat steps 1-3. Is this model significantly better than the model with \texttt{metro} as the only predictor?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

{Click for Exercise 0 Solution}

\begin{alert}

Use the \emph{states.rds} data set.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  states \textless{}{-}}\StringTok{ }\KeywordTok{read\_rds}\NormalTok{(}\StringTok{"dataSets/states.rds"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Fit a model predicting energy consumed per capita (energy) from the percentage of residents living in metropolitan areas (metro). Be sure to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Examine/plot the data before fitting the model.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  states\_en\_met \textless{}{-}}\StringTok{ }
\StringTok{      }\NormalTok{states }\OperatorTok{\%\textgreater{}\%}\StringTok{ }
\StringTok{      }\KeywordTok{select}\NormalTok{(metro, energy)}

  \KeywordTok{summary}\NormalTok{(states\_en\_met)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      metro            energy     
##  Min.   : 20.40   Min.   :200.0  
##  1st Qu.: 46.98   1st Qu.:285.0  
##  Median : 67.55   Median :320.0  
##  Mean   : 64.07   Mean   :354.5  
##  3rd Qu.: 81.58   3rd Qu.:371.5  
##  Max.   :100.00   Max.   :991.0  
##  NA's   :1        NA's   :1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{plot}\NormalTok{(states\_en\_met)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rmodels/figures/unnamed-chunk-100-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{cor}\NormalTok{(states\_en\_met, }\DataTypeTok{use =} \StringTok{"pairwise"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             metro     energy
## metro   1.0000000 -0.3397445
## energy -0.3397445  1.0000000
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Print and interpret the model \texttt{summary()}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  mod\_en\_met \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(energy }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{metro, }\DataTypeTok{data =}\NormalTok{ states)}
  \KeywordTok{summary}\NormalTok{(mod\_en\_met)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = energy ~ metro, data = states)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -215.51  -64.54  -30.87   18.71  583.97 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 501.0292    61.8136   8.105 1.53e-10 ***
## metro        -2.2871     0.9139  -2.503   0.0158 *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 140.2 on 48 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.1154, Adjusted R-squared:  0.097 
## F-statistic: 6.263 on 1 and 48 DF,  p-value: 0.01578
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \texttt{plot()} the model to look for deviations from modeling assumptions.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{)) }\CommentTok{\# splits the plotting window into 4 panels}
  \KeywordTok{plot}\NormalTok{(mod\_en\_met)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rmodels/figures/unnamed-chunk-102-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Select one or more additional predictors to add to your model and repeat steps 1-3. Is this model significantly better than the model with \emph{metro} as the only predictor?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  states\_en\_met\_pop\_wst \textless{}{-}}\StringTok{ }
\StringTok{      }\NormalTok{states }\OperatorTok{\%\textgreater{}\%}
\StringTok{      }\KeywordTok{select}\NormalTok{(energy, metro, pop, waste)}

  \KeywordTok{summary}\NormalTok{(states\_en\_met\_pop\_wst)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      energy          metro             pop               waste       
##  Min.   :200.0   Min.   : 20.40   Min.   :  454000   Min.   :0.5400  
##  1st Qu.:285.0   1st Qu.: 46.98   1st Qu.: 1299750   1st Qu.:0.8225  
##  Median :320.0   Median : 67.55   Median : 3390500   Median :0.9600  
##  Mean   :354.5   Mean   : 64.07   Mean   : 4962040   Mean   :0.9888  
##  3rd Qu.:371.5   3rd Qu.: 81.58   3rd Qu.: 5898000   3rd Qu.:1.1450  
##  Max.   :991.0   Max.   :100.00   Max.   :29760000   Max.   :1.5100  
##  NA's   :1       NA's   :1        NA's   :1          NA's   :1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{plot}\NormalTok{(states\_en\_met\_pop\_wst)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rmodels/figures/unnamed-chunk-103-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{cor}\NormalTok{(states\_en\_met\_pop\_wst, }\DataTypeTok{use =} \StringTok{"pairwise"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            energy      metro        pop      waste
## energy  1.0000000 -0.3397445 -0.1840357 -0.2526499
## metro  -0.3397445  1.0000000  0.5653562  0.4877881
## pop    -0.1840357  0.5653562  1.0000000  0.5255713
## waste  -0.2526499  0.4877881  0.5255713  1.0000000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  mod\_en\_met\_pop\_waste \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(energy }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{metro }\OperatorTok{+}\StringTok{ }\NormalTok{pop }\OperatorTok{+}\StringTok{ }\NormalTok{waste, }\DataTypeTok{data =}\NormalTok{ states)}
  \KeywordTok{summary}\NormalTok{(mod\_en\_met\_pop\_waste)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = energy ~ 1 + metro + pop + waste, data = states)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -224.62  -67.48  -31.76   12.65  589.48 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  5.617e+02  9.905e+01   5.671    9e-07 ***
## metro       -2.079e+00  1.168e+00  -1.780   0.0816 .  
## pop          1.649e-06  4.809e-06   0.343   0.7332    
## waste       -8.307e+01  1.042e+02  -0.797   0.4295    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 142.2 on 46 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.1276, Adjusted R-squared:  0.07067 
## F-statistic: 2.242 on 3 and 46 DF,  p-value: 0.09599
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{anova}\NormalTok{(mod\_en\_met, mod\_en\_met\_pop\_waste)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Model 1: energy ~ metro
## Model 2: energy ~ 1 + metro + pop + waste
##   Res.Df    RSS Df Sum of Sq      F Pr(>F)
## 1     48 943103                           
## 2     46 930153  2     12949 0.3202 0.7276
\end{verbatim}

\end{alert}

\hypertarget{interactions-factors}{%
\section{Interactions \& factors}\label{interactions-factors}}

\begin{alert}

\textbf{GOAL: To learn how to specify interaction effects and fit models with categorical predictors.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Formula syntax for interaction effects
\item
  Factor levels and labels
\item
  Contrasts and pairwise comparisons
\end{enumerate}

\end{alert}

\hypertarget{modeling-interactions}{%
\subsection{Modeling interactions}\label{modeling-interactions}}

Interactions allow us assess the extent to which the association between one predictor and the outcome depends on a second predictor. For example: Does the association between expense and SAT scores depend on the median income in the state?

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# Add the interaction to the model}
\NormalTok{  sat\_expense\_by\_percent \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(csat }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{expense }\OperatorTok{+}\StringTok{ }\NormalTok{income }\OperatorTok{+}\StringTok{ }\NormalTok{expense }\OperatorTok{:}\StringTok{ }\NormalTok{income, }\DataTypeTok{data =}\NormalTok{ states\_data)}

  \CommentTok{\# same as above, but shorter syntax}
\NormalTok{  sat\_expense\_by\_percent \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(csat }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{expense }\OperatorTok{*}\StringTok{ }\NormalTok{income, }\DataTypeTok{data =}\NormalTok{ states\_data) }

  \CommentTok{\# Show the regression coefficients table}
  \KeywordTok{summary}\NormalTok{(sat\_expense\_by\_percent) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{coef}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                     Estimate   Std. Error   t value     Pr(>|t|)
## (Intercept)     1.380364e+03 1.720863e+02  8.021351 2.367069e-10
## expense        -6.384067e-02 3.270087e-02 -1.952262 5.687837e-02
## income         -1.049785e+01 4.991463e+00 -2.103161 4.083253e-02
## expense:income  1.384647e-03 8.635529e-04  1.603431 1.155395e-01
\end{verbatim}

\hypertarget{regression-with-categorical-predictors}{%
\subsection{Regression with categorical predictors}\label{regression-with-categorical-predictors}}

Let's try to predict SAT scores from region, a categorical variable.
Note that you must make sure R does not think your categorical variable is numeric.

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# make sure R knows region is categorical}
  \KeywordTok{str}\NormalTok{(states\_data}\OperatorTok{$}\NormalTok{region)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  Factor w/ 4 levels "West","N. East",..: 3 1 1 3 1 1 2 3 NA 3 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  states\_data}\OperatorTok{$}\NormalTok{region \textless{}{-}}\StringTok{ }\KeywordTok{factor}\NormalTok{(states\_data}\OperatorTok{$}\NormalTok{region)}

  \CommentTok{\# arguments to the factor() function}
  \CommentTok{\# factor(x, levels, labels)}

  \KeywordTok{levels}\NormalTok{(states\_data}\OperatorTok{$}\NormalTok{region)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "West"    "N. East" "South"   "Midwest"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# Add region to the model}
\NormalTok{  sat\_region \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(csat }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{region, }\DataTypeTok{data =}\NormalTok{ states\_data) }

  \CommentTok{\# Show the results}
  \KeywordTok{summary}\NormalTok{(sat\_region) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{coef}\NormalTok{() }\CommentTok{\# show the regression coefficients table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                Estimate Std. Error    t value     Pr(>|t|)
## (Intercept)   946.30769   14.79582 63.9577807 1.352577e-46
## regionN. East -56.75214   23.13285 -2.4533141 1.800383e-02
## regionSouth   -16.30769   19.91948 -0.8186806 4.171898e-01
## regionMidwest  63.77564   21.35592  2.9863209 4.514152e-03
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{anova}\NormalTok{(sat\_region) }\CommentTok{\# show ANOVA table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Response: csat
##           Df Sum Sq Mean Sq F value    Pr(>F)    
## region     3  82049 27349.8  9.6102 4.859e-05 ***
## Residuals 46 130912  2845.9                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

So, make sure to tell R which variables are categorical by converting them to factors!

\hypertarget{setting-factor-reference-groups-contrasts}{%
\subsection{Setting factor reference groups \& contrasts}\label{setting-factor-reference-groups-contrasts}}

\textbf{Contrasts} is the umbrella term used to describe the process of testing linear combinations of parameters from regression models. All statistical sofware use contrasts, but each software has different defaults and their own way of overriding these.

The default contrasts in R are ``treatment'' contrasts (aka ``dummy coding''), where each level within a factor is identified within a matrix of binary \texttt{0} / \texttt{1} variables, with the first level chosen as the reference category.They're called ``treatment'' contrasts, because of the typical use case where there is one control group (the reference group) and one or more treatment groups that are to be compared to the controls. It is easy to change the default contrasts to something other than treatment contrasts, though this is rarely needed. More often, we may want to change the reference group in treatment contrasts or get all sets of pairwise contrasts between factor levels.

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# default treatment (dummy) contrasts}
  \KeywordTok{contrasts}\NormalTok{(states\_data}\OperatorTok{$}\NormalTok{region)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         N. East South Midwest
## West          0     0       0
## N. East       1     0       0
## South         0     1       0
## Midwest       0     0       1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# change the reference group}
\NormalTok{  states\_data}\OperatorTok{$}\NormalTok{region \textless{}{-}}\StringTok{ }\KeywordTok{relevel}\NormalTok{(states\_data}\OperatorTok{$}\NormalTok{region, }\DataTypeTok{ref =} \StringTok{"Midwest"}\NormalTok{)}

  \CommentTok{\# check the reference group has changed}
  \KeywordTok{contrasts}\NormalTok{(states\_data}\OperatorTok{$}\NormalTok{region)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         West N. East South
## Midwest    0       0     0
## West       1       0     0
## N. East    0       1     0
## South      0       0     1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# refit the model}
\NormalTok{  mod\_region \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(csat }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{region, }\DataTypeTok{data =}\NormalTok{ states\_data)}
  \KeywordTok{summary}\NormalTok{(mod\_region) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{coef}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                 Estimate Std. Error   t value     Pr(>|t|)
## (Intercept)   1010.08333   15.39998 65.589930 4.296307e-47
## regionWest     -63.77564   21.35592 -2.986321 4.514152e-03
## regionN. East -120.52778   23.52385 -5.123641 5.798399e-06
## regionSouth    -80.08333   20.37225 -3.931000 2.826007e-04
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# get all pairwise contrasts between means}
\NormalTok{  mod\_region }\OperatorTok{\%\textgreater{}\%}
\StringTok{      }\KeywordTok{emmeans}\NormalTok{(}\DataTypeTok{specs =}\NormalTok{ pairwise }\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{region)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $emmeans
##  region  emmean   SE df lower.CL upper.CL
##  Midwest   1010 15.4 46      979     1041
##  West       946 14.8 46      917      976
##  N. East    890 17.8 46      854      925
##  South      930 13.3 46      903      957
## 
## Confidence level used: 0.95 
## 
## $contrasts
##  contrast          estimate   SE df t.ratio p.value
##  Midwest - West        63.8 21.4 46  2.986  0.0226 
##  Midwest - N. East    120.5 23.5 46  5.124  <.0001 
##  Midwest - South       80.1 20.4 46  3.931  0.0016 
##  West - N. East        56.8 23.1 46  2.453  0.0812 
##  West - South          16.3 19.9 46  0.819  0.8453 
##  N. East - South      -40.4 22.2 46 -1.820  0.2774 
## 
## P value adjustment: tukey method for comparing a family of 4 estimates
\end{verbatim}

\hypertarget{exercise-1-1}{%
\subsection{Exercise 1}\label{exercise-1-1}}

\textbf{Interactions \& factors}

Use the \texttt{states} data set.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add on to the regression equation that you created in Exercise 1 by generating an interaction term and testing the interaction.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Try adding region to the model. Are there significant differences across the four regions?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

{Click for Exercise 1 Solution}

\begin{alert}

Use the states data set.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add on to the regression equation that you created in exercise 1 by generating an interaction term and testing the interaction.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  mod\_en\_metro\_by\_waste \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(energy }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{metro }\OperatorTok{*}\StringTok{ }\NormalTok{waste, }\DataTypeTok{data =}\NormalTok{ states)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Try adding a region to the model. Are there significant differences across the four regions?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  mod\_en\_region \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(energy }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{metro }\OperatorTok{*}\StringTok{ }\NormalTok{waste }\OperatorTok{+}\StringTok{ }\NormalTok{region, }\DataTypeTok{data =}\NormalTok{ states)}
  \KeywordTok{anova}\NormalTok{(mod\_en\_metro\_by\_waste, mod\_en\_region)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Analysis of Variance Table
## 
## Model 1: energy ~ 1 + metro * waste
## Model 2: energy ~ 1 + metro * waste + region
##   Res.Df    RSS Df Sum of Sq    F Pr(>F)
## 1     46 930683                         
## 2     43 821247  3    109436 1.91 0.1422
\end{verbatim}

\end{alert}

\hypertarget{models-with-binary-outcomes}{%
\section{Models with binary outcomes}\label{models-with-binary-outcomes}}

\begin{alert}

\textbf{GOAL: To learn how to use the \texttt{glm()} function to model binary outcomes.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The \texttt{family} and \texttt{link} components of the \texttt{glm()} function call
\item
  Transforming model coefficients into odds ratios
\item
  Transforming model coefficients into predicted marginal means
\end{enumerate}

\end{alert}

\hypertarget{logistic-regression}{%
\subsection{Logistic regression}\label{logistic-regression}}

This far we have used the \texttt{lm()} function to fit our regression models. \texttt{lm()} is great, but limited --- in particular it only fits models for continuous dependent variables. For categorical dependent variables we can use the \texttt{glm()} function.

For these models we will use a different dataset, drawn from the National Health Interview Survey. From the \href{http://www.cdc.gov/nchs/nhis.htm}{CDC website}:

\begin{quote}
The National Health Interview Survey (NHIS) has monitored the health of the nation since 1957. NHIS data on a broad range of health topics are collected through personal household interviews. For over 50 years, the U.S. Census Bureau has been the data collection agent for the National Health Interview Survey. Survey results have been instrumental in providing data to track health status, health care access, and progress toward achieving national health objectives.
\end{quote}

Load the National Health Interview Survey data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  NH11 \textless{}{-}}\StringTok{ }\KeywordTok{read\_rds}\NormalTok{(}\StringTok{"dataSets/NatHealth2011.rds"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{logistic-regression-example}{%
\subsection{Logistic regression example}\label{logistic-regression-example}}

Motivation for a logistic regression model --- with a binary response:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Errors will not be normally distributed
\item
  Variance will not be homoskedastic
\item
  Predictions should be constrained to be on the interval {[}0, 1{]}
\end{enumerate}

\includegraphics{R/Rmodels/images/logistic.png}

Anatomy of a generalized linear model:

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# OLS model using lm()}
  \KeywordTok{lm}\NormalTok{(outcome }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{pred1 }\OperatorTok{+}\StringTok{ }\NormalTok{pred2, }
     \DataTypeTok{data =}\NormalTok{ mydata)}

  \CommentTok{\# OLS model using glm()}
  \KeywordTok{glm}\NormalTok{(outcome }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{pred1 }\OperatorTok{+}\StringTok{ }\NormalTok{pred2, }
      \DataTypeTok{data =}\NormalTok{ mydata, }
      \DataTypeTok{family =} \KeywordTok{gaussian}\NormalTok{(}\DataTypeTok{link =} \StringTok{"identity"}\NormalTok{))}
 
  \CommentTok{\# logistic model using glm()}
  \KeywordTok{glm}\NormalTok{(outcome }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{pred1 }\OperatorTok{+}\StringTok{ }\NormalTok{pred2, }
      \DataTypeTok{data =}\NormalTok{ mydata, }
      \DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link =} \StringTok{"logit"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

The \texttt{family} argument sets the error distribution for the model, while the \texttt{link} function
argument relates the predictors to the expected value of the outcome.

Let's predict the probability of being diagnosed with hypertension based on age, sex, sleep, and bmi.
Here's the theoretical model:

\begin{alert}

\[
logit(p(hypertension_i = 1)) = \beta_{0}1 + \beta_1age_i + \beta_2sex_i + \beta_3sleep_i + \beta_4bmi_i 
\]

\end{alert}

where \(logit(\cdot)\) is the non-linear link function that relates a linear expression of the predictors to the expectation of the binary response:

\begin{alert}

\[
logit(p(hypertension_i = 1)) = ln \left( \frac{p(hypertension_i = 1)}{1-p(hypertension_i = 1)} \right) = ln \left( \frac{p(hypertension_i = 1)}{p(hypertension_i = 0)} \right)
\]

\end{alert}

And here's how we fit this model in R. First, let's clean up the hypertension outcome by making it binary:

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{str}\NormalTok{(NH11}\OperatorTok{$}\NormalTok{hypev) }\CommentTok{\# check stucture of hypev}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  Factor w/ 5 levels "1 Yes","2 No",..: 2 2 1 2 2 1 2 2 1 2 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{levels}\NormalTok{(NH11}\OperatorTok{$}\NormalTok{hypev) }\CommentTok{\# check levels of hypev}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "1 Yes"             "2 No"              "7 Refused"        
## [4] "8 Not ascertained" "9 Don't know"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# collapse all missing values to NA}
\NormalTok{  NH11}\OperatorTok{$}\NormalTok{hypev \textless{}{-}}\StringTok{ }\KeywordTok{factor}\NormalTok{(NH11}\OperatorTok{$}\NormalTok{hypev, }\DataTypeTok{levels=}\KeywordTok{c}\NormalTok{(}\StringTok{"2 No"}\NormalTok{, }\StringTok{"1 Yes"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Now let's use \texttt{glm()} to estimate the model:

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# run our regression model}
\NormalTok{  hyp\_out \textless{}{-}}\StringTok{ }\KeywordTok{glm}\NormalTok{(hypev }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{age\_p }\OperatorTok{+}\StringTok{ }\NormalTok{sex }\OperatorTok{+}\StringTok{ }\NormalTok{sleep }\OperatorTok{+}\StringTok{ }\NormalTok{bmi,}
                 \DataTypeTok{data =}\NormalTok{ NH11, }
                 \DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link =} \StringTok{"logit"}\NormalTok{))}

  \KeywordTok{summary}\NormalTok{(hyp\_out) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{coef}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                 Estimate   Std. Error    z value     Pr(>|z|)
## (Intercept) -4.269466028 0.0564947294 -75.572820 0.000000e+00
## age_p        0.060699303 0.0008227207  73.778743 0.000000e+00
## sex2 Female -0.144025092 0.0267976605  -5.374540 7.677854e-08
## sleep       -0.007035776 0.0016397197  -4.290841 1.779981e-05
## bmi          0.018571704 0.0009510828  19.526906 6.485172e-85
\end{verbatim}

\hypertarget{odds-ratios}{%
\subsection{Odds ratios}\label{odds-ratios}}

Generalized linear models use link functions to relate the average value of the response to the predictors,
so raw coefficients are difficult to interpret. For example, the \texttt{age} coefficient of .06 in the previous
model tells us that for every one unit increase in \texttt{age}, the log odds of hypertension diagnosis increases
by 0.06. Since most of us are not used to thinking in log odds this is not too helpful!

One solution is to transform the coefficients to make them easier to interpret.
Here we transform them into odds ratios by exponentiating:

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# point estimates}
  \KeywordTok{coef}\NormalTok{(hyp\_out) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{exp}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept)       age_p sex2 Female       sleep         bmi 
##  0.01398925  1.06257935  0.86586602  0.99298892  1.01874523
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# confidence intervals}
  \KeywordTok{confint}\NormalTok{(hyp\_out) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{exp}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                  2.5 %     97.5 %
## (Intercept) 0.01251677 0.01561971
## age_p       1.06087385 1.06430082
## sex2 Female 0.82155196 0.91255008
## sleep       0.98978755 0.99617465
## bmi         1.01685145 1.02065009
\end{verbatim}

\hypertarget{predicted-marginal-means}{%
\subsection{Predicted marginal means}\label{predicted-marginal-means}}

Instead of reporting odds ratios, we may want to calculate predicted marginal means (sometimes called ``least-squares means'' or ``estimated marginal means''). These are average values of the outcome at particular levels of the predictors. For ease of interpretation, we want these marginal means to be on the response scale (i.e., the probability scale). We can use the \texttt{effects} package to compute these quantities of interest for us (by default, the numerical output will be on the response scale).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  hyp\_out }\OperatorTok{\%\textgreater{}\%}\StringTok{ }
\StringTok{      }\KeywordTok{allEffects}\NormalTok{() }\OperatorTok{\%\textgreater{}\%}
\StringTok{      }\KeywordTok{plot}\NormalTok{(}\DataTypeTok{type =} \StringTok{"response"}\NormalTok{) }\CommentTok{\# "response" refers to the probability scale}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rmodels/figures/unnamed-chunk-117-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# generate a sequence of ages at which to get predictions of the outcome}
\NormalTok{  age\_years \textless{}{-}}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{20}\NormalTok{, }\DecValTok{80}\NormalTok{, }\DataTypeTok{by =} \DecValTok{5}\NormalTok{)}
\NormalTok{  age\_years}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 20 25 30 35 40 45 50 55 60 65 70 75 80
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  eff\_df \textless{}{-}}\StringTok{ }
\StringTok{      }\NormalTok{hyp\_out }\OperatorTok{\%\textgreater{}\%}\StringTok{ }
\StringTok{      }\KeywordTok{allEffects}\NormalTok{(}\DataTypeTok{xlevels =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{age\_p =}\NormalTok{ age\_years)) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\CommentTok{\# override defaults for age}
\StringTok{      }\KeywordTok{as.data.frame}\NormalTok{() }\CommentTok{\# get confidence intervals}
  
\NormalTok{  eff\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $age_p
##    age_p        fit          se      lower      upper
## 1     20 0.06690384 0.001915704 0.06324553 0.07075778
## 2     25 0.08852692 0.002181618 0.08434323 0.09289708
## 3     30 0.11626770 0.002418813 0.11161020 0.12109307
## 4     35 0.15125876 0.002603243 0.14622690 0.15643204
## 5     40 0.19446321 0.002722428 0.18918282 0.19985467
## 6     45 0.24642528 0.002796260 0.24098582 0.25194677
## 7     50 0.30698073 0.002895857 0.30133437 0.31268554
## 8     55 0.37501156 0.003124112 0.36890868 0.38115441
## 9     60 0.44836479 0.003531792 0.44145305 0.45529654
## 10    65 0.52403564 0.004052454 0.51608756 0.53197156
## 11    70 0.59861876 0.004545531 0.58967801 0.60749436
## 12    75 0.66889903 0.004880732 0.65926418 0.67839434
## 13    80 0.73237506 0.004986539 0.72248912 0.74203457
## 
## $sex
##        sex       fit          se     lower     upper
## 1   1 Male 0.2994186 0.004188707 0.2912739 0.3076922
## 2 2 Female 0.2701044 0.003715028 0.2628852 0.2774472
## 
## $sleep
##   sleep       fit          se     lower     upper
## 1     3 0.2899941 0.003276427 0.2836147 0.2964575
## 2    30 0.2524895 0.007427001 0.2382124 0.2673219
## 3    50 0.2268657 0.012446183 0.2034008 0.2521806
## 4    80 0.1919843 0.018549461 0.1582199 0.2309771
## 5   100 0.1710955 0.021584286 0.1328287 0.2176200
## 
## $bmi
##   bmi       fit          se     lower     upper
## 1  10 0.2144084 0.004121590 0.2064409 0.2225972
## 2  30 0.2835093 0.002849407 0.2779580 0.2891272
## 3  60 0.4085485 0.007450161 0.3940311 0.4232272
## 4  80 0.5003663 0.012139141 0.4765911 0.5241398
## 5 100 0.5921593 0.016180071 0.5601051 0.6234481
\end{verbatim}

\hypertarget{exercise-2}{%
\subsection{Exercise 2}\label{exercise-2}}

\textbf{Logistic regression}

Use the \texttt{NH11} data set that we loaded earlier.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use \texttt{glm()} to conduct a logistic regression to predict ever worked (\texttt{everwrk}) using age (\texttt{age\_p}) and marital status (\texttt{r\_maritl}). Make sure you only keep the following two levels for \texttt{everwrk} (\texttt{1\ Yes} and \texttt{2\ No}). Hint: use the \texttt{factor()} function. Also, make sure to drop any \texttt{r\_maritl} levels that do not contain observations. Hint: see \texttt{?droplevels}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Predict the probability of working for each level of marital status. Hint: use \texttt{allEffects()}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

Note that the data are not perfectly clean and ready to be modeled. You will need to clean up at least some of the variables before fitting the model.

{Click for Exercise 2 Solution}

\begin{alert}

Use the NH11 data set that we loaded earlier. Note that the data is not perfectly clean and ready to be modeled. You will need to clean up at least some of the variables before fitting the model.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use \texttt{glm()} to conduct a logistic regression to predict ever worked (\texttt{everwrk}) using age (\texttt{age\_p}) and marital status (\texttt{r\_maritl}). Make sure you only keep the following two levels for \texttt{everwrk} (\texttt{1\ Yes} and \texttt{2\ No}). Hint: use the \texttt{factor()} function. Also, make sure to drop any \texttt{r\_maritl} levels that do not contain observations. Hint: see \texttt{?droplevels}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  NH11 \textless{}{-}}\StringTok{ }
\StringTok{      }\NormalTok{NH11 }\OperatorTok{\%\textgreater{}\%}
\StringTok{      }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{everwrk =} \KeywordTok{factor}\NormalTok{(everwrk, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"1 Yes"}\NormalTok{, }\StringTok{"2 No"}\NormalTok{)),}
             \DataTypeTok{r\_maritl =} \KeywordTok{droplevels}\NormalTok{(r\_maritl)}
\NormalTok{             )}

\NormalTok{  mod\_wk\_age\_mar \textless{}{-}}\StringTok{ }\KeywordTok{glm}\NormalTok{(everwrk }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{age\_p }\OperatorTok{+}\StringTok{ }\NormalTok{r\_maritl, }
                        \DataTypeTok{data =}\NormalTok{ NH11,}
                        \DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link =} \StringTok{"logit"}\NormalTok{))}

  \KeywordTok{summary}\NormalTok{(mod\_wk\_age\_mar)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = everwrk ~ 1 + age_p + r_maritl, family = binomial(link = "logit"), 
##     data = NH11)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.0436  -0.5650  -0.4391  -0.3370   2.7308  
## 
## Coefficients:
##                                              Estimate Std. Error z value
## (Intercept)                                 -0.440248   0.093538  -4.707
## age_p                                       -0.029812   0.001645 -18.118
## r_maritl2 Married - spouse not in household  0.049675   0.217310   0.229
## r_maritl4 Widowed                            0.683618   0.084335   8.106
## r_maritl5 Divorced                          -0.730115   0.111681  -6.538
## r_maritl6 Separated                         -0.128091   0.151366  -0.846
## r_maritl7 Never married                      0.343611   0.069222   4.964
## r_maritl8 Living with partner               -0.443583   0.137770  -3.220
## r_maritl9 Unknown marital status             0.395480   0.492967   0.802
##                                             Pr(>|z|)    
## (Intercept)                                 2.52e-06 ***
## age_p                                        < 2e-16 ***
## r_maritl2 Married - spouse not in household  0.81919    
## r_maritl4 Widowed                           5.23e-16 ***
## r_maritl5 Divorced                          6.25e-11 ***
## r_maritl6 Separated                          0.39742    
## r_maritl7 Never married                     6.91e-07 ***
## r_maritl8 Living with partner                0.00128 ** 
## r_maritl9 Unknown marital status             0.42241    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 11082  on 14039  degrees of freedom
## Residual deviance: 10309  on 14031  degrees of freedom
##   (18974 observations deleted due to missingness)
## AIC: 10327
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Predict the probability of working for each level of marital status. Hint: use \texttt{allEffects()}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  mod\_wk\_age\_mar }\OperatorTok{\%\textgreater{}\%}\StringTok{ }
\StringTok{      }\KeywordTok{allEffects}\NormalTok{() }\OperatorTok{\%\textgreater{}\%}
\StringTok{      }\KeywordTok{as.data.frame}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $age_p
##   age_p        fit          se      lower      upper
## 1    20 0.27587439 0.011448539 0.25400910 0.29886780
## 2    30 0.22043363 0.007483648 0.20611629 0.23545053
## 3    50 0.13477473 0.003183752 0.12865574 0.14113761
## 4    70 0.07902788 0.003053617 0.07324630 0.08522385
## 5    80 0.05987515 0.003123927 0.05403759 0.06629914
## 
## $r_maritl
##                              r_maritl        fit          se      lower
## 1     1 Married - spouse in household 0.10822000 0.004259644 0.10014980
## 2 2 Married - spouse not in household 0.11310823 0.021393167 0.07746061
## 3                           4 Widowed 0.19381087 0.010634762 0.17381358
## 4                          5 Divorced 0.05524394 0.005361664 0.04562877
## 5                         6 Separated 0.09646417 0.012707502 0.07426824
## 6                     7 Never married 0.14611000 0.007459212 0.13208775
## 7               8 Living with partner 0.07224958 0.008904955 0.05662466
## 8            9 Unknown marital status 0.15270076 0.063528455 0.06440837
##        upper
## 1 0.11685606
## 2 0.16227532
## 3 0.21550873
## 4 0.06674358
## 5 0.12440219
## 6 0.16134411
## 7 0.09176661
## 8 0.32055728
\end{verbatim}

\end{alert}

\hypertarget{multilevel-modeling}{%
\section{Multilevel modeling}\label{multilevel-modeling}}

\begin{alert}

\textbf{GOAL: To learn about how to use the \texttt{lmer()} function to model clustered data.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The formula syntax for incorporating random effects into a model
\item
  Calculating the intraclass correlation (ICC)
\item
  Model comparison for fixed and random effects
\end{enumerate}

\end{alert}

\hypertarget{multilevel-modeling-overview}{%
\subsection{Multilevel modeling overview}\label{multilevel-modeling-overview}}

\begin{itemize}
\tightlist
\item
  Multi-level (AKA hierarchical) models are a type of \textbf{mixed-effects} model
\item
  They are used to model data that are clustered (i.e., non-independent)
\item
  Mixed-effects models include two types of predictors: \textbf{fixed-effects} and \textbf{random effects}

  \begin{itemize}
  \tightlist
  \item
    \textbf{Fixed-effects} -- observed levels are of direct interest (.e.g, sex, political party\ldots)
  \item
    \textbf{Random-effects} -- observed levels not of direct interest: goal is to make inferences to a population represented by observed levels
  \item
    In R, the \texttt{lme4} package is the most popular for mixed effects models
  \item
    Use the \texttt{lmer()} function for liner mixed models, \texttt{glmer()} for generalized linear mixed models
  \end{itemize}
\end{itemize}

\hypertarget{the-exam-data}{%
\subsection{The Exam data}\label{the-exam-data}}

The Exam data set contains exam scores of 4,059 students from 65 schools in Inner London. The variable names are as follows:

\begin{longtable}[]{@{}ll@{}}
\toprule
Variable & Description\tabularnewline
\midrule
\endhead
school & School ID - a factor.\tabularnewline
normexam & Normalized exam score.\tabularnewline
standLRT & Standardized LR test score.\tabularnewline
student & Student id (within school) - a factor\tabularnewline
\bottomrule
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  Exam \textless{}{-}}\StringTok{ }\KeywordTok{read\_rds}\NormalTok{(}\StringTok{"dataSets/Exam.rds"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{the-null-model-icc}{%
\subsection{The null model \& ICC}\label{the-null-model-icc}}

As a preliminary step it is often useful to partition the variance in the dependent variable into the various levels. This can be accomplished by running a null model (i.e., a model with a random effects grouping structure, but no fixed-effects predictors).

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# anatomy of lmer() function}
  \KeywordTok{lmer}\NormalTok{(outcome }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{pred1 }\OperatorTok{+}\StringTok{ }\NormalTok{pred2 }\OperatorTok{+}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{|}\StringTok{ }\NormalTok{grouping\_variable), }
       \DataTypeTok{data =}\NormalTok{ mydata)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# null model, grouping by school but not fixed effects.}
\NormalTok{  Norm1 \textless{}{-}}\KeywordTok{lmer}\NormalTok{(normexam }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{|}\StringTok{ }\NormalTok{school), }
              \DataTypeTok{data =} \KeywordTok{na.omit}\NormalTok{(Exam))}
  \KeywordTok{summary}\NormalTok{(Norm1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Linear mixed model fit by REML ['lmerMod']
## Formula: normexam ~ 1 + (1 | school)
##    Data: na.omit(Exam)
## 
## REML criterion at convergence: 9962.9
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.8749 -0.6452  0.0045  0.6888  3.6836 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  school   (Intercept) 0.1634   0.4042  
##  Residual             0.8520   0.9231  
## Number of obs: 3662, groups:  school, 65
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) -0.01310    0.05312  -0.247
\end{verbatim}

The is .161/(.161 + .852) = .159 = 16\% of the variance is at the school level.

There is no consensus on how to calculate p-values for MLMs; hence why they are omitted from the \texttt{lme4} output.
But, if you really need p-values, the \texttt{lmerTest} package will calculate p-values for you (using the Satterthwaite
approximation).

\hypertarget{adding-fixed-effects-predictors}{%
\subsection{Adding fixed-effects predictors}\label{adding-fixed-effects-predictors}}

Here's a theoretical model that predicts exam scores from student's standardized tests scores:

\begin{alert}

\[
examscores_{ij} = \mu1 + \beta_1testscores_{ij} + U_{0j} + \epsilon_{ij}
\]

\end{alert}

where \(U_{0j}\) is the random intercept for the \(j\)th \texttt{school}. Let's implement this in R using \texttt{lmer()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  Norm2 \textless{}{-}}\KeywordTok{lmer}\NormalTok{(normexam }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{standLRT }\OperatorTok{+}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{|}\StringTok{ }\NormalTok{school),}
               \DataTypeTok{data =} \KeywordTok{na.omit}\NormalTok{(Exam)) }
  \KeywordTok{summary}\NormalTok{(Norm2) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Linear mixed model fit by REML ['lmerMod']
## Formula: normexam ~ 1 + standLRT + (1 | school)
##    Data: na.omit(Exam)
## 
## REML criterion at convergence: 8483.5
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.6725 -0.6300  0.0234  0.6777  3.3340 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  school   (Intercept) 0.09369  0.3061  
##  Residual             0.56924  0.7545  
## Number of obs: 3662, groups:  school, 65
## 
## Fixed effects:
##               Estimate Std. Error t value
## (Intercept) -4.313e-05  4.055e-02  -0.001
## standLRT     5.669e-01  1.324e-02  42.821
## 
## Correlation of Fixed Effects:
##          (Intr)
## standLRT 0.007
\end{verbatim}

\hypertarget{multiple-degree-of-freedom-comparisons}{%
\subsection{Multiple degree of freedom comparisons}\label{multiple-degree-of-freedom-comparisons}}

As with \texttt{lm()} and \texttt{glm()} models, you can compare the two \texttt{lmer()} models using the \texttt{anova()} function. With mixed effects models, this will produce a likelihood ratio test.

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{anova}\NormalTok{(Norm1, Norm2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Data: na.omit(Exam)
## Models:
## Norm1: normexam ~ 1 + (1 | school)
## Norm2: normexam ~ 1 + standLRT + (1 | school)
##       npar    AIC    BIC  logLik deviance  Chisq Df Pr(>Chisq)    
## Norm1    3 9964.9 9983.5 -4979.4   9958.9                         
## Norm2    4 8480.1 8505.0 -4236.1   8472.1 1486.8  1  < 2.2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\hypertarget{random-slopes}{%
\subsection{Random slopes}\label{random-slopes}}

Add a random effect of students' standardized test scores as well. Now in addition to estimating the distribution of intercepts across schools, we also estimate the distribution of the slope of exam on standardized test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  Norm3 \textless{}{-}}\StringTok{ }\KeywordTok{lmer}\NormalTok{(normexam }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{standLRT }\OperatorTok{+}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{standLRT }\OperatorTok{|}\StringTok{ }\NormalTok{school), }
                \DataTypeTok{data =} \KeywordTok{na.omit}\NormalTok{(Exam)) }
  \KeywordTok{summary}\NormalTok{(Norm3) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Linear mixed model fit by REML ['lmerMod']
## Formula: normexam ~ 1 + standLRT + (1 + standLRT | school)
##    Data: na.omit(Exam)
## 
## REML criterion at convergence: 8442.8
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.7904 -0.6246  0.0245  0.6734  3.4376 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  school   (Intercept) 0.09092  0.3015       
##           standLRT    0.01639  0.1280   0.49
##  Residual             0.55589  0.7456       
## Number of obs: 3662, groups:  school, 65
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) -0.01250    0.04011  -0.312
## standLRT     0.56094    0.02119  26.474
## 
## Correlation of Fixed Effects:
##          (Intr)
## standLRT 0.360
\end{verbatim}

\hypertarget{test-the-significance-of-the-random-slope}{%
\subsection{Test the significance of the random slope}\label{test-the-significance-of-the-random-slope}}

To test the significance of a random slope just compare models with and without the random slope term using a likelihood ratio test:

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{anova}\NormalTok{(Norm2, Norm3) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Data: na.omit(Exam)
## Models:
## Norm2: normexam ~ 1 + standLRT + (1 | school)
## Norm3: normexam ~ 1 + standLRT + (1 + standLRT | school)
##       npar    AIC    BIC  logLik deviance Chisq Df Pr(>Chisq)    
## Norm2    4 8480.1 8505.0 -4236.1   8472.1                        
## Norm3    6 8444.1 8481.4 -4216.1   8432.1 40.01  2  2.051e-09 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\hypertarget{exercise-3-1}{%
\subsection{Exercise 3}\label{exercise-3-1}}

\textbf{Multilevel modeling}

Use the \texttt{bh1996} dataset:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# install.packages("multilevel")}
\KeywordTok{data}\NormalTok{(bh1996, }\DataTypeTok{package=}\StringTok{"multilevel"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

From the data documentation:

\begin{quote}
Variables are Leadership Climate (\texttt{LEAD}), Well-Being (\texttt{WBEING}), and Work Hours (\texttt{HRS}). The group identifier is named \texttt{GRP}.
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a null model predicting wellbeing (\texttt{WBEING})
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Calculate the ICC for your null model
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Run a second multi-level model that adds two individual-level predictors, average number of hours worked (\texttt{HRS}) and leadership skills (\texttt{LEAD}) to the model and interpret your output.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Now, add a random effect of average number of hours worked (\texttt{HRS}) to the model and interpret your output. Test the significance of this random term.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

{Click for Exercise 3 Solution}

\begin{alert}

Use the dataset, bh1996:

\begin{Shaded}
\begin{Highlighting}[]
  \CommentTok{\# install.packages("multilevel")}
  \KeywordTok{data}\NormalTok{(bh1996, }\DataTypeTok{package=}\StringTok{"multilevel"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

From the data documentation:

\begin{quote}
Variables are Leadership Climate (\texttt{LEAD}), Well-Being (\texttt{WBEING}), and Work Hours (\texttt{HRS}). The group identifier is named \texttt{GRP}.
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a null model predicting wellbeing (\texttt{WBEING}).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  mod\_grp0 \textless{}{-}}\StringTok{ }\KeywordTok{lmer}\NormalTok{(WBEING }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{|}\StringTok{ }\NormalTok{GRP), }\DataTypeTok{data =} \KeywordTok{na.omit}\NormalTok{(bh1996))}
  \KeywordTok{summary}\NormalTok{(mod\_grp0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Linear mixed model fit by REML ['lmerMod']
## Formula: WBEING ~ 1 + (1 | GRP)
##    Data: na.omit(bh1996)
## 
## REML criterion at convergence: 19347.3
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.3217 -0.6475  0.0311  0.7182  2.6674 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  GRP      (Intercept) 0.0358   0.1892  
##  Residual             0.7895   0.8885  
## Number of obs: 7382, groups:  GRP, 99
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)   2.7743     0.0222   124.9
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Run a second multi-level model that adds two individual-level predictors, average number of hours worked (\texttt{HRS}) and leadership skills (\texttt{LEAD}) to the model and interpret your output.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  mod\_grp1 \textless{}{-}}\StringTok{ }\KeywordTok{lmer}\NormalTok{(WBEING }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{HRS }\OperatorTok{+}\StringTok{ }\NormalTok{LEAD }\OperatorTok{+}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{|}\StringTok{ }\NormalTok{GRP), }\DataTypeTok{data =} \KeywordTok{na.omit}\NormalTok{(bh1996))}
  \KeywordTok{summary}\NormalTok{(mod\_grp1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Linear mixed model fit by REML ['lmerMod']
## Formula: WBEING ~ 1 + HRS + LEAD + (1 | GRP)
##    Data: na.omit(bh1996)
## 
## REML criterion at convergence: 17860
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.9188 -0.6588  0.0382  0.7040  3.6440 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  GRP      (Intercept) 0.01929  0.1389  
##  Residual             0.64668  0.8042  
## Number of obs: 7382, groups:  GRP, 99
## 
## Fixed effects:
##              Estimate Std. Error t value
## (Intercept)  1.686160   0.067702  24.906
## HRS         -0.031617   0.004378  -7.221
## LEAD         0.500743   0.012811  39.087
## 
## Correlation of Fixed Effects:
##      (Intr) HRS   
## HRS  -0.800       
## LEAD -0.635  0.121
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Now, add a random effect of average number of hours worked (\texttt{HRS}) to the model and interpret your output. Test the significance of this random term.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  mod\_grp2 \textless{}{-}}\StringTok{ }\KeywordTok{lmer}\NormalTok{(WBEING }\OperatorTok{\textasciitilde{}}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{HRS }\OperatorTok{+}\StringTok{ }\NormalTok{LEAD }\OperatorTok{+}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\NormalTok{HRS }\OperatorTok{|}\StringTok{ }\NormalTok{GRP), }\DataTypeTok{data =} \KeywordTok{na.omit}\NormalTok{(bh1996))}
  \KeywordTok{anova}\NormalTok{(mod\_grp1, mod\_grp2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Data: na.omit(bh1996)
## Models:
## mod_grp1: WBEING ~ 1 + HRS + LEAD + (1 | GRP)
## mod_grp2: WBEING ~ 1 + HRS + LEAD + (1 + HRS | GRP)
##          npar   AIC   BIC  logLik deviance  Chisq Df Pr(>Chisq)
## mod_grp1    5 17848 17882 -8918.9    17838                     
## mod_grp2    7 17851 17899 -8918.3    17837 1.2202  2     0.5433
\end{verbatim}

\end{alert}

\hypertarget{wrap-up-2}{%
\section{Wrap-up}\label{wrap-up-2}}

\hypertarget{feedback-2}{%
\subsection{Feedback}\label{feedback-2}}

These workshops are a work in progress, please provide any feedback to: \href{mailto:help@iq.harvard.edu}{\nolinkurl{help@iq.harvard.edu}}

\hypertarget{resources-3}{%
\subsection{Resources}\label{resources-3}}

\begin{itemize}
\tightlist
\item
  IQSS

  \begin{itemize}
  \tightlist
  \item
    Workshops: \url{https://dss.iq.harvard.edu/workshop-materials}
  \item
    Data Science Services: \url{https://dss.iq.harvard.edu/}
  \item
    Research Computing Environment: \url{https://iqss.github.io/dss-rce/}
  \end{itemize}
\item
  HBS

  \begin{itemize}
  \tightlist
  \item
    Research Computing Services workshops: \url{https://training.rcs.hbs.org/workshops}
  \item
    Other HBS RCS resources: \url{https://training.rcs.hbs.org/workshop-materials}
  \item
    RCS consulting email: \url{mailto:research@hbs.edu}
  \end{itemize}
\end{itemize}

\hypertarget{r-graphics}{%
\chapter{R Graphics}\label{r-graphics}}

\textbf{Topics}

\begin{itemize}
\tightlist
\item
  R \texttt{ggplot2} package
\item
  Geometric objects and aesthetics
\item
  Setup basic plots
\item
  Add and modify scales and legends
\item
  Manipulate plot labels
\item
  Change and create plot themes
\end{itemize}

\hypertarget{setup-2}{%
\section{Setup}\label{setup-2}}

\hypertarget{software-and-materials-2}{%
\subsection{Software and Materials}\label{software-and-materials-2}}

Follow the \href{./Rinstall.html}{R Installation} instructions and ensure that you can successfully start RStudio.

\hypertarget{class-structure-2}{%
\subsection{Class Structure}\label{class-structure-2}}

Informal - Ask questions at any time. Really!

Collaboration is encouraged - please spend a minute introducing yourself to your neighbors!

\hypertarget{prerequisites-2}{%
\subsection{Prerequisites}\label{prerequisites-2}}

This is an intermediate R course:

\begin{itemize}
\tightlist
\item
  Assumes working knowledge of R
\item
  Relatively fast-paced
\end{itemize}

\hypertarget{launch-an-r-session-1}{%
\subsection{Launch an R session}\label{launch-an-r-session-1}}

Start RStudio and create a new project:

\begin{itemize}
\tightlist
\item
  On Windows click the start button and search for RStudio. On Mac
  RStudio will be in your applications folder.
\item
  In Rstudio go to \texttt{File\ -\textgreater{}\ New\ Project}.
\item
  Choose \texttt{Existing\ Directory} and browse to the workshop materials directory on your desktop.
\item
  Choose \texttt{File\ -\textgreater{}\ Open\ File} and select the file with the word ``BLANK'' in the name.
\end{itemize}

\hypertarget{packages-1}{%
\subsection{Packages}\label{packages-1}}

You should have already installed the \texttt{tidyverse} and \texttt{rmarkdown}
packages onto your computer before the workshop
--- see \href{./Rinstall.html}{R Installation}.
Now let's load these packages into the search path of our R session.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(rmarkdown)}
\end{Highlighting}
\end{Shaded}

The \texttt{ggplot2} package is contained within \texttt{tidyverse}, but we also want to
install two additional packages, \texttt{scales} and \texttt{ggrepel}, which provide
additional functionality.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# install.packages("scales")}
\KeywordTok{library}\NormalTok{(scales)}

\CommentTok{\# install.packages("ggrepel") }
\KeywordTok{library}\NormalTok{(ggrepel)}
\end{Highlighting}
\end{Shaded}

\hypertarget{goals-2}{%
\subsection{Goals}\label{goals-2}}

\begin{alert}

We will learn about the \texttt{grammar\ of\ graphics} --- a system for understanding
the building blocks of a graph --- using the \texttt{ggplot2} package. In particular,
we'll learn about:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Basic plots, \textbf{aesthetic mapping and inheritance}
\item
  Tailoring \textbf{statistical transformations} to particular plots
\item
  \textbf{Modifying scales} to change axes and add labels
\item
  \textbf{Faceting} to create many small plots
\item
  Changing plot \textbf{themes}
\end{enumerate}

\end{alert}

\hypertarget{why-ggplot2}{%
\section{\texorpdfstring{Why \texttt{ggplot2}?}{Why ggplot2?}}\label{why-ggplot2}}

\texttt{ggplot2} is a package within in the \texttt{tidyverse} suite of packages. Advantages of \texttt{ggplot2} include:

\begin{itemize}
\tightlist
\item
  consistent underlying \texttt{grammar\ of\ graphics} (Wilkinson, 2005)
\item
  very flexible --- plot specification at a high level of abstraction
\item
  theme system for polishing plot appearance
\item
  many users, active mailing list
\end{itemize}

That said, there are some things you cannot (or should not) do with \texttt{ggplot2}:

\begin{itemize}
\tightlist
\item
  3-dimensional graphics (see the \texttt{rgl} package)
\item
  Graph-theory type graphs (nodes/edges layout; see the \texttt{igraph} package)
\item
  Interactive graphics (see the \texttt{ggvis} package)
\end{itemize}

\hypertarget{what-is-the-grammar-of-graphics}{%
\subsection{What is the Grammar Of Graphics?}\label{what-is-the-grammar-of-graphics}}

The basic idea: independently specify plot building blocks and combine them to create just
about any kind of graphical display you want. Building blocks of a graph include the
following (\textbf{bold denotes essential elements}):

\begin{itemize}
\tightlist
\item
  \textbf{data}
\item
  \textbf{aesthetic mapping}
\item
  \textbf{geometric object}
\item
  statistical transformations
\item
  scales
\item
  coordinate system
\item
  position adjustments
\item
  faceting
\item
  themes
\end{itemize}

By the end of this workshop, you should understand what these building blocks do and
how to use them to create the following plot:

\includegraphics{R/Rgraphics/images/final_plot.png}

\hypertarget{ggplot2-vs-base-graphics}{%
\subsection{\texorpdfstring{\texttt{ggplot2} VS base graphics}{ggplot2 VS base graphics}}\label{ggplot2-vs-base-graphics}}

Compared to base graphics, \texttt{ggplot2}

\begin{itemize}
\tightlist
\item
  is more verbose for simple / canned graphics
\item
  is less verbose for complex / custom graphics
\item
  does not have methods (data should always be in a \texttt{data.frame})
\item
  has sensible defaults for generating legends
\end{itemize}

\hypertarget{geometric-objects-aesthetics}{%
\section{Geometric objects \& aesthetics}\label{geometric-objects-aesthetics}}

\hypertarget{aesthetic-mapping}{%
\subsection{Aesthetic mapping}\label{aesthetic-mapping}}

In ggplot land \emph{aesthetic} means ``something you can see''. Examples include:

\begin{itemize}
\tightlist
\item
  position (i.e., on the x and y axes)
\item
  color (``outside'' color)
\item
  fill (``inside'' color)
\item
  shape (of points)
\item
  linetype
\item
  size
\end{itemize}

Each type of geom accepts only a subset of all aesthetics; refer to the geom help pages to see what mappings each geom accepts. Aesthetic mappings are set with the \texttt{aes()} function.

\hypertarget{geometric-objects-geom}{%
\subsection{\texorpdfstring{Geometric objects (\texttt{geom})}{Geometric objects (geom)}}\label{geometric-objects-geom}}

Geometric objects are the actual marks we put on a plot. Examples include:

\begin{itemize}
\tightlist
\item
  points (\texttt{geom\_point()}, for scatter plots, dot plots, etc.)
\item
  lines (\texttt{geom\_line()}, for time series, trend lines, etc.)
\item
  boxplot (\texttt{geom\_boxplot()}, for boxplots!)
\end{itemize}

A plot \textbf{must have at least one geom}; there is no upper limit. You can add a geom to a plot using the \texttt{+} operator.

Each \texttt{geom\_} has a particular set of aesthetic mappings associated with it. Some examples are provided below,
with required aesthetics in \textbf{bold} and optional aesthetics in plain text:

\begin{longtable}[]{@{}lll@{}}
\toprule
\begin{minipage}[b]{0.13\columnwidth}\raggedright
\texttt{geom\_}\strut
\end{minipage} & \begin{minipage}[b]{0.14\columnwidth}\raggedright
Usage\strut
\end{minipage} & \begin{minipage}[b]{0.65\columnwidth}\raggedright
Aesthetics\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.13\columnwidth}\raggedright
\texttt{geom\_point()}\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
Scatter plot\strut
\end{minipage} & \begin{minipage}[t]{0.65\columnwidth}\raggedright
\textbf{\texttt{x}},\textbf{\texttt{y}},\texttt{alpha},\texttt{color},\texttt{fill},\texttt{group},\texttt{shape},\texttt{size},\texttt{stroke}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.13\columnwidth}\raggedright
\texttt{geom\_line()}\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
Line plot\strut
\end{minipage} & \begin{minipage}[t]{0.65\columnwidth}\raggedright
\textbf{\texttt{x}},\textbf{\texttt{y}},\texttt{alpha},\texttt{color},\texttt{linetype},\texttt{size}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.13\columnwidth}\raggedright
\texttt{geom\_bar()}\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
Bar chart\strut
\end{minipage} & \begin{minipage}[t]{0.65\columnwidth}\raggedright
\textbf{\texttt{x}},\textbf{\texttt{y}},\texttt{alpha},\texttt{color},\texttt{fill},\texttt{group},\texttt{linetype},\texttt{size}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.13\columnwidth}\raggedright
\texttt{geom\_boxplot()}\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
Boxplot\strut
\end{minipage} & \begin{minipage}[t]{0.65\columnwidth}\raggedright
\textbf{\texttt{x}},\textbf{\texttt{lower}},\textbf{\texttt{upper}},\textbf{\texttt{middle}},\textbf{\texttt{ymin}},\textbf{\texttt{ymax}},\texttt{alpha},\texttt{color},\texttt{fill}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.13\columnwidth}\raggedright
\texttt{geom\_density()}\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
Density plot\strut
\end{minipage} & \begin{minipage}[t]{0.65\columnwidth}\raggedright
\textbf{\texttt{x}},\textbf{\texttt{y}},\texttt{alpha},\texttt{color},\texttt{fill},\texttt{group},\texttt{linetype},\texttt{size},\texttt{weight}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.13\columnwidth}\raggedright
\texttt{geom\_smooth()}\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
Conditional means\strut
\end{minipage} & \begin{minipage}[t]{0.65\columnwidth}\raggedright
\textbf{\texttt{x}},\textbf{\texttt{y}},\texttt{alpha},\texttt{color},\texttt{fill},\texttt{group},\texttt{linetype},\texttt{size},\texttt{weight}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.13\columnwidth}\raggedright
\texttt{geom\_label()}\strut
\end{minipage} & \begin{minipage}[t]{0.14\columnwidth}\raggedright
Text\strut
\end{minipage} & \begin{minipage}[t]{0.65\columnwidth}\raggedright
\textbf{\texttt{x}},\textbf{\texttt{y}},\textbf{\texttt{label}},\texttt{alpha},\texttt{angle},\texttt{color},\texttt{family},\texttt{fontface},\texttt{size}\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

You can get a list of all available geometric objects and their associated aesthetics at \url{https://ggplot2.tidyverse.org/reference/}. Or, simply type \texttt{geom\_\textless{}tab\textgreater{}} in any good R IDE (such as Rstudio) to see a list of functions starting with \texttt{geom\_}.

\hypertarget{points-scatterplot}{%
\subsubsection{Points (scatterplot)}\label{points-scatterplot}}

Now that we know about geometric objects and aesthetic mapping, we can make a \texttt{ggplot()}. \texttt{geom\_point()} requires mappings for x and y, all others are optional.

\textbf{Example data: housing prices}

Let's look at housing prices.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{housing \textless{}{-}}\StringTok{ }\KeywordTok{read\_csv}\NormalTok{(}\StringTok{"dataSets/landdata{-}states.csv"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(housing[}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{]) }\CommentTok{\# view first 5 columns}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 5
##   State region  Date Home_Value Structure_Cost
##   <chr> <chr>  <dbl>      <dbl>          <dbl>
## 1 AK    West   2010.     224952         160599
## 2 AK    West   2010.     225511         160252
## 3 AK    West   2010.     225820         163791
## 4 AK    West   2010      224994         161787
## 5 AK    West   2008      234590         155400
## 6 AK    West   2008.     233714         157458
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create a subset for 1st quarter 2001}
\NormalTok{hp2001Q1 \textless{}{-}}\StringTok{ }\NormalTok{housing }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{filter}\NormalTok{(Date }\OperatorTok{==}\StringTok{ }\FloatTok{2001.25}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Step 1:} create a blank canvas by specifying data:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ hp2001Q1)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-142-1.pdf}

\textbf{Step 2:} specify aesthetic mappings (how you want to map variables to visual aspects):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# here we map "Land\_Value" and "Structure\_Cost" to the x{-} and y{-}axes.}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ hp2001Q1, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Land\_Value, }\DataTypeTok{y =}\NormalTok{ Structure\_Cost))}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-143-1.pdf}

\textbf{Step 3:} add new layers of geometric objects that will show up on the plot:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# here we use geom\_point() to add a layer with point (dot) elements }
\CommentTok{\# as the geometric shapes to represent the data.}
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ hp2001Q1, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Land\_Value, }\DataTypeTok{y =}\NormalTok{ Structure\_Cost)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-144-1.pdf}

\hypertarget{lines-prediction-line}{%
\subsubsection{Lines (prediction line)}\label{lines-prediction-line}}

A plot constructed with \texttt{ggplot()} can have more than one geom. In that case the mappings established in the \texttt{ggplot()} call are plot defaults that can be added to or overridden --- this is referred to as \textbf{aesthetic inheritance}. Our plot could use a regression line:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# get predicted values from a linear regression}
\NormalTok{hp2001Q1}\OperatorTok{$}\NormalTok{pred\_SC \textless{}{-}}\StringTok{ }\KeywordTok{lm}\NormalTok{(Structure\_Cost }\OperatorTok{\textasciitilde{}}\StringTok{ }\KeywordTok{log}\NormalTok{(Land\_Value), }\DataTypeTok{data =}\NormalTok{ hp2001Q1) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{predict}\NormalTok{()}

\NormalTok{p1 \textless{}{-}}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(hp2001Q1, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{log}\NormalTok{(Land\_Value), }\DataTypeTok{y =}\NormalTok{ Structure\_Cost))}

\NormalTok{p1 }\OperatorTok{+}\StringTok{ }\KeywordTok{geom\_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ Home\_Value)) }\OperatorTok{+}\StringTok{ }\CommentTok{\# values for x and y are inherited from the ggplot() call above}
\StringTok{  }\KeywordTok{geom\_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ pred\_SC)) }\CommentTok{\# add predicted values to the plot overriding the y values from the ggplot() call above}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-145-1.pdf}

\hypertarget{smoothers}{%
\subsubsection{Smoothers}\label{smoothers}}

Not all geometric objects are simple shapes; the smooth geom includes a line and a ribbon.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ Home\_Value)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_smooth}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-146-1.pdf}

\hypertarget{text-label-points}{%
\subsubsection{Text (label points)}\label{text-label-points}}

Each geom accepts a particular set of mappings; for example \texttt{geom\_text()} accepts a \texttt{label} mapping.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom\_text}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =}\NormalTok{ State), }\DataTypeTok{size =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-147-1.pdf}

But what if we want to include points and labels? We can use \texttt{geom\_text\_repel()} to keep labels from overlapping the points and each other.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom\_text\_repel}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =}\NormalTok{ State), }\DataTypeTok{size =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-148-1.pdf}

\hypertarget{aesthetic-mapping-vs-assignment}{%
\subsection{Aesthetic mapping VS assignment}\label{aesthetic-mapping-vs-assignment}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Variables are \textbf{mapped} to aesthetics inside the \texttt{aes()} function.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{size =}\NormalTok{ Home\_Value))}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-149-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Constants are \textbf{assigned} to aesthetics outside the \texttt{aes()} call
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{(}\DataTypeTok{size =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-150-1.pdf}

This sometimes leads to confusion, as in this example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{size =} \DecValTok{2}\NormalTok{),}\CommentTok{\# incorrect! 2 is not a variable}
             \DataTypeTok{color=}\StringTok{"red"}\NormalTok{) }\CommentTok{\# this is fine {-}{-} all points red}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-151-1.pdf}

\hypertarget{mapping-variables-to-other-aesthetics}{%
\subsection{Mapping variables to other aesthetics}\label{mapping-variables-to-other-aesthetics}}

Other aesthetics are mapped in the same way as x and y in the previous example.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ Home\_Value, }\DataTypeTok{shape =}\NormalTok{ region))}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-152-1.pdf}

\hypertarget{exercise-0-2}{%
\subsection{Exercise 0}\label{exercise-0-2}}

The data for the exercises is available in the \texttt{dataSets/EconomistData.csv} file. Read it in with

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dat \textless{}{-}}\StringTok{ }\KeywordTok{read\_csv}\NormalTok{(}\StringTok{"dataSets/EconomistData.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Original sources for these data are \url{http://www.transparency.org/content/download/64476/1031428} \url{http://hdrstats.undp.org/en/indicators/display_cf_xls_indicator.cfm?indicator_id=103106\&lang=en}

These data consist of \emph{Human Development Index} and \emph{Corruption Perception Index} scores for several countries.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a scatter plot with \texttt{CPI} on the x axis and \texttt{HDI} on the y axis.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Color the points in the previous plot blue.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Map the color of the the points to \texttt{Region}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Keeping color mapped to \texttt{Region}, make the points bigger by setting size to 2
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Keeping color mapped to \texttt{Region}, map the size of the points to \texttt{HDI\_Rank}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

{Click for Exercise 0 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a scatter plot with \texttt{CPI} on the x axis and \texttt{HDI} on the y axis.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ CPI, }\DataTypeTok{y =}\NormalTok{ HDI)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-159-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Color the points in the previous plot blue.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ CPI, }\DataTypeTok{y =}\NormalTok{ HDI)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{(}\DataTypeTok{color =} \StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-160-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Map the color of the the points to \texttt{Region}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ CPI, }\DataTypeTok{y =}\NormalTok{ HDI)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ Region))}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-161-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Keeping color mapped to \texttt{Region}, make the points bigger by setting size to 2.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ CPI, }\DataTypeTok{y =}\NormalTok{ HDI)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ Region), }\DataTypeTok{size =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-162-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Keeping color mapped to \texttt{Region}, map the size of the points to \texttt{HDI\_Rank}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ CPI, }\DataTypeTok{y =}\NormalTok{ HDI)) }\OperatorTok{+}
\KeywordTok{geom\_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ Region, }\DataTypeTok{size =}\NormalTok{  HDI\_Rank))}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-163-1.pdf}

\end{alert}

\hypertarget{statistical-transformations}{%
\section{Statistical transformations}\label{statistical-transformations}}

\hypertarget{why-transform-data}{%
\subsection{Why transform data?}\label{why-transform-data}}

Some plot types (such as scatterplots) do not require transformations; each point is plotted at x and y coordinates equal to the original value. Other plots, such as boxplots, histograms, prediction lines etc. require statistical transformations:

\begin{itemize}
\tightlist
\item
  for a boxplot the y values must be transformed to the median and 1.5(IQR)
\item
  for a smoother the y values must be transformed into predicted values
\end{itemize}

Each geom has a default statistic, but these can be changed. For example, the default statistic for \texttt{geom\_histogram()} is \texttt{stat\_bin()}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{args}\NormalTok{(geom\_histogram)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## function (mapping = NULL, data = NULL, stat = "bin", position = "stack", 
##     ..., binwidth = NULL, bins = NULL, na.rm = FALSE, orientation = NA, 
##     show.legend = NA, inherit.aes = TRUE) 
## NULL
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{args}\NormalTok{(stat\_bin)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## function (mapping = NULL, data = NULL, geom = "bar", position = "stack", 
##     ..., binwidth = NULL, bins = NULL, center = NULL, boundary = NULL, 
##     breaks = NULL, closed = c("right", "left"), pad = FALSE, 
##     na.rm = FALSE, orientation = NA, show.legend = NA, inherit.aes = TRUE) 
## NULL
\end{verbatim}

Here is a list of geoms and their default statistics \url{https://ggplot2.tidyverse.org/reference/}

\hypertarget{setting-arguments}{%
\subsection{Setting arguments}\label{setting-arguments}}

Arguments to \texttt{stat\_} functions can be passed through \texttt{geom\_} functions. This can be slightly annoying because in order to change them you have to first determine which stat the geom uses, then determine the arguments to that stat.

For example, here is the default histogram of \texttt{Home\_Value}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p2 \textless{}{-}}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(housing, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Home\_Value))}
\NormalTok{p2 }\OperatorTok{+}\StringTok{ }\KeywordTok{geom\_histogram}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-165-1.pdf}

We can change the binning scheme by passing the \texttt{binwidth} argument to the \texttt{stat\_bin()} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p2 }\OperatorTok{+}\StringTok{ }\KeywordTok{geom\_histogram}\NormalTok{(}\DataTypeTok{stat =} \StringTok{"bin"}\NormalTok{, }\DataTypeTok{binwidth =} \DecValTok{4000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-166-1.pdf}

\hypertarget{changing-the-transformation}{%
\subsection{Changing the transformation}\label{changing-the-transformation}}

Sometimes the default statistical transformation is not what you need. This is often the case with pre-summarized data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{housing\_sum \textless{}{-}}\StringTok{ }
\StringTok{  }\NormalTok{housing }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{group\_by}\NormalTok{(State) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{Home\_Value\_Mean =} \KeywordTok{mean}\NormalTok{(Home\_Value)) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{()}

\KeywordTok{head}\NormalTok{(housing\_sum)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   State Home_Value_Mean
##   <chr>           <dbl>
## 1 AK            147385.
## 2 AL             92545.
## 3 AR             82077.
## 4 AZ            140756.
## 5 CA            282808.
## 6 CO            158176.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(housing\_sum, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ State, }\DataTypeTok{y =}\NormalTok{ Home\_Value\_Mean)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom\_bar}\NormalTok{()}

\CommentTok{\#\# Error: stat\_count() must not be used with a y aesthetic.  }
\end{Highlighting}
\end{Shaded}

What is the problem with the previous plot? Basically we take binned and summarized data and ask ggplot to bin and summarize it again (remember, \texttt{geom\_bar()} defaults to \texttt{stat\ =\ stat\_count}; obviously this will not work. We can fix it by telling \texttt{geom\_bar()} to use a different statistical transformation function. The \texttt{identity} function returns the same output as the input.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(housing\_sum, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ State, }\DataTypeTok{y =}\NormalTok{ Home\_Value\_Mean)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom\_bar}\NormalTok{(}\DataTypeTok{stat =} \StringTok{"identity"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-169-1.pdf}

\hypertarget{exercise-1-2}{%
\subsection{Exercise 1}\label{exercise-1-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Re-create a scatter plot with \texttt{CPI} on the x axis and \texttt{HDI} on the y axis (as you did in the previous exercise).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Overlay a smoothing line on top of the scatter plot using \texttt{geom\_smooth()}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Make the smoothing line in \texttt{geom\_smooth()} less smooth. Hint: see \texttt{?loess}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Change the smoothing line in \texttt{geom\_smooth()} to use a linear model for the predictions. Hint: see \texttt{?stat\_smooth}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  BONUS 1: Allow the smoothing line created in the last plot to vary across the levels of \texttt{Region}. Hint: map \texttt{Region} to the color and fill aesthetics.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  BONUS 2: Overlay a loess \texttt{(method\ =\ "loess")} smoothing line on top of the scatter plot using \texttt{geom\_line()}. Hint: change the statistical transformation.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

{Click for Exercise 1 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Re-create a scatter plot with \texttt{CPI} on the x axis and \texttt{HDI} on the y axis (as you did in the previous exercise).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ CPI, }\DataTypeTok{y =}\NormalTok{ HDI)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-176-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Overlay a smoothing line on top of the scatter plot using \texttt{geom\_smooth()}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ CPI, }\DataTypeTok{y =}\NormalTok{ HDI)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_smooth}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-177-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Make the smoothing line in \texttt{geom\_smooth()} less smooth. Hint: see \texttt{?loess}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ CPI, }\DataTypeTok{y =}\NormalTok{ HDI)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_smooth}\NormalTok{(}\DataTypeTok{span =} \FloatTok{.4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-178-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Change the smoothing line in \texttt{geom\_smooth()} to use a linear model for the predictions. Hint: see \texttt{?stat\_smooth}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ CPI, }\DataTypeTok{y =}\NormalTok{ HDI)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-179-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  BONUS 1: Allow the smoothing line created in the last plot to vary across the levels of \texttt{Region}. Hint: map \texttt{Region} to the color and fill aesthetics.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ CPI, }\DataTypeTok{y =}\NormalTok{ HDI, }\DataTypeTok{color =}\NormalTok{ Region, }\DataTypeTok{fill =}\NormalTok{ Region)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-180-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  BONUS 2: Overlay a loess \texttt{(method\ =\ "loess")} smoothing line on top of the scatter plot using \texttt{geom\_line()}. Hint: change the statistical transformation.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ CPI, }\DataTypeTok{y =}\NormalTok{ HDI)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_line}\NormalTok{(}\DataTypeTok{stat =} \StringTok{"smooth"}\NormalTok{, }\DataTypeTok{method =} \StringTok{"loess"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-181-1.pdf}

\end{alert}

\hypertarget{scales}{%
\section{Scales}\label{scales}}

\hypertarget{controlling-aesthetic-mapping}{%
\subsection{Controlling aesthetic mapping}\label{controlling-aesthetic-mapping}}

Aesthetic mapping (i.e., with \texttt{aes()}) only says that a variable should be mapped to an aesthetic. It doesn't say \emph{how} that should happen. For example, when mapping a variable to \emph{shape} with \texttt{aes(shape\ =\ x)} you don't say \emph{what} shapes should be used. Similarly, \texttt{aes(color\ =\ y)} doesn't say \emph{what} colors should be used. Also, \texttt{aes(size\ =\ z)} doesn't say \emph{what} sizes should be used. Describing what colors/shapes/sizes etc. to use is done by modifying the corresponding \emph{scale}. In \texttt{ggplot2} scales include

\begin{itemize}
\tightlist
\item
  position
\item
  color and fill
\item
  size
\item
  shape
\item
  line type
\end{itemize}

Scales are modified with a series of functions using a \texttt{scale\_\textless{}aesthetic\textgreater{}\_\textless{}type\textgreater{}} naming scheme. Try typing \texttt{scale\_\textless{}tab\textgreater{}} to see a list of scale modification functions.

\hypertarget{common-scale-arguments}{%
\subsection{Common scale arguments}\label{common-scale-arguments}}

The following arguments are common to most scales in \texttt{ggplot2}:

\begin{itemize}
\tightlist
\item
  \textbf{name:} the axis or legend title
\item
  \textbf{limits:} the minimum and maximum of the scale
\item
  \textbf{breaks:} the points along the scale where labels should appear
\item
  \textbf{labels:} the labels that appear at each break
\end{itemize}

Specific scale functions may have additional arguments; for example, the \texttt{scale\_color\_continuous()} function has arguments \texttt{low} and \texttt{high} for setting the colors at the low and high end of the scale.

\hypertarget{scale-modification-examples}{%
\subsection{Scale modification examples}\label{scale-modification-examples}}

Start by constructing a dotplot showing the distribution of home values by \texttt{Date} and \texttt{State}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p4 \textless{}{-}}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(housing, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ State, }\DataTypeTok{y =}\NormalTok{ Home\_Price\_Index)) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{geom\_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ Date), }\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{size =} \FloatTok{1.5}\NormalTok{,}
               \DataTypeTok{position =} \KeywordTok{position\_jitter}\NormalTok{(}\DataTypeTok{width =} \FloatTok{0.25}\NormalTok{, }\DataTypeTok{height =} \DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Now modify the breaks for the color scales

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p4 }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale\_color\_continuous}\NormalTok{(}\DataTypeTok{name=}\StringTok{""}\NormalTok{,}
                         \DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{1976}\NormalTok{, }\DecValTok{1994}\NormalTok{, }\DecValTok{2013}\NormalTok{),}
                         \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"\textquotesingle{}76"}\NormalTok{, }\StringTok{"\textquotesingle{}94"}\NormalTok{, }\StringTok{"\textquotesingle{}13"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-183-1.pdf}

Next change the low and high values to blue and red:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p4 }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale\_color\_continuous}\NormalTok{(}\DataTypeTok{name=}\StringTok{""}\NormalTok{,}
                         \DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{1976}\NormalTok{, }\DecValTok{1994}\NormalTok{, }\DecValTok{2013}\NormalTok{),}
                         \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"\textquotesingle{}76"}\NormalTok{, }\StringTok{"\textquotesingle{}94"}\NormalTok{, }\StringTok{"\textquotesingle{}13"}\NormalTok{),}
                         \DataTypeTok{low =} \StringTok{"blue"}\NormalTok{, }\DataTypeTok{high =} \StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-184-1.pdf}

\hypertarget{using-different-color-scales}{%
\subsection{Using different color scales}\label{using-different-color-scales}}

\texttt{ggplot2} has a wide variety of color scales; here is an example using \texttt{scale\_color\_gradient2()} to interpolate between three different colors.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p4 }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale\_color\_gradient2}\NormalTok{(}\DataTypeTok{name=}\StringTok{""}\NormalTok{,}
                        \DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{1976}\NormalTok{, }\DecValTok{1994}\NormalTok{, }\DecValTok{2013}\NormalTok{),}
                        \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"\textquotesingle{}76"}\NormalTok{, }\StringTok{"\textquotesingle{}94"}\NormalTok{, }\StringTok{"\textquotesingle{}13"}\NormalTok{),}
                        \DataTypeTok{low =} \StringTok{"blue"}\NormalTok{,}
                        \DataTypeTok{high =} \StringTok{"red"}\NormalTok{,}
                        \DataTypeTok{mid =} \StringTok{"gray60"}\NormalTok{,}
                        \DataTypeTok{midpoint =} \DecValTok{1994}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-185-1.pdf}

\hypertarget{available-scales}{%
\subsection{Available scales}\label{available-scales}}

\begin{itemize}
\tightlist
\item
  Partial combination matrix of available scales
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule
\texttt{scale\_} & Types & Examples\tabularnewline
\midrule
\endhead
\texttt{scale\_color\_} & \texttt{identity} & \texttt{scale\_fill\_continuous()}\tabularnewline
\texttt{scale\_fill\_} & \texttt{manual} & \texttt{scale\_color\_discrete()}\tabularnewline
\texttt{scale\_size\_} & \texttt{continuous} & \texttt{scale\_size\_manual()}\tabularnewline
& \texttt{discrete} & \texttt{scale\_size\_discrete()}\tabularnewline
& &\tabularnewline
\texttt{scale\_shape\_} & \texttt{discrete} & \texttt{scale\_shape\_discrete()}\tabularnewline
\texttt{scale\_linetype\_} & \texttt{identity} & \texttt{scale\_shape\_manual()}\tabularnewline
& \texttt{manual} & \texttt{scale\_linetype\_discrete()}\tabularnewline
& &\tabularnewline
\texttt{scale\_x\_} & \texttt{continuous} & \texttt{scale\_x\_continuous()}\tabularnewline
\texttt{scale\_y\_} & \texttt{discrete} & \texttt{scale\_y\_discrete()}\tabularnewline
& \texttt{reverse} & \texttt{scale\_x\_log()}\tabularnewline
& \texttt{log} & \texttt{scale\_y\_reverse()}\tabularnewline
& \texttt{date} & \texttt{scale\_x\_date()}\tabularnewline
& \texttt{datetime} & \texttt{scale\_y\_datetime()}\tabularnewline
\bottomrule
\end{longtable}

Note that in RStudio you can type \texttt{scale\_} followed by \texttt{tab} to get the whole list of available scales. For a complete list of available scales see \url{https://ggplot2.tidyverse.org/reference/}

\hypertarget{exercise-2-1}{%
\subsection{Exercise 2}\label{exercise-2-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a scatter plot with \texttt{CPI} on the x axis and \texttt{HDI} on the y axis. Color the points to indicate \texttt{Region}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Modify the x, y, and color scales so that they have more easily-understood names (e.g., spell out ``Human development Index'' instead of \texttt{HDI}). Hint: see \texttt{?scale\_x\_continous}, \texttt{?scale\_y\_continuous}, and \texttt{?scale\_color\_discrete}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Modify the color scale to use specific values of your choosing. Hint: see \texttt{?scale\_color\_manual}. NOTE: you can specify color by name (e.g., ``blue'') or by ``Hex value'' --- see \url{https://www.color-hex.com/}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

{Click for Exercise 2 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a scatter plot with \texttt{CPI} on the x axis and \texttt{HDI} on the y axis. Color the points to indicate \texttt{Region}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ CPI, }\DataTypeTok{y =}\NormalTok{ HDI, }\DataTypeTok{color =}\NormalTok{ Region)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-189-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Modify the x, y, and color scales so that they have more easily-understood names (e.g., spell out ``Human development Index'' instead of \texttt{HDI}).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ CPI, }\DataTypeTok{y =}\NormalTok{ HDI, }\DataTypeTok{color =}\NormalTok{ Region)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale\_x\_continuous}\NormalTok{(}\DataTypeTok{name =} \StringTok{"Corruption Perception Index"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale\_y\_continuous}\NormalTok{(}\DataTypeTok{name =} \StringTok{"Human Development Index"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale\_color\_discrete}\NormalTok{(}\DataTypeTok{name =} \StringTok{"Region of the world"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-190-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Modify the color scale to use specific values of your choosing. Hint: see \texttt{?scale\_color\_manual}. NOTE: you can specify color by name (e.g., ``blue'') or by ``Hex value'' --- see \url{https://www.color-hex.com/}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(dat, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ CPI, }\DataTypeTok{y =}\NormalTok{ HDI, }\DataTypeTok{color =}\NormalTok{ Region)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale\_x\_continuous}\NormalTok{(}\DataTypeTok{name =} \StringTok{"Corruption Perception Index"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale\_y\_continuous}\NormalTok{(}\DataTypeTok{name =} \StringTok{"Human Development Index"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale\_color\_manual}\NormalTok{(}\DataTypeTok{name =} \StringTok{"Region of the world"}\NormalTok{,}
                     \DataTypeTok{values =} \KeywordTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"green"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"orange"}\NormalTok{, }\StringTok{"grey"}\NormalTok{, }\StringTok{"brown"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-191-1.pdf}

\end{alert}

\hypertarget{faceting}{%
\section{Faceting}\label{faceting}}

\hypertarget{what-is-faceting}{%
\subsection{What is faceting?}\label{what-is-faceting}}

\begin{itemize}
\tightlist
\item
  Faceting is \texttt{ggplot2} parlance for \textbf{small multiples}
\item
  The idea is to create separate graphs for subsets of data
\item
  \texttt{ggplot2} offers two functions for creating small multiples:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    \texttt{facet\_wrap()}: define subsets as the levels of a single grouping variable
  \item
    \texttt{facet\_grid()}: define subsets as the crossing of two grouping variables
  \end{enumerate}
\item
  Facilitates comparison among plots, not just of geoms within a plot
\end{itemize}

\hypertarget{what-is-the-trend-in-housing-prices-in-each-state}{%
\subsection{What is the trend in housing prices in each state?}\label{what-is-the-trend-in-housing-prices-in-each-state}}

Start by using a technique we already know; map \texttt{State} to color:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p5 \textless{}{-}}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(housing, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Date, }\DataTypeTok{y =}\NormalTok{ Home\_Value))}
\NormalTok{p5 }\OperatorTok{+}\StringTok{ }\KeywordTok{geom\_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ State))  }
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-192-1.pdf}

There are two problems here; there are too many states to distinguish each one by color, and the lines obscure one another.

\hypertarget{faceting-to-the-rescue}{%
\subsection{Faceting to the rescue}\label{faceting-to-the-rescue}}

We can remedy the deficiencies of the previous plot by faceting by \texttt{State} rather than mapping \texttt{State} to color.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p5 \textless{}{-}}\StringTok{ }\NormalTok{p5 }\OperatorTok{+}\StringTok{ }\KeywordTok{geom\_line}\NormalTok{() }\OperatorTok{+}
\StringTok{   }\KeywordTok{facet\_wrap}\NormalTok{(}\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{State, }\DataTypeTok{ncol =} \DecValTok{10}\NormalTok{)}
\NormalTok{p5}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-193-1.pdf}

\hypertarget{themes}{%
\section{Themes}\label{themes}}

\hypertarget{what-are-themes}{%
\subsection{What are themes?}\label{what-are-themes}}

The \texttt{ggplot2} theme system handles non-data plot elements such as:

\begin{itemize}
\tightlist
\item
  Axis label properties (e.g., font, size, color, etc.)
\item
  Plot background
\item
  Facet label background
\item
  Legend appearance
\end{itemize}

Built-in themes include:

\begin{itemize}
\tightlist
\item
  \texttt{theme\_gray()} (default)
\item
  \texttt{theme\_bw()}
\item
  \texttt{theme\_classic()}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p5 }\OperatorTok{+}\StringTok{ }\KeywordTok{theme\_linedraw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-194-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p5 }\OperatorTok{+}\StringTok{ }\KeywordTok{theme\_light}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-195-1.pdf}
You can see a list of available built-in themes here \url{https://ggplot2.tidyverse.org/reference/}

\hypertarget{overriding-theme-defaults}{%
\subsection{Overriding theme defaults}\label{overriding-theme-defaults}}

Specific theme elements can be overridden using \texttt{theme()}. For example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# theme(thing\_to\_modify = modifying\_function(arg1, arg2))}

\NormalTok{p5 }\OperatorTok{+}\StringTok{ }\KeywordTok{theme\_minimal}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{text =} \KeywordTok{element\_text}\NormalTok{(}\DataTypeTok{color =} \StringTok{"red"}\NormalTok{))  }
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-196-1.pdf}

All theme options are documented in \texttt{?theme}. We can also see the
existing default values using:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{theme\_get}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{creating-saving-new-themes}{%
\subsection{Creating \& saving new themes}\label{creating-saving-new-themes}}

You can create new themes, as in the following example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theme\_new \textless{}{-}}\StringTok{ }\KeywordTok{theme\_bw}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{plot.background =} \KeywordTok{element\_rect}\NormalTok{(}\DataTypeTok{size =} \DecValTok{1}\NormalTok{, }\DataTypeTok{color =} \StringTok{"blue"}\NormalTok{, }\DataTypeTok{fill =} \StringTok{"black"}\NormalTok{),}
        \DataTypeTok{text =} \KeywordTok{element\_text}\NormalTok{(}\DataTypeTok{size =} \DecValTok{12}\NormalTok{, }\DataTypeTok{color =} \StringTok{"ivory"}\NormalTok{),}
        \DataTypeTok{axis.text.y =} \KeywordTok{element\_text}\NormalTok{(}\DataTypeTok{colour =} \StringTok{"purple"}\NormalTok{),}
        \DataTypeTok{axis.text.x =} \KeywordTok{element\_text}\NormalTok{(}\DataTypeTok{colour =} \StringTok{"red"}\NormalTok{),}
        \DataTypeTok{panel.background =} \KeywordTok{element\_rect}\NormalTok{(}\DataTypeTok{fill =} \StringTok{"pink"}\NormalTok{),}
        \DataTypeTok{strip.background =} \KeywordTok{element\_rect}\NormalTok{(}\DataTypeTok{fill =} \KeywordTok{muted}\NormalTok{(}\StringTok{"orange"}\NormalTok{)))}

\NormalTok{p5 }\OperatorTok{+}\StringTok{ }\NormalTok{theme\_new}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-198-1.pdf}

\hypertarget{saving-plots}{%
\section{Saving plots}\label{saving-plots}}

We can save a plot to either a vector (e.g., pdf, eps, ps, svg)
or raster (e.g., jpg, png, tiff, bmp, wmf) graphics file using
the \texttt{ggsave()} function:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggsave}\NormalTok{(}\DataTypeTok{filename =} \StringTok{"myplot.pdf"}\NormalTok{, }\DataTypeTok{plot =}\NormalTok{ p5, }\DataTypeTok{device =} \StringTok{"pdf"}\NormalTok{, }\DataTypeTok{height =} \DecValTok{6}\NormalTok{, }\DataTypeTok{width =} \DecValTok{6}\NormalTok{, }\DataTypeTok{units =} \StringTok{"in"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{the-1-faq}{%
\section{The \#1 FAQ}\label{the-1-faq}}

\hypertarget{map-aesthetic-to-different-columns}{%
\subsection{Map aesthetic to different columns}\label{map-aesthetic-to-different-columns}}

The most frequently asked question goes something like this: \emph{I have two variables in my data.frame, and I'd like to plot them as separate points, with different color depending on which variable it is. How do I do that?}

\textbf{Wrong}

Fixing, rather than mapping, the color aesthetic:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Produces verbose code when using many colors
\item
  Results in no legend being produced
\item
  Means you cannot change color scales
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{housing\_byyear \textless{}{-}}\StringTok{ }
\StringTok{  }\NormalTok{housing }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{group\_by}\NormalTok{(Date) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{Home\_Value\_Mean =} \KeywordTok{mean}\NormalTok{(Home\_Value),}
            \DataTypeTok{Land\_Value\_Mean =} \KeywordTok{mean}\NormalTok{(Land\_Value)) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{()}

\KeywordTok{ggplot}\NormalTok{(housing\_byyear, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{Date)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y=}\NormalTok{Home\_Value\_Mean), }\DataTypeTok{color=}\StringTok{"red"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y=}\NormalTok{Land\_Value\_Mean), }\DataTypeTok{color=}\StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-200-1.pdf}

\textbf{Right}

To avoid these pitfalls, we need to \textbf{map} our data to the color aesthetic.
We can do this by \textbf{reshaping} our data from \textbf{wide format} to \textbf{long format}.
Here is the logic behind this process:

\includegraphics{R/Rgraphics/images/wide_vs_long.png}

Here's the code that implements this transformation:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{home\_land\_byyear \textless{}{-}}\StringTok{ }
\StringTok{    }\NormalTok{housing\_byyear }\OperatorTok{\%\textgreater{}\%}
\StringTok{    }\KeywordTok{pivot\_longer}\NormalTok{(}\DataTypeTok{cols =} \KeywordTok{c}\NormalTok{(Home\_Value\_Mean, Land\_Value\_Mean),}
                 \DataTypeTok{names\_to =} \StringTok{"type"}\NormalTok{,}
                 \DataTypeTok{values\_to =} \StringTok{"value"}\NormalTok{)}
                          
\KeywordTok{ggplot}\NormalTok{(home\_land\_byyear, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Date, }\DataTypeTok{y =}\NormalTok{ value, }\DataTypeTok{color =}\NormalTok{ type)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-201-1.pdf}

\hypertarget{exercise-3-2}{%
\subsection{Exercise 3}\label{exercise-3-2}}

For this exercise, we're going to use the built-in \texttt{midwest} dataset:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(}\StringTok{"midwest"}\NormalTok{, }\DataTypeTok{package =} \StringTok{"ggplot2"}\NormalTok{)}
\KeywordTok{head}\NormalTok{(midwest)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 28
##     PID county state  area poptotal popdensity popwhite popblack popamerindian
##   <int> <chr>  <chr> <dbl>    <int>      <dbl>    <int>    <int>         <int>
## 1   561 ADAMS  IL    0.052    66090      1271.    63917     1702            98
## 2   562 ALEXA~ IL    0.014    10626       759      7054     3496            19
## 3   563 BOND   IL    0.022    14991       681.    14477      429            35
## 4   564 BOONE  IL    0.017    30806      1812.    29344      127            46
## 5   565 BROWN  IL    0.018     5836       324.     5264      547            14
## 6   566 BUREAU IL    0.05     35688       714.    35157       50            65
## # ... with 19 more variables: popasian <int>, popother <int>, percwhite <dbl>,
## #   percblack <dbl>, percamerindan <dbl>, percasian <dbl>, percother <dbl>,
## #   popadults <int>, perchsd <dbl>, percollege <dbl>, percprof <dbl>,
## #   poppovertyknown <int>, percpovertyknown <dbl>, percbelowpoverty <dbl>,
## #   percchildbelowpovert <dbl>, percadultpoverty <dbl>,
## #   percelderlypoverty <dbl>, inmetro <int>, category <chr>
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a scatter plot with \texttt{area} on the x axis and the log of \texttt{poptotal} on the y axis.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Within the \texttt{geom\_point()} call, map color to \texttt{state}, map size to the log of \texttt{popdensity}, and fix transparency (\texttt{alpha}) to 0.3.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Add a smoother and turn off plotting the confidence interval. Hint: see the \texttt{se} argument to \texttt{geom\_smooth()}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Facet the plot by \texttt{state}. Set the \texttt{scales} argument to \texttt{facet\_wrap()} to allow separate ranges for the x-axis.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Change the default color scale to use the discrete \texttt{RColorBrewer} palette called \texttt{Set1}. Hint: see \texttt{?scale\_color\_brewer}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  BONUS: Change the default theme to \texttt{theme\_bw()} and modify it so that the axis text and facet label background are blue. Hint: see \texttt{?theme} and especially \texttt{axis.text} and \texttt{strip.background}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

{Click for Exercise 3 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a scatter plot with \texttt{area} on the x axis and the log of \texttt{poptotal} on the y axis.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p6 \textless{}{-}}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(midwest, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ area, }\DataTypeTok{y =} \KeywordTok{log}\NormalTok{(poptotal))) }
\NormalTok{p6 }\OperatorTok{+}\StringTok{ }\KeywordTok{geom\_point}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-209-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Within the \texttt{geom\_point()} call, map color to \texttt{state}, map size to the log of \texttt{popdensity}, and fix transparency (\texttt{alpha}) to 0.3.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p6 \textless{}{-}}\StringTok{ }\NormalTok{p6 }\OperatorTok{+}\StringTok{ }\KeywordTok{geom\_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ state, }\DataTypeTok{size =} \KeywordTok{log}\NormalTok{(popdensity)), }\DataTypeTok{alpha =} \FloatTok{0.3}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Add a smoother and turn off plotting the confidence interval. Hint: see the \texttt{se} argument to \texttt{geom\_smooth()}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p6 \textless{}{-}}\StringTok{ }\NormalTok{p6 }\OperatorTok{+}\StringTok{ }\KeywordTok{geom\_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"loess"}\NormalTok{, }\DataTypeTok{se =} \OtherTok{FALSE}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Facet the plot by \texttt{state}. Set the \texttt{scales} argument to \texttt{facet\_wrap()} to allow separate ranges for the x-axis.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p6 \textless{}{-}}\StringTok{ }\NormalTok{p6 }\OperatorTok{+}\StringTok{ }\KeywordTok{facet\_wrap}\NormalTok{(}\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{state, }\DataTypeTok{scales =} \StringTok{"free\_x"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Change the default color scale to use the discrete \texttt{RColorBrewer} palette called \texttt{Set1}. Hint: see \texttt{?scale\_color\_brewer}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p6 \textless{}{-}}\StringTok{ }\NormalTok{p6 }\OperatorTok{+}\StringTok{ }\KeywordTok{scale\_color\_brewer}\NormalTok{(}\DataTypeTok{palette =} \StringTok{"Set1"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  BONUS: Change the default theme to \texttt{theme\_bw()} and modify it so that the axis text and facet label background are blue. Hint: see \texttt{?theme} and especially \texttt{axis.text} and \texttt{strip.background}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p6 \textless{}{-}}\StringTok{ }\NormalTok{p6 }\OperatorTok{+}\StringTok{ }\KeywordTok{theme\_bw}\NormalTok{() }\OperatorTok{+}
\StringTok{    }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{axis.title =} \KeywordTok{element\_text}\NormalTok{(}\DataTypeTok{color =} \StringTok{"blue"}\NormalTok{, }\DataTypeTok{face =} \StringTok{"bold"}\NormalTok{),}
          \DataTypeTok{strip.background =} \KeywordTok{element\_rect}\NormalTok{(}\DataTypeTok{fill =} \StringTok{"yellow"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Here's the complete code for the Exercise 3 plot:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p6 \textless{}{-}}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(midwest, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ area, }\DataTypeTok{y =} \KeywordTok{log}\NormalTok{(poptotal))) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom\_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ state, }\DataTypeTok{size =} \KeywordTok{log}\NormalTok{(popdensity)), }\DataTypeTok{alpha =} \FloatTok{0.3}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom\_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"loess"}\NormalTok{, }\DataTypeTok{se =} \OtherTok{FALSE}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{facet\_wrap}\NormalTok{(}\OperatorTok{\textasciitilde{}}\StringTok{ }\NormalTok{state, }\DataTypeTok{scales =} \StringTok{"free\_x"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{scale\_color\_brewer}\NormalTok{(}\DataTypeTok{palette =} \StringTok{"Set1"}\NormalTok{) }\OperatorTok{+}
\StringTok{    }\KeywordTok{theme\_bw}\NormalTok{() }\OperatorTok{+}
\StringTok{    }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{axis.title =} \KeywordTok{element\_text}\NormalTok{(}\DataTypeTok{color =} \StringTok{"blue"}\NormalTok{, }\DataTypeTok{face =} \StringTok{"bold"}\NormalTok{),}
         \DataTypeTok{strip.background =} \KeywordTok{element\_rect}\NormalTok{(}\DataTypeTok{fill =} \StringTok{"yellow"}\NormalTok{))}

\NormalTok{p6         }
\end{Highlighting}
\end{Shaded}

\includegraphics{R/Rgraphics/figures/unnamed-chunk-215-1.pdf}

\end{alert}

\hypertarget{wrap-up-3}{%
\section{Wrap-up}\label{wrap-up-3}}

\hypertarget{feedback-3}{%
\subsection{Feedback}\label{feedback-3}}

These workshops are a work in progress, please provide any feedback to: \href{mailto:help@iq.harvard.edu}{\nolinkurl{help@iq.harvard.edu}}

\hypertarget{resources-4}{%
\subsection{Resources}\label{resources-4}}

\begin{itemize}
\tightlist
\item
  IQSS

  \begin{itemize}
  \tightlist
  \item
    Workshops: \url{https://dss.iq.harvard.edu/workshop-materials}
  \item
    Data Science Services: \url{https://dss.iq.harvard.edu/}
  \item
    Research Computing Environment: \url{https://iqss.github.io/dss-rce/}
  \end{itemize}
\item
  HBS

  \begin{itemize}
  \tightlist
  \item
    Research Computing Services workshops: \url{https://training.rcs.hbs.org/workshops}
  \item
    Other HBS RCS resources: \url{https://training.rcs.hbs.org/workshop-materials}
  \item
    RCS consulting email: \url{mailto:research@hbs.edu}
  \end{itemize}
\item
  ggplot2

  \begin{itemize}
  \tightlist
  \item
    Reference: \url{https://ggplot2.tidyverse.org/reference/}
  \item
    Cheatsheets: \url{https://rstudio.com/wp-content/uploads/2019/01/Cheatsheets_2019.pdf}
  \item
    Examples: \url{http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html}
  \item
    Tutorial: \url{https://uc-r.github.io/ggplot_intro}
  \item
    Mailing list: \url{http://groups.google.com/group/ggplot2}
  \item
    Wiki: \url{https://github.com/hadley/ggplot2/wiki}
  \item
    Website: \url{http://had.co.nz/ggplot2/}
  \item
    StackOverflow: \url{http://stackoverflow.com/questions/tagged/ggplot}
  \end{itemize}
\end{itemize}

\hypertarget{r-data-wrangling}{%
\chapter{R Data Wrangling}\label{r-data-wrangling}}

\textbf{Topics}

\begin{itemize}
\tightlist
\item
  Loading Excel worksheets
\item
  Iterating over files
\item
  Writing your own functions
\item
  Filtering with regular expressions (regex)
\item
  Reshaping data
\end{itemize}

\hypertarget{setup-3}{%
\section{Setup}\label{setup-3}}

\hypertarget{software-and-materials-3}{%
\subsection{Software and Materials}\label{software-and-materials-3}}

Follow the \href{./Rinstall.html}{R Installation} instructions and ensure that you can successfully start RStudio.

\hypertarget{class-structure-3}{%
\subsection{Class Structure}\label{class-structure-3}}

Informal - Ask questions at any time. Really!

Collaboration is encouraged - please spend a minute introducing yourself to your neighbors!

\hypertarget{prerequisites-3}{%
\subsection{Prerequisites}\label{prerequisites-3}}

This is an intermediate / advanced R course:

\begin{itemize}
\tightlist
\item
  Assumes intermediate knowledge of R
\item
  Relatively fast-paced
\end{itemize}

\hypertarget{launch-an-r-session-2}{%
\subsection{Launch an R session}\label{launch-an-r-session-2}}

Start RStudio and create a new project:

\begin{itemize}
\tightlist
\item
  On Windows click the start button and search for RStudio. On Mac
  RStudio will be in your applications folder.
\item
  In Rstudio go to \texttt{File\ -\textgreater{}\ New\ Project}.
\item
  Choose \texttt{Existing\ Directory} and browse to the workshop materials directory on your desktop.
\item
  Choose \texttt{File\ -\textgreater{}\ Open\ File} and select the file with the word ``BLANK'' in the name.
\end{itemize}

\hypertarget{packages-2}{%
\subsection{Packages}\label{packages-2}}

You should have already installed the \texttt{tidyverse} and \texttt{rmarkdown}
packages onto your computer before the workshop
--- see \href{./Rinstall.html}{R Installation}.
Now let's load these packages into the search path of our R session.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(rmarkdown)}
\KeywordTok{library}\NormalTok{(readxl) }\CommentTok{\# installed with tidyverse, but not loaded into R session}
\end{Highlighting}
\end{Shaded}

\hypertarget{workshop-outline}{%
\subsection{Workshop Outline}\label{workshop-outline}}

\textbf{Example data}

The UK \href{https://www.ons.gov.uk}{Office for National Statistics} provides yearly
data on the most popular boys names going back to 1996. The data is provided
separately for boys and girls and is stored in Excel spreadsheets.

\textbf{Overall Goal}

Our mission is to extract and graph the \textbf{top 100} boys names in England and Wales for every year since 1996.

\includegraphics{R/RDataWrangling/images/goal.png}

\textbf{Exercise 0: Problems with the data}

There are several things that make our goal challenging. Let's take a look at the data:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Locate the files named \texttt{1996boys\_tcm77-254026.xlsx} and
  \texttt{2015boysnamesfinal.xlsx} and open them separately in a
  spreadsheet program.

  (If you don't have a spreadsheet program installed on
  your computer you can download one from
  \url{https://www.libreoffice.org/download/download/}).

  What issues can you identify that might make working
  with these data difficult?

  In what ways is the format different between the two files?
\end{enumerate}

{Click for Exercise 0 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Multiple Excel sheets in each file, each with a different name, but each file contains a \texttt{Table\ 1}.
\item
  The data does not start on row one. Headers are on row 7, followed by a blank line, followed by the actual data.
\item
  The data is stored in an inconvenient way, with ranks 1-50 in the first set of columns and ranks 51-100 in a second set of columns.
\item
  The second worksheet \texttt{2015boysnamesfinal.xlsx} contains extra columns between the data of interest, resulting in the second set of columns (ranks 51-100) being placed in a different position.
\item
  The year from which the data comes is only reported in the Excel file name, not within the data itself.
\item
  There are notes below the data.
\end{enumerate}

These differences will make it more difficult to automate re-arranging the data since we have to write code that can handle different input formats.

\end{alert}

\begin{alert}

\textbf{Steps to accomplish the goal of extracting and graphing the \emph{top 100} boys names in England and Wales for every year since 1996:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{-1}
\item
  \textbf{Explore example data to highlight problems (already done!)}
\item
  \textbf{Reading data from multiple Excel worksheets into R data frames}

  \begin{itemize}
  \tightlist
  \item
    list Excel file names in a character vector
  \item
    read Excel sheetnames into a list of character vectors
  \item
    read Excel data for ``Table 1'' only into a list of data frames
  \end{itemize}
\item
  \textbf{Clean up data within each R data frame}

  \begin{itemize}
  \tightlist
  \item
    sort and merge columns within each data frame inside the list
  \item
    drop missing values from each data frame
  \item
    reshape data format from wide to long
  \end{itemize}
\item
  \textbf{Organize the data into one large data frame and store it}

  \begin{itemize}
  \tightlist
  \item
    create a year column within each data frame within the list
  \item
    append all the data frames in the list into one large data frame
  \end{itemize}
\end{enumerate}

\end{alert}

NOTE: please make sure you close the Excel files before continuing with the
workshop, otherwise you may encounter issues with file paths when reading
the data into R.

\hypertarget{working-with-excel-worksheets}{%
\section{Working with Excel worksheets}\label{working-with-excel-worksheets}}

\begin{alert}

\textbf{GOAL: To learn how to read data from multiple Excel worksheets into R data frames.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  List Excel file names in a character vector
\item
  Read Excel sheetnames into a list of character vectors
\item
  Read Excel data for ``Table 1'' only into a list of data frames
\end{enumerate}

\end{alert}

As you can see, the data is in quite a messy state. Note that this is
not a contrived example; this is exactly the way the data came to us
from the UK government website! Let's start cleaning and organizing
it.

Each Excel file contains a worksheet with the boy names data we want.
Each file also contains additional supplemental worksheets that we are
not currently interested in. As noted above, the worksheet of interest
differs from year to year, but always has ``Table 1'' in the sheet name.

The first step is to get a character vector of file names.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{boy\_file\_names \textless{}{-}}\StringTok{ }\KeywordTok{list.files}\NormalTok{(}\StringTok{"dataSets/boys"}\NormalTok{, }\DataTypeTok{full.names =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Now that we've told R the names of the data files, we can start working
with them. For example, the first file is

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{boy\_file\_names[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "dataSets/boys/1996boys_tcm77-254026.xlsx"
\end{verbatim}

and we can use the \texttt{excel\_sheets()} function from the \texttt{readxl} package
within \texttt{tidyverse} to list the worksheet names from this file.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{excel\_sheets}\NormalTok{(boy\_file\_names[}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Contents"                     "Table 1 - Top 100 boys, E&W" 
## [3] "Table 2-Top 10 boys by month" "Table 3 - Boys names - E&W"
\end{verbatim}

\hypertarget{iterating-with-map}{%
\subsection{\texorpdfstring{Iterating with \texttt{map()}}{Iterating with map()}}\label{iterating-with-map}}

Now that we know how to retrieve the names of the worksheets in an
Excel file, we could start writing code to extract the sheet names from
each file, e.g.,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{excel\_sheets}\NormalTok{(boy\_file\_names[}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Contents"                     "Table 1 - Top 100 boys, E&W" 
## [3] "Table 2-Top 10 boys by month" "Table 3 - Boys names - E&W"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{excel\_sheets}\NormalTok{(boy\_file\_names[}\DecValTok{2}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Contents"                        "Table 1 - Top 100 boys, E&W"    
## [3] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
## [5] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
## [7] "Table 6 - Boys names - E&W"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# ...}
\KeywordTok{excel\_sheets}\NormalTok{(boy\_file\_names[}\DecValTok{20}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "Contents"             "Metadata"             "Terms and Conditions"
##  [4] "Table 1"              "Table 2"              "Table 3"             
##  [7] "Table 4"              "Table 5"              "Table 6"             
## [10] "Related Publications"
\end{verbatim}

This is not a terrible idea for a small number of files, but it is
more convenient to let R do the iteration for us. We could use a \texttt{for\ loop},
or \texttt{sapply()}, but the \texttt{map()} family of functions from the \texttt{purrr}
package within \texttt{tidyverse} gives us a more consistent alternative,
so we'll use that.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# map(object to iterate over, function that does task within each iteration)}

\KeywordTok{map}\NormalTok{(boy\_file\_names, excel\_sheets)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] "Contents"                     "Table 1 - Top 100 boys, E&W" 
## [3] "Table 2-Top 10 boys by month" "Table 3 - Boys names - E&W"  
## 
## [[2]]
## [1] "Contents"                        "Table 1 - Top 100 boys, E&W"    
## [3] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
## [5] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
## [7] "Table 6 - Boys names - E&W"     
## 
## [[3]]
## [1] "Contents"                        "Table 1 - Top 100 boys' names"  
## [3] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
## [5] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
## [7] "Table 6 - Boys names - E&W"     
## 
## [[4]]
## [1] "Contents"                        "Table 1 - Top 100 boys' names"  
## [3] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
## [5] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
## [7] "Table 6 - Boys names - E&W"     
## 
## [[5]]
## [1] "Contents"                        "Table 1 - Top 100 boys, E&W"    
## [3] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
## [5] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
## [7] "Table 6 - Boys names - E&W"     
## 
## [[6]]
## [1] "Contents"                        "Table 1 - Top 100 boys, E&W"    
## [3] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
## [5] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
## [7] "Table 6 - Boys names - E&W"     
## 
## [[7]]
## [1] "Contents"                        "Table 1 - Top 100 boys, E&W"    
## [3] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
## [5] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
## [7] "Table 6 - Boys names - E&W"     
## 
## [[8]]
## [1] "Contents"                        "Table 1 - Top 100 boys, E&W"    
## [3] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
## [5] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
## [7] "Table 6 - Boys names - E&W"     
## 
## [[9]]
## [1] "Contents"                        "Table 1 - Top 100 boys, E&W"    
## [3] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
## [5] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
## [7] "Table 6 - Boys names - E&W"     
## 
## [[10]]
## [1] "Contents"                        "Table 1 - Top 100 boys, E&W"    
## [3] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
## [5] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
## [7] "Table 6 - Boys names - E&W"     
## 
## [[11]]
## [1] "Contents"                        "Table 1 - Top 100 boys, E&W"    
## [3] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
## [5] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
## [7] "Table 6 - Boys names - E&W"     
## 
## [[12]]
## [1] "Contents"                        "Table 1 - Top 100 boys, E&W"    
## [3] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
## [5] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
## [7] "Table 6 - Boys names - E&W"     
## 
## [[13]]
## [1] "Contents"                        "Table 1 - Top 100 boys' names"  
## [3] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
## [5] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
## [7] "Table 6 - Boys names - E&W"     
## 
## [[14]]
## [1] "Contents"                        "Table 1 - Top 100 boys' names"  
## [3] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
## [5] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
## [7] "Table 6 - Boys names - E&W"     
## 
## [[15]]
## [1] "Contents"                        "Table 1 - Top 100 boys, E&W"    
## [3] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
## [5] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
## [7] "Table 6 - Boys names - E&W"     
## 
## [[16]]
##  [1] "Contents"                        "Metadata"                       
##  [3] "Terms and Conditions"            "Table 1 - Top 100 boys, E&W"    
##  [5] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
##  [7] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
##  [9] "Table 6 - Boys names - E&W"      "Related Publications"           
## 
## [[17]]
##  [1] "Contents"                        "Metadata"                       
##  [3] "Terms and Conditions"            "Table 1 - Top 100 boys, E&W"    
##  [5] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
##  [7] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
##  [9] "Table 6 - Boys names - E&W"      "Related Publications"           
## 
## [[18]]
##  [1] "Contents"                        "Metadata"                       
##  [3] "Terms and Conditions"            "Table 1 - Top 100 boys, E&W"    
##  [5] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
##  [7] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
##  [9] "Table 6 - Boys names - E&W"      "Related Publications"           
## 
## [[19]]
##  [1] "Contents"                        "Metadata"                       
##  [3] "Terms and Conditions"            "Table 1 - Top 100 boys, E&W"    
##  [5] "Table 2 - Top 100 boys, England" "Table 3 - Top 100 boys, Wales"  
##  [7] "Table 4 - Top 10 boys by region" "Table 5 - Top 10 boys by month" 
##  [9] "Table 6 - Boys names - E&W"      "Related Publications"           
## 
## [[20]]
##  [1] "Contents"             "Metadata"             "Terms and Conditions"
##  [4] "Table 1"              "Table 2"              "Table 3"             
##  [7] "Table 4"              "Table 5"              "Table 6"             
## [10] "Related Publications"
\end{verbatim}

\hypertarget{filtering-strings-using-regex}{%
\subsection{Filtering strings using regex}\label{filtering-strings-using-regex}}

To extract the correct worksheet names we need a way to extract
strings containing ``Table 1''.

Base R provides some string manipulation capabilities
(see \texttt{?regex}, \texttt{?sub} and \texttt{?grep}), but we will use the
\texttt{stringr} package within \texttt{tidyverse} because it is more
user-friendly. \texttt{stringr} provides functions to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  detect
\item
  locate
\item
  extract
\item
  match
\item
  replace
\item
  combine
\item
  split
\end{enumerate}

strings. Here we want to detect the pattern ``Table 1'', and only
return elements with this pattern. We can do that using the
\texttt{str\_subset()} function:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The first argument to \texttt{str\_subset()} is character vector we want to search in.
\item
  The second argument is a \emph{regular expression} matching the pattern we want to retain.
\end{enumerate}

If you are not familiar with regular expressions (regex),
\url{http://www.regexr.com/} is a good place to start. Regex is essentially
just a programmatic way of doing operations like ``find'' or ``find and replace''
in MS Word or Excel.

Now that we know how to filter character vectors using \texttt{str\_subset()} we can
identify the correct sheet in a particular Excel file. For example,

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# str\_subset(character\_vector, regex\_pattern)}

\CommentTok{\# nesting functions}
\KeywordTok{str\_subset}\NormalTok{(}\KeywordTok{excel\_sheets}\NormalTok{(boy\_file\_names[}\DecValTok{1}\NormalTok{]), }\DataTypeTok{pattern =} \StringTok{"Table 1"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Table 1 - Top 100 boys, E&W"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# piping functions}
\KeywordTok{excel\_sheets}\NormalTok{(boy\_file\_names[}\DecValTok{1}\NormalTok{]) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{str\_subset}\NormalTok{(}\DataTypeTok{pattern =} \StringTok{"Table 1"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Table 1 - Top 100 boys, E&W"
\end{verbatim}

\hypertarget{writing-your-own-functions}{%
\subsection{Writing your own functions}\label{writing-your-own-functions}}

The next step is to retrieve worksheet names and subset them.

The \texttt{map*} functions are useful when you want to apply a function to a
vector of inputs and obtain the return values for each input. This
is very convenient when a function already exists that does exactly what you
want. In the examples above we mapped the \texttt{excel\_sheets()} function to
the elements of a character vector containing file names.

However, there is no function that both:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Retrieves worksheet names, and
\item
  Subsets the names
\end{enumerate}

So, we will have to write one. Fortunately, writing functions in R is easy.
Functions require 3 elements:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A \textbf{name}
\item
  One or more \textbf{arguments}
\item
  A \textbf{body} containing computations
\end{enumerate}

Anatomy of a function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{function\_name \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(arg1, arg2, ....) \{}
  
\NormalTok{    body of }\ControlFlowTok{function} \CommentTok{\# where stuff happens }

    \KeywordTok{return}\NormalTok{( results ) }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Simple examples:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myfun \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{  x}\OperatorTok{\^{}}\DecValTok{2}
\NormalTok{\}}

\KeywordTok{myfun}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]   1   4   9  16  25  36  49  64  81 100
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myfun2 \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, y) \{}
\NormalTok{  z \textless{}{-}}\StringTok{ }\NormalTok{x}\OperatorTok{\^{}}\DecValTok{2} \OperatorTok{+}\StringTok{ }\NormalTok{y}
  \KeywordTok{return}\NormalTok{(z)}
\NormalTok{\}}

\KeywordTok{myfun2}\NormalTok{(}\DataTypeTok{x=}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{, }\DataTypeTok{y=}\DecValTok{42}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  43  46  51  58  67  78  91 106 123 142
\end{verbatim}

Examples using the Excel data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{get\_data\_sheet\_name \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(file, term)\{}
  \KeywordTok{excel\_sheets}\NormalTok{(file) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{str\_subset}\NormalTok{(}\DataTypeTok{pattern =}\NormalTok{ term)}
\NormalTok{\}}

\CommentTok{\# the goal is generalization }
\KeywordTok{get\_data\_sheet\_name}\NormalTok{(boy\_file\_names[}\DecValTok{1}\NormalTok{], }\DataTypeTok{term =} \StringTok{"Table 1"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Table 1 - Top 100 boys, E&W"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{get\_data\_sheet\_name}\NormalTok{(boy\_file\_names[}\DecValTok{1}\NormalTok{], }\DataTypeTok{term =} \StringTok{"Table 2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Table 2-Top 10 boys by month"
\end{verbatim}

Now we can map this new function over our vector of file names.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# map(object to iterate over, }
\CommentTok{\#     function that does task within each iteration, }
\CommentTok{\#     arguments to previous function)}
 
\KeywordTok{map}\NormalTok{(boy\_file\_names,      }\CommentTok{\# list object}
\NormalTok{    get\_data\_sheet\_name, }\CommentTok{\# function}
    \DataTypeTok{term =} \StringTok{"Table 1"}\NormalTok{)    }\CommentTok{\# argument to previous function}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] "Table 1 - Top 100 boys, E&W"
## 
## [[2]]
## [1] "Table 1 - Top 100 boys, E&W"
## 
## [[3]]
## [1] "Table 1 - Top 100 boys' names"
## 
## [[4]]
## [1] "Table 1 - Top 100 boys' names"
## 
## [[5]]
## [1] "Table 1 - Top 100 boys, E&W"
## 
## [[6]]
## [1] "Table 1 - Top 100 boys, E&W"
## 
## [[7]]
## [1] "Table 1 - Top 100 boys, E&W"
## 
## [[8]]
## [1] "Table 1 - Top 100 boys, E&W"
## 
## [[9]]
## [1] "Table 1 - Top 100 boys, E&W"
## 
## [[10]]
## [1] "Table 1 - Top 100 boys, E&W"
## 
## [[11]]
## [1] "Table 1 - Top 100 boys, E&W"
## 
## [[12]]
## [1] "Table 1 - Top 100 boys, E&W"
## 
## [[13]]
## [1] "Table 1 - Top 100 boys' names"
## 
## [[14]]
## [1] "Table 1 - Top 100 boys' names"
## 
## [[15]]
## [1] "Table 1 - Top 100 boys, E&W"
## 
## [[16]]
## [1] "Table 1 - Top 100 boys, E&W"
## 
## [[17]]
## [1] "Table 1 - Top 100 boys, E&W"
## 
## [[18]]
## [1] "Table 1 - Top 100 boys, E&W"
## 
## [[19]]
## [1] "Table 1 - Top 100 boys, E&W"
## 
## [[20]]
## [1] "Table 1"
\end{verbatim}

\hypertarget{reading-excel-data-files}{%
\section{Reading Excel data files}\label{reading-excel-data-files}}

Now that we know the correct worksheet from each file, we can actually
read those data into R. We can do that using the \texttt{read\_excel()} function.

We'll start by reading the data from the first file, just to check
that it works. Recall that the actual data starts on row 7, so we want
to skip the first 6 rows. We can use the \texttt{glimpse()} function from
the \texttt{dplyr} package within \texttt{tidyverse} to view the output.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{temp \textless{}{-}}\StringTok{ }\KeywordTok{read\_excel}\NormalTok{(}
  \DataTypeTok{path =}\NormalTok{ boy\_file\_names[}\DecValTok{1}\NormalTok{],}
  \DataTypeTok{sheet =} \KeywordTok{get\_data\_sheet\_name}\NormalTok{(boy\_file\_names[}\DecValTok{1}\NormalTok{], }\DataTypeTok{term =} \StringTok{"Table 1"}\NormalTok{),}
  \DataTypeTok{skip =} \DecValTok{6}
\NormalTok{)}

\KeywordTok{glimpse}\NormalTok{(temp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 59
## Columns: 7
## $ ...1      <chr> NA, "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "1...
## $ Name...2  <chr> NA, "JACK", "DANIEL", "THOMAS", "JAMES", "JOSHUA", "MATTH...
## $ Count...3 <dbl> NA, 10779, 10338, 9603, 9385, 7887, 7426, 6496, 6193, 616...
## $ ...4      <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N...
## $ ...5      <dbl> NA, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 6...
## $ Name...6  <chr> NA, "DOMINIC", "NICHOLAS", "BRANDON", "RHYS", "MARK", "MA...
## $ Count...7 <dbl> NA, 1519, 1385, 1337, 1259, 1222, 1192, 1186, 1135, 1128,...
\end{verbatim}

Note that R has added a suffix to each column name \texttt{...1}, \texttt{...2},
\texttt{...3}, etc. because duplicate names are not allowed, so the suffix serves
to disambiguate. The trailing number represents the index of the column.

\hypertarget{exercise-1-3}{%
\subsection{Exercise 1}\label{exercise-1-3}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a function called \texttt{read\_boys\_names} that takes a file name as an argument
  and reads the worksheet containing ``Table 1'' from that file. Don't forget
  to skip the first 6 rows.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Test your function by using it to read \emph{one} of the boys names
  Excel files.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Use the \texttt{map()} function to create a list of data frames called \texttt{boysNames}\\
  from all the Excel files, using the function you wrote in step 1.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

{Click for Exercise 1 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a function that takes a file name as an argument and reads the worksheet containing ``Table 1'' from that file.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{read\_boys\_names \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(file, sheet\_name) \{}
  \KeywordTok{read\_excel}\NormalTok{(}
    \DataTypeTok{path =}\NormalTok{ file,}
    \DataTypeTok{sheet =} \KeywordTok{get\_data\_sheet\_name}\NormalTok{(file, }\DataTypeTok{term =}\NormalTok{ sheet\_name),}
    \DataTypeTok{skip =} \DecValTok{6}
\NormalTok{  )}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Test your function by using it to read \emph{one} of the boys names Excel files.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{read\_boys\_names}\NormalTok{(boy\_file\_names[}\DecValTok{1}\NormalTok{], }\DataTypeTok{sheet\_name =} \StringTok{"Table 1"}\NormalTok{) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{glimpse}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 59
## Columns: 7
## $ ...1      <chr> NA, "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "1...
## $ Name...2  <chr> NA, "JACK", "DANIEL", "THOMAS", "JAMES", "JOSHUA", "MATTH...
## $ Count...3 <dbl> NA, 10779, 10338, 9603, 9385, 7887, 7426, 6496, 6193, 616...
## $ ...4      <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N...
## $ ...5      <dbl> NA, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 6...
## $ Name...6  <chr> NA, "DOMINIC", "NICHOLAS", "BRANDON", "RHYS", "MARK", "MA...
## $ Count...7 <dbl> NA, 1519, 1385, 1337, 1259, 1222, 1192, 1186, 1135, 1128,...
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Use the \texttt{map()} function to read data from all the Excel files, using the function you wrote in step 1.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{boysNames \textless{}{-}}\StringTok{ }\KeywordTok{map}\NormalTok{(boy\_file\_names, read\_boys\_names, }\DataTypeTok{sheet\_name =} \StringTok{"Table 1"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{data-cleanup}{%
\section{Data cleanup}\label{data-cleanup}}

\begin{alert}

\textbf{GOAL: To learn how to clean up data within each R data frame.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Sort and merge columns within each data frame inside the list
\item
  Drop missing values from each data frame
\item
  Reshape data format from wide to long
\end{enumerate}

\end{alert}

Now that we've read in the data, we can see that there are some
problems we need to fix. Specifically, we need to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  fix column names
\item
  get rid of blank row at the top and the notes at the bottom
\item
  get rid of extraneous ``changes in rank'' columns if they exist
\item
  transform the side-by-side tables layout to a single table
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Rank 1:50 {-}{-}{-} Names / Counts are in columns 2 and 3 }
\CommentTok{\# Rank 51:100 {-}{-}{-} Names / Counts are in columns 6 and 7}
\KeywordTok{glimpse}\NormalTok{(boysNames[[}\DecValTok{1}\NormalTok{]]) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 59
## Columns: 7
## $ ...1      <chr> NA, "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "1...
## $ Name...2  <chr> NA, "JACK", "DANIEL", "THOMAS", "JAMES", "JOSHUA", "MATTH...
## $ Count...3 <dbl> NA, 10779, 10338, 9603, 9385, 7887, 7426, 6496, 6193, 616...
## $ ...4      <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N...
## $ ...5      <dbl> NA, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 6...
## $ Name...6  <chr> NA, "DOMINIC", "NICHOLAS", "BRANDON", "RHYS", "MARK", "MA...
## $ Count...7 <dbl> NA, 1519, 1385, 1337, 1259, 1222, 1192, 1186, 1135, 1128,...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Rank 1:50 {-}{-}{-} Names / Counts are in columns 2 and 3 }
\CommentTok{\# Rank 51:100 {-}{-}{-} Names / Counts are in columns 7 and 8}
\KeywordTok{glimpse}\NormalTok{(boysNames[[}\DecValTok{10}\NormalTok{]]) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 61
## Columns: 9
## $ ...1             <chr> NA, "1", "2", "3", "4", "5", "6", "7", "8", "9", "...
## $ Name...2         <chr> NA, "JACK", "JOSHUA", "THOMAS", "JAMES", "OLIVER",...
## $ Count...3        <dbl> NA, 7434, 7167, 6792, 5654, 5516, 5270, 5219, 5106...
## $ `since 2004...4` <chr> NA, "-", "-", "-", "-", "+2", "-1", "-1", "-", "+2...
## $ ...5             <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA...
## $ ...6             <dbl> NA, 51, 52, 53, 53, 55, 56, 57, 58, 59, 60, 61, 62...
## $ Name...7         <chr> NA, "NOAH", "MUHAMMAD", "ALEX", "ISAAC", "OSCAR", ...
## $ Count...8        <dbl> NA, 1346, 1318, 1302, 1302, 1262, 1256, 1172, 1126...
## $ `since 2004...9` <chr> NA, "+23", "-1", "-7", "+5", "+4", "-4", "+6", "+1...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Rank 1:50 {-}{-}{-} Names / Counts are in columns 2 and 3 }
\CommentTok{\# Rank 51:100 {-}{-}{-} Names / Counts are in columns 8 and 9}
\KeywordTok{glimpse}\NormalTok{(boysNames[[}\DecValTok{20}\NormalTok{]]) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 61
## Columns: 11
## $ Rank...1          <chr> NA, "1", "2", "3", "4", "5", "6", "7", "8", "9", ...
## $ Name...2          <chr> NA, "OLIVER", "JACK", "HARRY", "GEORGE", "JACOB",...
## $ Count...3         <dbl> NA, 6941, 5371, 5308, 4869, 4850, 4831, 4148, 408...
## $ `since 2014...4`  <chr> NA, "­ ", "­ ", "­ ", "+3 ", "-1 ", "-1 ", "+4 ",...
## $ `since 2005...5`  <chr> NA, "+4 ", "-1 ", "+6 ", "+13 ", "+16 ", "+6 ", "...
## $ ...6              <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N...
## $ Rank...7          <chr> NA, "51", "52", "53", "54", "55", "56", "57", "58...
## $ Name...8          <chr> NA, "REUBEN", "HARLEY", "LUCA", "MICHAEL", "HUGO"...
## $ Count...9         <dbl> NA, 1188, 1175, 1167, 1165, 1153, 1148, 1112, 109...
## $ `since 2014...10` <chr> NA, "­ ", "-7 ", "+5 ", "-2 ", "+15 ", "-10 ", "+...
## $ `since 2005...11` <chr> NA, "+51* ", "+18 ", "+30 ", "-12 ", "+124* ", "-...
\end{verbatim}

In short, we want to go from this:

\includegraphics{R/RDataWrangling/images/messy.png}

to this:

\includegraphics{R/RDataWrangling/images/clean.png}

There are many ways to do this kind of data manipulation in R. We're
going to use the \texttt{dplyr} and \texttt{tidyr} packages from within \texttt{tidyverse}
to make our lives easier.

\hypertarget{selecting-columns}{%
\subsection{Selecting columns}\label{selecting-columns}}

Next we want to retain just the \texttt{Name...2}, \texttt{Name...6}, \texttt{Count...3} and \texttt{Count...7} columns.
We can do that using the \texttt{select()} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{boysNames[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 59 x 7
##    ...1  Name...2 Count...3 ...4   ...5 Name...6 Count...7
##    <chr> <chr>        <dbl> <lgl> <dbl> <chr>        <dbl>
##  1 <NA>  <NA>            NA NA       NA <NA>            NA
##  2 1     JACK         10779 NA       51 DOMINIC       1519
##  3 2     DANIEL       10338 NA       52 NICHOLAS      1385
##  4 3     THOMAS        9603 NA       53 BRANDON       1337
##  5 4     JAMES         9385 NA       54 RHYS          1259
##  6 5     JOSHUA        7887 NA       55 MARK          1222
##  7 6     MATTHEW       7426 NA       56 MAX           1192
##  8 7     RYAN          6496 NA       57 DYLAN         1186
##  9 8     JOSEPH        6193 NA       58 HENRY         1135
## 10 9     SAMUEL        6161 NA       59 PETER         1128
## # ... with 49 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{boysNames[[}\DecValTok{1}\NormalTok{]] \textless{}{-}}\StringTok{ }\KeywordTok{select}\NormalTok{(boysNames[[}\DecValTok{1}\NormalTok{]], Name...}\DecValTok{2}\NormalTok{, Name...}\DecValTok{6}\NormalTok{, Count...}\DecValTok{3}\NormalTok{, Count...}\DecValTok{7}\NormalTok{)}
\NormalTok{boysNames[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 59 x 4
##    Name...2 Name...6 Count...3 Count...7
##    <chr>    <chr>        <dbl>     <dbl>
##  1 <NA>     <NA>            NA        NA
##  2 JACK     DOMINIC      10779      1519
##  3 DANIEL   NICHOLAS     10338      1385
##  4 THOMAS   BRANDON       9603      1337
##  5 JAMES    RHYS          9385      1259
##  6 JOSHUA   MARK          7887      1222
##  7 MATTHEW  MAX           7426      1192
##  8 RYAN     DYLAN         6496      1186
##  9 JOSEPH   HENRY         6193      1135
## 10 SAMUEL   PETER         6161      1128
## # ... with 49 more rows
\end{verbatim}

\hypertarget{data-types-and-structures}{%
\subsection{Data types and structures}\label{data-types-and-structures}}

We've now encountered several different data types and data structures. Let's take a step back and survey the options available in R.

\textbf{Data structures:}

In R, the most foundational data structure is the \textbf{vector}. Vectors are \emph{containers} that
can hold a \emph{collection} of values. Vectors come in two basic forms:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{atomic}: only hold elements of the same type; they are \textbf{homogeneous}. The \texttt{c()} function can be used to create atomic vectors.
\item
  \textbf{list}: can hold elements of different types; they are \textbf{heterogeneous}. The \texttt{list()} function can be used to create list vectors.
\end{enumerate}

\texttt{NULL} is closely related to vectors and often serves the role of a zero length vector.

\includegraphics{R/RDataWrangling/images/summary_tree.png}

From these two basic forms, the following six structures are derived:

\begin{longtable}[]{@{}lll@{}}
\toprule
\begin{minipage}[b]{0.10\columnwidth}\raggedright
Type\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright
Elements\strut
\end{minipage} & \begin{minipage}[b]{0.71\columnwidth}\raggedright
Description\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.10\columnwidth}\raggedright
atomic vector\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
homogeneous\strut
\end{minipage} & \begin{minipage}[t]{0.71\columnwidth}\raggedright
contains elements of the same \textbf{type}, one of: character, integer, double, logical\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.10\columnwidth}\raggedright
array\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
homogeneous\strut
\end{minipage} & \begin{minipage}[t]{0.71\columnwidth}\raggedright
an atomic vector with attributes giving dimensions (1, 2, or \textgreater2)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.10\columnwidth}\raggedright
matrix\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
homogeneous\strut
\end{minipage} & \begin{minipage}[t]{0.71\columnwidth}\raggedright
an array with 2 dimensions\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.10\columnwidth}\raggedright
factor\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
homogeneous\strut
\end{minipage} & \begin{minipage}[t]{0.71\columnwidth}\raggedright
an atomic integer vector containing only predefined values, storing categorical data\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.10\columnwidth}\raggedright
list\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
heterogeneous\strut
\end{minipage} & \begin{minipage}[t]{0.71\columnwidth}\raggedright
a container whose elements can encompass any mixture of data types\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.10\columnwidth}\raggedright
data.frame\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
heterogeneous\strut
\end{minipage} & \begin{minipage}[t]{0.71\columnwidth}\raggedright
a rectangular list with elements (columns) containing atomic vectors of equal length\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Each vector can have \textbf{attributes}, which are a named list of metadata that can include the vector's \textbf{dimensions} and its \textbf{class}. The latter is a property assigned to an object that determines how \textbf{generic functions} operate with it, and thus which \textbf{methods} are available for it. The class of an object can be queried using the \texttt{class()} function. You can learn more details about R data structures here: \url{https://adv-r.hadley.nz/vectors-chap.html}

\textbf{Data types:}

There are four primary types of atomic vectors. Collectively, integer and double vectors are known as numeric vectors. You can query the \textbf{type} of an object using the \texttt{typeof()} function.

\includegraphics{R/RDataWrangling/images/summary_tree_atomic.png}

\begin{longtable}[]{@{}ll@{}}
\toprule
Type & Description\tabularnewline
\midrule
\endhead
character & ``a'', ``swc''\tabularnewline
integer & 2L (the L tells R to store this as an integer)\tabularnewline
double (floating point) & 2, 15.5\tabularnewline
logical & TRUE, FALSE\tabularnewline
\bottomrule
\end{longtable}

\textbf{Coercion:}

If heterogeneous elements are stored in an atomic vector, R will \textbf{coerce} the vector to the simplest type required to store all the information. The order of coercion is roughly: logical -\textgreater{} integer -\textgreater{} double -\textgreater{} character -\textgreater{} list. For example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{1.5}\NormalTok{, }\FloatTok{2.7}\NormalTok{, }\FloatTok{3.9}\NormalTok{)}
\KeywordTok{typeof}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "double"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y \textless{}{-}}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{1.5}\NormalTok{, }\FloatTok{2.7}\NormalTok{, }\FloatTok{3.9}\NormalTok{, }\StringTok{"a"}\NormalTok{)}
\KeywordTok{typeof}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "character"
\end{verbatim}

\hypertarget{list-indexing}{%
\subsection{List indexing}\label{list-indexing}}

Now that we know about data structures more generally, let's focus on the \emph{list} structure we created for \texttt{boysNames}.
Why are we using \textbf{double brackets} \texttt{{[}{[}} to index this list object, instead of the single brackets \texttt{{[}} we used to index atomic vectors?

\includegraphics{R/RDataWrangling/images/indexing_lists.png}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# various data structures}
\NormalTok{numbers \textless{}{-}}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{10}
\NormalTok{letters \textless{}{-}}\StringTok{ }\NormalTok{LETTERS[}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{]}
\NormalTok{dat \textless{}{-}}\StringTok{ }\KeywordTok{head}\NormalTok{(mtcars)}
\NormalTok{x \textless{}{-}}\StringTok{ }\NormalTok{237L}

\CommentTok{\# combine in a list}
\NormalTok{mylist \textless{}{-}}\StringTok{ }\KeywordTok{list}\NormalTok{(numbers, letters, dat, x)}

\CommentTok{\# indexing the list}
\NormalTok{mylist[}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] "A" "B" "C" "D"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(mylist[}\DecValTok{2}\NormalTok{]) }\CommentTok{\# a list}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "list"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mylist[[}\DecValTok{2}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "A" "B" "C" "D"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{class}\NormalTok{(mylist[[}\DecValTok{2}\NormalTok{]]) }\CommentTok{\# a character vector}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "character"
\end{verbatim}

\hypertarget{dropping-missing-values}{%
\subsection{Dropping missing values}\label{dropping-missing-values}}

Next we want to remove blank rows and rows used for notes. An easy way
to do that is to use \texttt{drop\_na()} from the \texttt{tidyr} package within \texttt{tidyverse}
to remove rows with missing values.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{boysNames[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 59 x 4
##    Name...2 Name...6 Count...3 Count...7
##    <chr>    <chr>        <dbl>     <dbl>
##  1 <NA>     <NA>            NA        NA
##  2 JACK     DOMINIC      10779      1519
##  3 DANIEL   NICHOLAS     10338      1385
##  4 THOMAS   BRANDON       9603      1337
##  5 JAMES    RHYS          9385      1259
##  6 JOSHUA   MARK          7887      1222
##  7 MATTHEW  MAX           7426      1192
##  8 RYAN     DYLAN         6496      1186
##  9 JOSEPH   HENRY         6193      1135
## 10 SAMUEL   PETER         6161      1128
## # ... with 49 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{boysNames[[}\DecValTok{1}\NormalTok{]] \textless{}{-}}\StringTok{ }\NormalTok{boysNames[[}\DecValTok{1}\NormalTok{]] }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{drop\_na}\NormalTok{()}

\NormalTok{boysNames[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 50 x 4
##    Name...2 Name...6 Count...3 Count...7
##    <chr>    <chr>        <dbl>     <dbl>
##  1 JACK     DOMINIC      10779      1519
##  2 DANIEL   NICHOLAS     10338      1385
##  3 THOMAS   BRANDON       9603      1337
##  4 JAMES    RHYS          9385      1259
##  5 JOSHUA   MARK          7887      1222
##  6 MATTHEW  MAX           7426      1192
##  7 RYAN     DYLAN         6496      1186
##  8 JOSEPH   HENRY         6193      1135
##  9 SAMUEL   PETER         6161      1128
## 10 LIAM     STEPHEN       5802      1122
## # ... with 40 more rows
\end{verbatim}

\hypertarget{exercise-2-2}{%
\subsection{Exercise 2}\label{exercise-2-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a function called \texttt{namecount} that takes a data frame as an
  argument and returns a modified version, which keeps only columns that
  include the strings \texttt{Name} and \texttt{Count} in the column names.
  HINT: see the \texttt{?matches} function.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Test your function on the first data frame in the list of boys
  names data.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Use the \texttt{map()} function to each data frame in the list of boys
  names data and save it to the list called \texttt{boysNames}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

{Click for Exercise 2 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write a function that takes a data frame as an argument and returns a modified version, which keeps only columns that include the strings \texttt{Name} and \texttt{Count} in the column names. HINT: see the \texttt{?matches} function.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  namecount \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(data) \{}
      \KeywordTok{select}\NormalTok{(data, }\KeywordTok{matches}\NormalTok{(}\StringTok{"Name|Count"}\NormalTok{))}
\NormalTok{  \}}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Test your function on the first data frame in the list of boys names data.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
  \KeywordTok{namecount}\NormalTok{(boysNames[[}\DecValTok{1}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 50 x 4
##    Name...2 Name...6 Count...3 Count...7
##    <chr>    <chr>        <dbl>     <dbl>
##  1 JACK     DOMINIC      10779      1519
##  2 DANIEL   NICHOLAS     10338      1385
##  3 THOMAS   BRANDON       9603      1337
##  4 JAMES    RHYS          9385      1259
##  5 JOSHUA   MARK          7887      1222
##  6 MATTHEW  MAX           7426      1192
##  7 RYAN     DYLAN         6496      1186
##  8 JOSEPH   HENRY         6193      1135
##  9 SAMUEL   PETER         6161      1128
## 10 LIAM     STEPHEN       5802      1122
## # ... with 40 more rows
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Use the \texttt{map()} function to each data frame in the list of boys names data.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{  boysNames \textless{}{-}}\StringTok{ }\KeywordTok{map}\NormalTok{(boysNames, namecount)}
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{reshaping-from-wide-to-long}{%
\subsection{Reshaping from wide to long}\label{reshaping-from-wide-to-long}}

Our final task is to re-arrange the data so that it is all in a single
table instead of in two side-by-side tables. For many similar tasks
the \texttt{gather()} function in the \texttt{tidyr} package is useful, but in this
case we will be better off using a combination of \texttt{select()} and
\texttt{bind\_rows()}. Here's the logic behind this step:

\includegraphics{R/RDataWrangling/images/wide_vs_long.png}

Here's the code that implements the transformation:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{boysNames[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 50 x 4
##    Name...2 Name...6 Count...3 Count...7
##    <chr>    <chr>        <dbl>     <dbl>
##  1 JACK     DOMINIC      10779      1519
##  2 DANIEL   NICHOLAS     10338      1385
##  3 THOMAS   BRANDON       9603      1337
##  4 JAMES    RHYS          9385      1259
##  5 JOSHUA   MARK          7887      1222
##  6 MATTHEW  MAX           7426      1192
##  7 RYAN     DYLAN         6496      1186
##  8 JOSEPH   HENRY         6193      1135
##  9 SAMUEL   PETER         6161      1128
## 10 LIAM     STEPHEN       5802      1122
## # ... with 40 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{first\_columns \textless{}{-}}\StringTok{ }\KeywordTok{select}\NormalTok{(boysNames[[}\DecValTok{1}\NormalTok{]], }\DataTypeTok{Name =}\NormalTok{ Name...}\DecValTok{2}\NormalTok{, }\DataTypeTok{Count =}\NormalTok{ Count...}\DecValTok{3}\NormalTok{)}
\NormalTok{second\_columns \textless{}{-}}\StringTok{ }\KeywordTok{select}\NormalTok{(boysNames[[}\DecValTok{1}\NormalTok{]], }\DataTypeTok{Name =}\NormalTok{ Name...}\DecValTok{6}\NormalTok{, }\DataTypeTok{Count =}\NormalTok{ Count...}\DecValTok{7}\NormalTok{)}

\KeywordTok{bind\_rows}\NormalTok{(first\_columns, second\_columns)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 100 x 2
##    Name    Count
##    <chr>   <dbl>
##  1 JACK    10779
##  2 DANIEL  10338
##  3 THOMAS   9603
##  4 JAMES    9385
##  5 JOSHUA   7887
##  6 MATTHEW  7426
##  7 RYAN     6496
##  8 JOSEPH   6193
##  9 SAMUEL   6161
## 10 LIAM     5802
## # ... with 90 more rows
\end{verbatim}

\hypertarget{exercise-3-3}{%
\subsection{Exercise 3}\label{exercise-3-3}}

\textbf{Cleanup all the data}

In the previous examples we learned how to drop empty rows with
\texttt{drop\_na()}, select only relevant columns with \texttt{select()}, and re-arrange
our data with \texttt{select()} and \texttt{bind\_rows()}. In each case we applied the
changes only to the first element of our \texttt{boysNames} list.

NOTE: some Excel files include extra blank columns between the first and second
set of \texttt{Name} and \texttt{Count} columns, resulting in different numeric suffixes
for the second set of columns. You will need to use a regular expression
to match each of these different column names. HINT: see the \texttt{?matches}
function.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a new function called \texttt{cleanupNamesData} that:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 1) subsets data to include only those columns that include the term \textasciigrave{}Name\textasciigrave{} and \textasciigrave{}Count\textasciigrave{} and apply listwise deletion}

\CommentTok{\# 2) subset two separate data frames, with first and second set of \textasciigrave{}Name\textasciigrave{} and \textasciigrave{}Count\textasciigrave{} columns}

\CommentTok{\# 3) append the two datasets}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Your task now is to use the \texttt{map()} function to apply each of these
  transformations to all the elements in \texttt{boysNames}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

{Click for Exercise 3 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a new function called \texttt{cleanupNamesData} that:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cleanupNamesData \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(file)\{}

  \CommentTok{\# subset data to include only those columns that include the term \textasciigrave{}Name\textasciigrave{} and \textasciigrave{}Count\textasciigrave{}}
\NormalTok{  subsetted\_file \textless{}{-}}\StringTok{ }\NormalTok{file }\OperatorTok{\%\textgreater{}\%}
\StringTok{    }\KeywordTok{select}\NormalTok{(}\KeywordTok{matches}\NormalTok{(}\StringTok{"Name|Count"}\NormalTok{)) }\OperatorTok{\%\textgreater{}\%}
\StringTok{    }\KeywordTok{drop\_na}\NormalTok{()}

  \CommentTok{\# subset two separate data frames, with first and second set of \textasciigrave{}Name\textasciigrave{} and \textasciigrave{}Count\textasciigrave{} columns }
\NormalTok{  first\_columns \textless{}{-}}\StringTok{ }\KeywordTok{select}\NormalTok{(subsetted\_file, }\DataTypeTok{Name =}\NormalTok{ Name...}\DecValTok{2}\NormalTok{, }\DataTypeTok{Count =}\NormalTok{ Count...}\DecValTok{3}\NormalTok{) }

\NormalTok{  second\_columns \textless{}{-}}\StringTok{ }\KeywordTok{select}\NormalTok{(subsetted\_file, }\DataTypeTok{Name =} \KeywordTok{matches}\NormalTok{(}\StringTok{"Name...6|Name...7|Name...8"}\NormalTok{),}
                                           \DataTypeTok{Count =} \KeywordTok{matches}\NormalTok{(}\StringTok{"Count...7|Count...8|Count...9"}\NormalTok{))}

  \CommentTok{\# append the two datasets}
  \KeywordTok{bind\_rows}\NormalTok{(first\_columns, second\_columns)}
\NormalTok{\}}


\CommentTok{\#\# test it out on the second data frame in the list}
\NormalTok{boysNames[[}\DecValTok{2}\NormalTok{]] }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{glimpse}\NormalTok{() }\CommentTok{\# before cleanup}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 61
## Columns: 4
## $ Name...2  <chr> NA, "JACK", "JAMES", "THOMAS", "DANIEL", "JOSHUA", "MATTH...
## $ Count...3 <dbl> NA, 10145, 9853, 9479, 9047, 7698, 7443, 6367, 5809, 5631...
## $ Name...7  <chr> NA, "SEAN", "DYLAN", "DOMINIC", "LOUIS", "RHYS", "NICHOLA...
## $ Count...8 <dbl> NA, 1388, 1380, 1359, 1325, 1291, 1274, 1244, 1241, 1158,...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{boysNames[[}\DecValTok{2}\NormalTok{]] }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{cleanupNamesData}\NormalTok{() }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{glimpse}\NormalTok{() }\CommentTok{\# after cleanup}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 100
## Columns: 2
## $ Name  <chr> "JACK", "JAMES", "THOMAS", "DANIEL", "JOSHUA", "MATTHEW", "SA...
## $ Count <dbl> 10145, 9853, 9479, 9047, 7698, 7443, 6367, 5809, 5631, 5404, ...
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Your task now is to use the \texttt{map()} function to apply each of these transformations to all the elements in \texttt{boysNames}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{boysNames \textless{}{-}}\StringTok{ }\KeywordTok{map}\NormalTok{(boysNames, cleanupNamesData)}
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{data-organization-storage}{%
\section{Data organization \& storage}\label{data-organization-storage}}

\begin{alert}

\textbf{GOAL: To learn how to organize the data into one large data frame and store it.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a year column within each data frame within the list
\item
  Append all the data frames in the list into one large data frame
\end{enumerate}

\end{alert}

Now that we have the data cleaned up and augmented, we can turn our attention to organizing and storing the data.

\hypertarget{a-list-of-data-frames}{%
\subsection{A list of data frames}\label{a-list-of-data-frames}}

Right now we have a list of data frames; one for each year. This is not a bad way to go. It has the advantage of making it easy to work with individual years; it has the disadvantage of making it more difficult to examine questions that require data from multiple years. To make the arrangement of the data clearer it helps to name each element of the list with the year it corresponds to.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(boysNames) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{glimpse}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## List of 6
##  $ : tibble [100 x 2] (S3: tbl_df/tbl/data.frame)
##   ..$ Name : chr [1:100] "JACK" "DANIEL" "THOMAS" "JAMES" ...
##   ..$ Count: num [1:100] 10779 10338 9603 9385 7887 ...
##  $ : tibble [100 x 2] (S3: tbl_df/tbl/data.frame)
##   ..$ Name : chr [1:100] "JACK" "JAMES" "THOMAS" "DANIEL" ...
##   ..$ Count: num [1:100] 10145 9853 9479 9047 7698 ...
##  $ : tibble [100 x 2] (S3: tbl_df/tbl/data.frame)
##   ..$ Name : chr [1:100] "JACK" "THOMAS" "JAMES" "DANIEL" ...
##   ..$ Count: num [1:100] 9845 9468 9197 7732 7672 ...
##  $ : tibble [100 x 2] (S3: tbl_df/tbl/data.frame)
##   ..$ Name : chr [1:100] "JACK" "THOMAS" "JAMES" "JOSHUA" ...
##   ..$ Count: num [1:100] 9785 9454 8748 7275 6935 ...
##  $ : tibble [100 x 2] (S3: tbl_df/tbl/data.frame)
##   ..$ Name : chr [1:100] "JACK" "THOMAS" "JAMES" "JOSHUA" ...
##   ..$ Count: num [1:100] 9079 8672 7489 7097 6229 ...
##  $ : tibble [100 x 2] (S3: tbl_df/tbl/data.frame)
##   ..$ Name : chr [1:100] "JACK" "THOMAS" "JOSHUA" "JAMES" ...
##   ..$ Count: num [1:100] 9000 8337 7182 7026 5759 ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(boy\_file\_names)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "dataSets/boys/1996boys_tcm77-254026.xlsx"
## [2] "dataSets/boys/1997boys_tcm77-254022.xlsx"
## [3] "dataSets/boys/1998boys_tcm77-254018.xlsx"
## [4] "dataSets/boys/1999boys_tcm77-254014.xlsx"
## [5] "dataSets/boys/2000boys_tcm77-254008.xlsx"
## [6] "dataSets/boys/2001boys_tcm77-254000.xlsx"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# use regex to extract years from file names}
\NormalTok{Years \textless{}{-}}\StringTok{ }\KeywordTok{str\_extract}\NormalTok{(boy\_file\_names, }\DataTypeTok{pattern =} \StringTok{"[0{-}9]\{4\}"}\NormalTok{)}
\NormalTok{Years}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "1996" "1997" "1998" "1999" "2000" "2001" "2002" "2003" "2004" "2005"
## [11] "2006" "2007" "2008" "2009" "2010" "2011" "2012" "2013" "2014" "2015"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(boysNames) }\CommentTok{\# returns NULL {-} no names in the list}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## NULL
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# assign years to list names}
\KeywordTok{names}\NormalTok{(boysNames) \textless{}{-}}\StringTok{ }\NormalTok{Years }

\KeywordTok{names}\NormalTok{(boysNames) }\CommentTok{\# returns the years as list names}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "1996" "1997" "1998" "1999" "2000" "2001" "2002" "2003" "2004" "2005"
## [11] "2006" "2007" "2008" "2009" "2010" "2011" "2012" "2013" "2014" "2015"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{head}\NormalTok{(boysNames) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{glimpse}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## List of 6
##  $ 1996: tibble [100 x 2] (S3: tbl_df/tbl/data.frame)
##   ..$ Name : chr [1:100] "JACK" "DANIEL" "THOMAS" "JAMES" ...
##   ..$ Count: num [1:100] 10779 10338 9603 9385 7887 ...
##  $ 1997: tibble [100 x 2] (S3: tbl_df/tbl/data.frame)
##   ..$ Name : chr [1:100] "JACK" "JAMES" "THOMAS" "DANIEL" ...
##   ..$ Count: num [1:100] 10145 9853 9479 9047 7698 ...
##  $ 1998: tibble [100 x 2] (S3: tbl_df/tbl/data.frame)
##   ..$ Name : chr [1:100] "JACK" "THOMAS" "JAMES" "DANIEL" ...
##   ..$ Count: num [1:100] 9845 9468 9197 7732 7672 ...
##  $ 1999: tibble [100 x 2] (S3: tbl_df/tbl/data.frame)
##   ..$ Name : chr [1:100] "JACK" "THOMAS" "JAMES" "JOSHUA" ...
##   ..$ Count: num [1:100] 9785 9454 8748 7275 6935 ...
##  $ 2000: tibble [100 x 2] (S3: tbl_df/tbl/data.frame)
##   ..$ Name : chr [1:100] "JACK" "THOMAS" "JAMES" "JOSHUA" ...
##   ..$ Count: num [1:100] 9079 8672 7489 7097 6229 ...
##  $ 2001: tibble [100 x 2] (S3: tbl_df/tbl/data.frame)
##   ..$ Name : chr [1:100] "JACK" "THOMAS" "JOSHUA" "JAMES" ...
##   ..$ Count: num [1:100] 9000 8337 7182 7026 5759 ...
\end{verbatim}

\hypertarget{one-big-data-frame}{%
\subsection{One big data frame}\label{one-big-data-frame}}

While storing the data in separate data frames by year makes some sense,
many operations will be easier if the data is simply stored in one big
data frame. We've already seen how to turn a list of data frames into a
single data.frame using \texttt{bind\_rows()}, but there is a problem; The year
information is stored in the names of the list elements, and so
flattening the data.frames into one will result in losing the year
information! Fortunately it is not too much trouble to add the year
information to each data frame before flattening.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# apply name of the list element (.y) as a new column in the data.frame (.x)}
\NormalTok{boysNames \textless{}{-}}\StringTok{ }\KeywordTok{imap}\NormalTok{(boysNames, }\OperatorTok{\textasciitilde{}}\StringTok{ }\KeywordTok{mutate}\NormalTok{(.x, }\DataTypeTok{Year =} \KeywordTok{as.integer}\NormalTok{(.y)))}

\NormalTok{boysNames[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $`1996`
## # A tibble: 100 x 3
##    Name    Count  Year
##    <chr>   <dbl> <int>
##  1 JACK    10779  1996
##  2 DANIEL  10338  1996
##  3 THOMAS   9603  1996
##  4 JAMES    9385  1996
##  5 JOSHUA   7887  1996
##  6 MATTHEW  7426  1996
##  7 RYAN     6496  1996
##  8 JOSEPH   6193  1996
##  9 SAMUEL   6161  1996
## 10 LIAM     5802  1996
## # ... with 90 more rows
\end{verbatim}

\hypertarget{exercise-4-1}{%
\subsection{Exercise 4}\label{exercise-4-1}}

\textbf{Make one big \texttt{data.frame}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Turn the list of boys names data frames into a single data frame. HINT: see \texttt{?bind\_rows}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Create a new directory called \texttt{all} within \texttt{dataSets} and write the data to a \texttt{.csv} file.
  HINT: see the \texttt{?dir.create} and \texttt{?write\_csv} functions.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  What were the five most popular names in 2013?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  How has the popularity of the name ``ANDREW'' changed over time?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# }
\end{Highlighting}
\end{Shaded}

{Click for Exercise 4 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Turn the list of boys names data frames into a single data frame.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{boysNames \textless{}{-}}\StringTok{ }\KeywordTok{bind\_rows}\NormalTok{(boysNames)}
\KeywordTok{glimpse}\NormalTok{(boysNames)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 2,000
## Columns: 3
## $ Name  <chr> "JACK", "DANIEL", "THOMAS", "JAMES", "JOSHUA", "MATTHEW", "RY...
## $ Count <dbl> 10779, 10338, 9603, 9385, 7887, 7426, 6496, 6193, 6161, 5802,...
## $ Year  <int> 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1996, 1...
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Create a new directory called \texttt{all} within \texttt{dataSets} and write the data to a \texttt{.csv} file. HINT: see the \texttt{?dir.create} and \texttt{?write\_csv} functions.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dir.create}\NormalTok{(}\StringTok{"dataSets/all"}\NormalTok{)}

\KeywordTok{write\_csv}\NormalTok{(boysNames, }\StringTok{"dataSets/all/boys\_names.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  What were the five most popular names in 2013?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{boysNames }\OperatorTok{\%\textgreater{}\%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(Year }\OperatorTok{==}\StringTok{ }\DecValTok{2013}\NormalTok{) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(Count)) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{head}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   Name    Count  Year
##   <chr>   <dbl> <int>
## 1 OLIVER   6949  2013
## 2 JACK     6212  2013
## 3 HARRY    5888  2013
## 4 JACOB    5126  2013
## 5 CHARLIE  5039  2013
## 6 THOMAS   4591  2013
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  How has the popularity of the name ``ANDREW'' changed over time?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{andrew \textless{}{-}}\StringTok{ }\KeywordTok{filter}\NormalTok{(boysNames, Name }\OperatorTok{==}\StringTok{ "ANDREW"}\NormalTok{)}

\KeywordTok{ggplot}\NormalTok{(andrew, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ Year, }\DataTypeTok{y =}\NormalTok{ Count)) }\OperatorTok{+}
\StringTok{    }\KeywordTok{geom\_line}\NormalTok{() }\OperatorTok{+}
\StringTok{    }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Popularity of Andrew, over time"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{R/RDataWrangling/figures/unnamed-chunk-260-1.pdf}

\end{alert}

\hypertarget{complete-code}{%
\section{Complete code}\label{complete-code}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Code for Section 1: Reading data from multiple Excel worksheets into R data frames
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{boy\_file\_names \textless{}{-}}\StringTok{ }\KeywordTok{list.files}\NormalTok{(}\StringTok{"dataSets/boys"}\NormalTok{, }\DataTypeTok{full.names =} \OtherTok{TRUE}\NormalTok{)}

\NormalTok{get\_data\_sheet\_name \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(file, term)\{}
  \KeywordTok{excel\_sheets}\NormalTok{(file) }\OperatorTok{\%\textgreater{}\%}\StringTok{ }\KeywordTok{str\_subset}\NormalTok{(}\DataTypeTok{pattern =}\NormalTok{ term)}
\NormalTok{\}}

\NormalTok{read\_boys\_names \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(file, sheet\_name) \{}
  \KeywordTok{read\_excel}\NormalTok{(}
    \DataTypeTok{path =}\NormalTok{ file,}
    \DataTypeTok{sheet =} \KeywordTok{get\_data\_sheet\_name}\NormalTok{(file, }\DataTypeTok{term =}\NormalTok{ sheet\_name),}
    \DataTypeTok{skip =} \DecValTok{6}
\NormalTok{  )}
\NormalTok{\}}

\NormalTok{boysNames \textless{}{-}}\StringTok{ }\KeywordTok{map}\NormalTok{(boy\_file\_names, read\_boys\_names, }\DataTypeTok{sheet\_name =} \StringTok{"Table 1"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Code for Section 2: Clean up data within each R data frame
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cleanupNamesData \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(file)\{}
  \CommentTok{\# subset data to include only those columns that include the term \textasciigrave{}Name\textasciigrave{} and \textasciigrave{}Count\textasciigrave{}}
\NormalTok{  subsetted\_file \textless{}{-}}\StringTok{ }\NormalTok{file }\OperatorTok{\%\textgreater{}\%}
\StringTok{    }\KeywordTok{select}\NormalTok{(}\KeywordTok{matches}\NormalTok{(}\StringTok{"Name|Count"}\NormalTok{)) }\OperatorTok{\%\textgreater{}\%}
\StringTok{    }\KeywordTok{drop\_na}\NormalTok{()}
  \CommentTok{\# subset two separate data frames, with first and second set of \textasciigrave{}Name\textasciigrave{} and \textasciigrave{}Count\textasciigrave{} columns }
\NormalTok{  first\_columns \textless{}{-}}\StringTok{ }\KeywordTok{select}\NormalTok{(subsetted\_file, }\DataTypeTok{Name =}\NormalTok{ Name...}\DecValTok{2}\NormalTok{, }\DataTypeTok{Count =}\NormalTok{ Count...}\DecValTok{3}\NormalTok{) }
\NormalTok{  second\_columns \textless{}{-}}\StringTok{ }\KeywordTok{select}\NormalTok{(subsetted\_file, }\DataTypeTok{Name =} \KeywordTok{matches}\NormalTok{(}\StringTok{"Name...6|Name...7|Name...8"}\NormalTok{),}
                                           \DataTypeTok{Count =} \KeywordTok{matches}\NormalTok{(}\StringTok{"Count...7|Count...8|Count...9"}\NormalTok{))}
  \CommentTok{\# append the two datasets}
  \KeywordTok{bind\_rows}\NormalTok{(first\_columns, second\_columns)}
\NormalTok{\}}

\NormalTok{boysNames \textless{}{-}}\StringTok{ }\KeywordTok{map}\NormalTok{(boysNames, cleanupNamesData)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Code for Section 3: Organize the data into one large data frame and store it
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Years \textless{}{-}}\StringTok{ }\KeywordTok{str\_extract}\NormalTok{(boy\_file\_names, }\DataTypeTok{pattern =} \StringTok{"[0{-}9]\{4\}"}\NormalTok{)}

\KeywordTok{names}\NormalTok{(boysNames) \textless{}{-}}\StringTok{ }\NormalTok{Years}

\NormalTok{boysNames \textless{}{-}}\StringTok{ }\KeywordTok{imap}\NormalTok{(boysNames, }\OperatorTok{\textasciitilde{}}\StringTok{ }\KeywordTok{mutate}\NormalTok{(.x, }\DataTypeTok{Year =} \KeywordTok{as.integer}\NormalTok{(.y)))}

\NormalTok{boysNames \textless{}{-}}\StringTok{ }\KeywordTok{bind\_rows}\NormalTok{(boysNames)}
\end{Highlighting}
\end{Shaded}

\hypertarget{wrap-up-4}{%
\section{Wrap-up}\label{wrap-up-4}}

\hypertarget{feedback-4}{%
\subsection{Feedback}\label{feedback-4}}

These workshops are a work in progress, please provide any feedback to: \href{mailto:help@iq.harvard.edu}{\nolinkurl{help@iq.harvard.edu}}

\hypertarget{resources-5}{%
\subsection{Resources}\label{resources-5}}

\begin{itemize}
\tightlist
\item
  IQSS

  \begin{itemize}
  \tightlist
  \item
    Workshops: \url{https://dss.iq.harvard.edu/workshop-materials}
  \item
    Data Science Services: \url{https://dss.iq.harvard.edu/}
  \item
    Research Computing Environment: \url{https://iqss.github.io/dss-rce/}
  \end{itemize}
\item
  HBS

  \begin{itemize}
  \tightlist
  \item
    Research Computing Services workshops: \url{https://training.rcs.hbs.org/workshops}
  \item
    Other HBS RCS resources: \url{https://training.rcs.hbs.org/workshop-materials}
  \item
    RCS consulting email: \url{mailto:research@hbs.edu}
  \end{itemize}
\item
  R

  \begin{itemize}
  \tightlist
  \item
    Learn from the best: \url{http://adv-r.had.co.nz/}; \url{http://r4ds.had.co.nz/}
  \item
    R documentation: \url{http://cran.r-project.org/manuals.html}
  \item
    Collection of R tutorials: \url{http://cran.r-project.org/other-docs.html}
  \item
    R for Programmers (by Norman Matloff, UC--Davis) \url{http://heather.cs.ucdavis.edu/~matloff/R/RProg.pdf}
  \item
    Calling C and Fortran from R (by Charles Geyer, UMinn) \url{http://www.stat.umn.edu/~charlie/rc/}
  \item
    State of the Art in Parallel Computing with R (Schmidberger et al.) \url{http://www.jstatso}\textbar.org/v31/i01/paper
  \end{itemize}
\end{itemize}

\hypertarget{part-python}{%
\part{Python}\label{part-python}}

\hypertarget{python-installation}{%
\chapter{Python Installation}\label{python-installation}}

\begin{alert}

\textbf{Your professional conduct is greatly appreciated. Out of respect to your fellow workshop attendees and instructors, please arrive at your workshop on time, having pre-installed all necessary software and materials. This will likely take 15-20 minutes.}

\end{alert}

Before starting any of our Python workshops, it is necessary to complete 2 tasks. Please make sure both of these tasks are completed \textbf{before} you attend your workshop, as, depending on your internet speed, they may take a long time.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  download and unzip \textbf{class materials}
\item
  download and install \textbf{Anaconda Python 3 distribution}
\end{enumerate}

\includegraphics{Python/PythonInstall/images/install_software_Python.png}

\hypertarget{troubleshooting-session-1}{%
\section{Troubleshooting session}\label{troubleshooting-session-1}}

We will hold a troubleshooting session during the 20 minutes prior to the start of the workshop.
\textbf{If you are unable to complete all of the tasks, please stop by the training room during this session.}
Once the workshop starts we will \textbf{NOT} be able to give you one-to-one assistance with troubleshooting installation problems. Likewise, if you arrive late, please do \textbf{NOT} expect one-to-one assistance for anything covered at the beginning of the workshop.

\hypertarget{materials-1}{%
\section{Materials}\label{materials-1}}

Download class materials for your workshop:

\begin{itemize}
\tightlist
\item
  Python Introduction: \url{https://github.com/IQSS/dss-workshops/raw/master/Python/PythonIntro.zip}
\item
  Python Webscraping: \url{https://github.com/IQSS/dss-workshops/raw/master/Python/PythonWebScrape.zip}
\end{itemize}

Extract materials from the zipped directory (Right-click =\textgreater{} Extract All on Windows, double-click on Mac) and move them to your desktop.

It will be useful when you view the above materials for you to see the different file extensions on your computer. Here are instructions for enabling this:

\begin{itemize}
\tightlist
\item
  \href{https://support.apple.com/guide/mac-help/show-or-hide-filename-extensions-on-mac-mchlp2304/mac}{Mac OS}
\item
  \href{http://kb.winzip.com/kb/entry/26/}{Windows OS}
\end{itemize}

\hypertarget{software-1}{%
\section{Software}\label{software-1}}

The \textbf{Anaconda Python distribution} is designed with data science in mind and contains a curated set of 270+ pre-installed Python packages. It is essential that you have the Anaconda Python distribution pre-installed so that we can start the workshop on time. It is also important that you have the \textbf{latest version} of the distribution, which currently is:

\begin{itemize}
\tightlist
\item
  Anaconda Python distribution version \textbf{2020.07}, which contains Python version \textbf{3.8.5}.
\end{itemize}

\textbf{Mac OS X:}

\begin{itemize}
\tightlist
\item
  Install Anaconda Python 3 by downloading and running \href{https://repo.anaconda.com/archive/Anaconda3-2020.07-MacOSX-x86_64.pkg}{this .pkg file}. Accept the defaults proposed by the Anaconda installer.
\end{itemize}

\textbf{Windows:}

\begin{itemize}
\tightlist
\item
  Install Anaconda Python 3 by downloading and running \href{https://repo.anaconda.com/archive/Anaconda3-2020.07-Windows-x86_64.exe}{this .exe file}. Accept the defaults proposed by the Anaconda installer.
\end{itemize}

\textbf{Linux:}

\begin{itemize}
\tightlist
\item
  Install Anaconda Python 3 by downloading and running \href{https://repo.anaconda.com/archive/Anaconda3-2020.07-Linux-x86_64.sh}{this .sh file}. Accept the defaults proposed by the Anaconda installer.
\end{itemize}

\begin{alert}

\textbf{Success? After installing, please start the \texttt{Anaconda\ Navigator} program. If you were successful with the installation, you should see a window similar to this:}

\end{alert}

\includegraphics{Python/PythonInstall/images/Anaconda_navigator.png}

To check that the installation is working correctly, click the \texttt{Launch} button under \texttt{JupyterLab}. A JupyterLab window should open in your web browser.

\begin{alert}

\textbf{If you are having any difficulties with the installation, please stop by the training room 20 minutes prior to the start of the workshop.}

\end{alert}

\hypertarget{jupyter-notebook-interfaces}{%
\section{Jupyter notebook interfaces}\label{jupyter-notebook-interfaces}}

We will be using Jupyter Notebooks to run our Python code. \href{https://jupyter-notebook.readthedocs.io/en/stable/}{Jupyter Notebooks} are documents that combine text, code, images, math, and rich media and can be viewed in a browser. There are two main ways to interact with Jupyter Notebooks:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  using \textbf{JupyterLab}, a modern ``extensible environment for interactive and reproducible computing'' that runs in your web browser.
\item
  using \textbf{Jupyter Notebook}, an older browser-based application.
\end{enumerate}

Compared to Jupyter Notebook, JupyterLab provides a more modern, richer and more robust coding environment. For this reason, \textbf{we strongly recommend that you use JupyterLab to interact with notebooks}.

\hypertarget{launch-jupyterlab}{%
\subsection{Launch JupyterLab}\label{launch-jupyterlab}}

Here's how to start JupyterLab and open a notebook within this interface (\textbf{recommended}):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start the \texttt{Anaconda\ Navigator} program
\item
  Click the \texttt{Launch} button under \texttt{JupyterLab}
\item
  A browser window will open with your computer's files listed on the left hand side of the page. Navigate to the folder with the workshop materials that you downloaded to your desktop and double-click on the folder
\item
  Within the workshop materials folder, double-click on the file with the word ``BLANK'' in the name (\texttt{*\_BLANK.ipynb}). (If a pop-up window asks you to \texttt{Select\ Kernel} choose \texttt{Python\ 3} kernel.) The Jupyter Notebook should now open on the right hand side of the page.
\end{enumerate}

If you have technical difficulty with JupyterLab you can try the older Jupyter Notebook as a fallback by clicking the \texttt{Launch} button under \texttt{Jupyter\ Notebook} in step 2.

\hypertarget{resources-6}{%
\section{Resources}\label{resources-6}}

\begin{itemize}
\tightlist
\item
  IQSS

  \begin{itemize}
  \tightlist
  \item
    Workshops: \url{https://dss.iq.harvard.edu/workshop-materials}
  \item
    Data Science Services: \url{https://dss.iq.harvard.edu/}
  \item
    Research Computing Environment: \url{https://iqss.github.io/dss-rce/}
  \end{itemize}
\item
  HBS

  \begin{itemize}
  \tightlist
  \item
    Research Computing Services workshops: \url{https://training.rcs.hbs.org/workshops}
  \item
    Other HBS RCS resources: \url{https://training.rcs.hbs.org/workshop-materials}
  \item
    RCS consulting email: \url{mailto:research@hbs.edu}
  \end{itemize}
\end{itemize}

\hypertarget{python-introduction}{%
\chapter{Python Introduction}\label{python-introduction}}

\textbf{Topics}

\begin{itemize}
\tightlist
\item
  Functions
\item
  Objects
\item
  Assignment
\item
  Finding help
\item
  List and dictionary structures
\item
  Indexing data structures
\item
  Iterating over collections of data
\item
  Importing packages
\end{itemize}

\hypertarget{setup-4}{%
\section{Setup}\label{setup-4}}

\hypertarget{software-and-materials-4}{%
\subsection{Software and Materials}\label{software-and-materials-4}}

Follow the \href{./PythonInstall.html}{Python Installation} instructions and ensure that you can successfully start JupyterLab.

A handy \href{Python/PythonIntro/python-cheat-sheet-basic.pdf}{cheat-sheet} is available to help you look up and remember basic syntax.

\hypertarget{class-structure-4}{%
\subsection{Class Structure}\label{class-structure-4}}

Informal - Ask questions at any time. Really!

Collaboration is encouraged - please spend a minute introducing yourself to your neighbors!

\hypertarget{prerequisites-4}{%
\subsection{Prerequisites}\label{prerequisites-4}}

This is an introductory Python course:

\begin{itemize}
\tightlist
\item
  Assumes no prior knowledge of \textbf{how to use} Python
\item
  We do assume you know \textbf{why} you want to learn Python. If you don't, and want a comparison of Python to other statistical software, see our \href{./DataScienceTools.html}{Data Science Tools} workshop
\item
  Relatively slow-paced
\end{itemize}

\hypertarget{goals-3}{%
\subsection{Goals}\label{goals-3}}

\begin{alert}

We will learn about the Python language by analyzing the text of Lewis Carroll's \emph{Alice's Adventures in Wonderland}.
In particular, our goals are to learn about:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What Python is and how it works
\item
  How we can interact with Python
\item
  Foundations of the language (functions, objects, assignment, methods)
\item
  Using methods and lists to analyze data
\item
  Iterating over collections of data to automate repetitive tasks
\item
  Storing related data in dictionaries (as key - value pairs)
\item
  Importing packages to add functionality
\end{enumerate}

\end{alert}

\hypertarget{python-basics}{%
\section{Python basics}\label{python-basics}}

\begin{alert}

\textbf{GOAL: To learn about the foundations of the Python language.}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What Python is and how it works
\item
  Python interfaces
\item
  Functions
\item
  Objects
\item
  Assignment
\item
  Methods
\end{enumerate}

\end{alert}

\hypertarget{what-is-python}{%
\subsection{What is Python?}\label{what-is-python}}

\begin{itemize}
\tightlist
\item
  Python is a free general purpose programming language
\item
  Python is an interpreted language, not a compiled one, meaning that all commands
  typed on the keyboard are directly executed without requiring to build a complete
  program (this is like R and unlike C, Fortran, Pascal, etc.)
\item
  Python has existed for about 30 years
\item
  Python is modular --- most functionality is from add-on packages. So the language can
  be thought of as a \emph{platform} for creating and running a large number of useful packages.
\end{itemize}

\hypertarget{why-use-python}{%
\subsection{Why use Python?}\label{why-use-python}}

\begin{itemize}
\tightlist
\item
  Relatively easy to learn
\item
  Extremely flexible: can be used to manipulate, analyze, and visualize data,
  make web sites, write games, and much more (Youtube and DropBox were written in Python)
\item
  Cutting edge machine learning tools
\item
  Publication quality graphics
\item
  150,000+ add on packages covering all aspects of statistics and machine learning
\item
  Active community of users
\end{itemize}

\hypertarget{how-does-python-work}{%
\subsection{How does Python work?}\label{how-does-python-work}}

While graphical-based statistical software (e.g., SPSS, GraphPad) immediately display
the results of an analysis, \textbf{Python stores results in an \texttt{object} (a data structure)},
so that an analysis can be done with no result displayed. Such a feature is very
useful, since a user can extract only that part of the results that is of interest
and can pass results into further analyses.

For example, if you run a series of 20 regressions and want to compare the
different regression coefficients, Python can display only the estimated coefficients:
thus the results may take a single line, whereas graphical-based software could
open 20 results windows. In addition, these regression coefficients can be passed
directly into further analyses --- such as generating predictions.

\includegraphics{Python/PythonIntro/images/python_chain.png}

When Python is running, variables, data, functions, results, etc., are \textbf{stored in memory}
on the computer in the form of \texttt{objects} that have a name. The user can
\textbf{perform actions} on these objects with \texttt{operators} (arithmetic, logical,
comparison, etc.) and \texttt{functions} (which are themselves objects). Here's a
schematic of how this all fits together:

\includegraphics{Python/PythonIntro/images/python_works.png}

\hypertarget{interfaces-1}{%
\subsection{Interfaces}\label{interfaces-1}}

\hypertarget{text-editors-ides-notebooks-1}{%
\subsubsection{Text editors, IDEs, \& Notebooks}\label{text-editors-ides-notebooks-1}}

There are different ways of interacting with Python. The two main ways are through:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{text editors} or \textbf{Integrated Development Environments (IDEs):} Text editors and IDEs are not really separate categories; as you add features to a text editor it becomes more like an IDE. Some editors/IDEs are language-specific while others are general purpose --- typically providing language support via plugins. The following table lists a few popular editors/IDEs that can be used with Python. In this workshop, we will use \href{https://jupyter.org/}{JupyterLab}, a modern ``extensible environment for interactive and reproducible computing'' that runs in your web browser.
\end{enumerate}

\begin{longtable}[]{@{}llll@{}}
\toprule
Editor / IDE & Features & Ease of use & Language support\tabularnewline
\midrule
\endhead
Spyder & Excellent & Easy & Python only\tabularnewline
PyCharm & Excellent & Moderate & Python only\tabularnewline
JupyterLab & Good & Easy & Excellent\tabularnewline
VS code & Excellent & Easy & Very good\tabularnewline
Atom & Good & Moderate & Good\tabularnewline
Vim & Excellent & Hard & Good\tabularnewline
Emacs & Excellent & Hard & Excellent\tabularnewline
\bottomrule
\end{longtable}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Notebooks:} Browser-based applications that allow you to create and share documents that contain live code, equations, visualizations, and narrative text. One popular choice is \href{https://jupyter.org/}{Jupyter Notebook}; an open source notebook that has support for 40+ languages, but has limited features compared with the JupyterLab IDE.
\end{enumerate}

\hypertarget{source-code-literate-programming-1}{%
\subsubsection{Source code \& literate programming}\label{source-code-literate-programming-1}}

There are also several different \textbf{formats} available for writing code in Python.
These basically boil down to a choice between:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Source code:} the practice of writing code, and possibly comments, in a plain text document. In Python this is done by writing code in a text file with a \texttt{.py} extension. Writing source code has the great advantage of being simple. Souce code is the format of choice if you intend to run your code as a complete script - for example, from the command line.
\item
  \textbf{Literate programming:} the practice of embedding computer code in a natural language document. In Python this is often done using the aformentioned \href{https://jupyter.org/}{Jupyter Notebook}, which is a \href{https://www.json.org/json-en.html}{JSON} document containing an ordered list of input/output cells which can contain code, text (using \emph{Markdown}), mathematics, plots, and rich media, usually ending with the \texttt{.ipynb} extension. Jupyter Notebooks are easy to write, human-readable, and the format of choice if you intend to run your code interactively, by running small pieces of code and looking at each output. Researchers can use Notebooks to write their journal papers, dissertations, and statistics/math class notes, since it is easy to convert into other formats later, such as HTML (for a webpage), MS Word, or PDF (via LaTeX).
\end{enumerate}

Here are some resources for learning more about Jupyter Notebooks:

\begin{itemize}
\tightlist
\item
  \url{https://www.dataquest.io/blog/jupyter-notebook-tutorial/}
\item
  \url{https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook}
\item
  \url{https://realpython.com/jupyter-notebook-introduction/}
\end{itemize}

\hypertarget{launch-jupyterlab-1}{%
\subsection{Launch JupyterLab}\label{launch-jupyterlab-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start the \texttt{Anaconda\ Navigator} program
\item
  Click the \texttt{Launch} button under \texttt{JupyterLab}
\item
  A browser window will open with your computer's files listed on the left hand side of the page. Navigate to the folder called \texttt{PythonIntro} that you downloaded to your desktop and double-click on the folder
\item
  Within the \texttt{PythonIntro} folder, double-click on the file with the word ``BLANK'' in the name (\texttt{PythonIntro\_BLANK.ipynb}). A pop-up window will ask you to \texttt{Select\ Kernal} --- you should select the Python 3 kernal. The Jupyter Notebook should now open on the right hand side of the page
\end{enumerate}

A Jupyter Notebook contains one or more \emph{cells} containing notes or code. To insert a new cell click the \texttt{+} button in the upper left. To execute a cell, select it and press \texttt{Control+Enter} or click the \texttt{Run} button at the top.

\hypertarget{syntax-rules-1}{%
\subsection{Syntax rules}\label{syntax-rules-1}}

\begin{itemize}
\tightlist
\item
  Python is case sensitive
\item
  Python uses white space as part of the syntax (it's important!)
\item
  Variable names should start with a letter (A-Z and a-z)
  and can include letters, digits (0-9), and underscores (\_)
\item
  Comments can be inserted using a hash \texttt{\#} symbol
\item
  Functions must be written with parentheses, even
  if there is nothing within them; for example: \texttt{len()}
\end{itemize}

\hypertarget{function-calls-1}{%
\subsection{Function calls}\label{function-calls-1}}

\textbf{Functions perform actions} --- they take some input, called \texttt{arguments} and return some
output (i.e., a result). Here's a schematic of how a function works:

\includegraphics{Python/PythonIntro/images/function.png}

The general form for calling Python functions is

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# function\_name(arg1, arg2, arg3, ... argn)}
\end{Highlighting}
\end{Shaded}

The arguments in a function can be objects (data, formulae, expressions, etc.),
some of which could be defined by default in the function; these default values may
be modified by the user by specifying options.

\hypertarget{assignment-1}{%
\subsection{Assignment}\label{assignment-1}}

In Python we can assign an object (data structure) to an name using the \texttt{=} operator.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# name = thing\_to\_assign}
\NormalTok{x }\OperatorTok{=} \DecValTok{10}
\end{Highlighting}
\end{Shaded}

The name on the left of the equals sign is one that we chose. When choosing names, they must:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  start with a \emph{letter}
\item
  use only \emph{letters}, \emph{numbers} and \emph{underscores}
\end{enumerate}

\hypertarget{reading-data-1}{%
\subsection{Reading data}\label{reading-data-1}}

Reading information from a file is the first step in many projects, so we'll use functions to read data into Python and assign them to a named object. The workshop materials you downloaded earlier include a file named \texttt{Alice\_in\_wonderland.txt} which contains the text of Lewis Carroll's \emph{Alice's Adventures in Wonderland}. We can use the \texttt{open()} function to create a file \textbf{object} that makes a \textbf{connection} to the file:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alice\_file }\OperatorTok{=} \BuiltInTok{open}\NormalTok{(}\StringTok{"Alice\_in\_wonderland.txt"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \texttt{alice\_file} object name we just created does \emph{not} contain the contents of \texttt{Alice\_in\_wonderland.txt}. It is a representation in Python of the \emph{file itself} rather than the \emph{contents} of the file.

\hypertarget{object-methods}{%
\subsection{Object methods}\label{object-methods}}

The \texttt{alice\_file} object provides \emph{methods} that we can use to do things with it. Methods are invoked using syntax that looks like \texttt{ObjectName.method()}. You can see the methods available for acting on an object by typing the object's name followed by a \texttt{.} and pressing the \texttt{tab} key. For example, typing \texttt{alice\_file.} and pressing \texttt{tab} will display a list of methods as shown below.

\includegraphics{Python/PythonIntro/images/notebook_file_completion.png}.

Among the methods we have for doing things with our \texttt{alice\_file} object is one named \texttt{read}. We can use the \texttt{help} function to learn more about it.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{help}\NormalTok{(alice\_file.read)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Help on built-in function read:
## 
## read(size=-1, /) method of _io.TextIOWrapper instance
##     Read at most n characters from stream.
##     
##     Read from underlying buffer until we have n characters or we hit EOF.
##     If n is negative or omitted, read until EOF.
\end{verbatim}

Since \texttt{alice\_file.read} looks promising, we will invoke this method and see what it does.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alice\_txt }\OperatorTok{=}\NormalTok{ alice\_file.read()}
\BuiltInTok{print}\NormalTok{(alice\_txt[:}\DecValTok{500}\NormalTok{]) }\CommentTok{\# the [:500] gets the first 500 character {-}{-} more on this later.}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ﻿ALICE'S ADVENTURES IN WONDERLAND
## 
## by
## 
## Lewis Carroll
## 
## CHAPTER I. Down the Rabbit-Hole
## 
## Alice was beginning to get very tired of sitting by her sister on the
## bank, and of having nothing to do: once or twice she had peeped into the
## book her sister was reading, but it had no pictures or conversations in
## it, 'and what is the use of a book,' thought Alice 'without pictures or
## conversations?'
## 
## So she was considering in her own mind (as well as she could, for the
## hot day made her feel very sleepy and s
\end{verbatim}

That's all there is to it! We've read the contents of \texttt{Alice\_in\_wonderland.txt} and stored this text in a Python object we named \texttt{alice\_txt}. Now let's start to explore this object, and learn some more things about Python along the way.

\hypertarget{using-object-methods-lists}{%
\section{Using object methods \& lists}\label{using-object-methods-lists}}

\begin{alert}

\textbf{GOAL: To learn how to use methods and lists to analyze data.} We will do this using the Alice text to count:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Words
\item
  Chapters
\item
  Paragraphs
\end{enumerate}

\end{alert}

How many words does the text contain? To answer this question, we can split the text up so there is one element per word, and then count the number of words.

\hypertarget{splitting-a-string-into-a-list-of-words}{%
\subsection{Splitting a string into a list of words}\label{splitting-a-string-into-a-list-of-words}}

How do we figure out how to split strings in Python? We can ask Python what our \texttt{alice\_txt} object is and what methods it provides. We can ask Python what things are using the \texttt{type()} function, like this:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{type}\NormalTok{(alice\_txt)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## <class 'str'>
\end{verbatim}

Python tells us that \texttt{alice\_txt} is of type \texttt{str} (i.e., it is a string). We can find out what methods are available for working with strings by typing \texttt{alice\_txt.} and pressing \texttt{tab}. We'll see that among the methods is one named \texttt{split}, as shown below.

\includegraphics{Python/PythonIntro/images/notebook_string_completion.png}

To learn how to use this method we can check the documentation.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{help}\NormalTok{(alice\_txt.split)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Help on built-in function split:
## 
## split(...) method of builtins.str instance
##     S.split(sep=None, maxsplit=-1) -> list of strings
##     
##     Return a list of the words in S, using sep as the
##     delimiter string.  If maxsplit is given, at most maxsplit
##     splits are done. If sep is not specified or is None, any
##     whitespace string is a separator and empty strings are
##     removed from the result.
\end{verbatim}

Since the default is to split on whitespace (spaces, newlines, tabs) we can get a reasonable word count simply by calling the \texttt{split} method and counting the number of elements in the result. But, before we do that, we should learn more about the type of object the \texttt{split} method has returned.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alice\_words }\OperatorTok{=}\NormalTok{ alice\_txt.split() }\CommentTok{\# returns a list}
\BuiltInTok{type}\NormalTok{(alice\_words)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## <class 'list'>
\end{verbatim}

\hypertarget{working-with-lists}{%
\subsection{Working with lists}\label{working-with-lists}}

The \texttt{split} method we used to break up the text of \emph{Alice in Wonderland} into words produced a \emph{list}. A lot of the techniques we'll use later to analyze this text also produce lists, so its worth taking a few minutes to learn more about them.

Note that the displayed representation of lists and other data structures in Python often closely matches the syntax used to create them. For example, we can create a list using square brackets, just as we see when we print a list.

A \emph{list} in Python is used to store a collection of items:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create a list}
\NormalTok{y }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"D"}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

As with other types in Python, you can get a list of methods by typing the name of the object followed by a \texttt{.} and pressing \texttt{tab}.

\hypertarget{extracting-subsets-from-lists}{%
\subsection{Extracting subsets from lists}\label{extracting-subsets-from-lists}}

Among the things you can do with a list is extract subsets of items using \textbf{bracket indexing notation}. This is useful in many situations, including the current one where we want to inspect a long list without printing out the whole thing.

The examples below show how indexing works in Python. First using pseudocode:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# syntax}
\CommentTok{\# object[ start : end : by ]}

\CommentTok{\# defaults}
\CommentTok{\# object[ 0 : end : 1 ]}
\end{Highlighting}
\end{Shaded}

Then using a real list:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create a list}
\NormalTok{y }\OperatorTok{=}\NormalTok{ [}\DecValTok{1}\NormalTok{, }\StringTok{"b"}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"D"}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{]}

\NormalTok{y[}\DecValTok{0}\NormalTok{] }\CommentTok{\# returns first element {-} the number 1 (yes, the index counts from zero!)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y[}\DecValTok{1}\NormalTok{] }\CommentTok{\# returns second element {-} the letter "b"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'b'
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y[ :}\DecValTok{3}\NormalTok{] }\CommentTok{\# returns a list with only the first 3 elements, but index is of length 4 (0 to 3) because last index is excluded}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1, 'b', 3]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y[}\DecValTok{2}\NormalTok{:}\DecValTok{5}\NormalTok{] }\CommentTok{\# returns a list with elements 3, "D", 5}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [3, 'D', 5]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{] }\CommentTok{\# returns last element {-} the number 6 }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y[}\OperatorTok{{-}}\DecValTok{4}\NormalTok{: ] }\CommentTok{\# returns a list with last 4 elements}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [3, 'D', 5, 6]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alice\_words[}\DecValTok{11}\NormalTok{:}\DecValTok{20}\NormalTok{] }\CommentTok{\# returns a list with words 11 through 19}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ['Rabbit-Hole', 'Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of']
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alice\_words[}\OperatorTok{{-}}\DecValTok{10}\NormalTok{: ] }\CommentTok{\# returns a list with the last 10 words}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ['her', 'own', 'child-life,', 'and', 'the', 'happy', 'summer', 'days.', 'THE', 'END']
\end{verbatim}

\hypertarget{using-sets-to-count-unique-items}{%
\subsection{Using sets to count unique items}\label{using-sets-to-count-unique-items}}

Now that we have a list containing the individual words from \emph{Alice's Adventures in Wonderland}, we can calculate how many words there are in total using the \texttt{len()} (length) function:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{len}\NormalTok{(alice\_words) }\CommentTok{\# counts elements in a data structure}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 26445
\end{verbatim}

According to our above computation, there are about 26 thousand total words in the Alice text. But how many \emph{unique} words are there? Python has a special data structure called a \emph{set} that makes it easy to find out. A \emph{set} drops all duplicates, giving a collection of the unique elements. Here's a simple example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set example}
\NormalTok{mylist }\OperatorTok{=}\NormalTok{ \{}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{\}}
\BuiltInTok{set}\NormalTok{(mylist)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## {1, 4, 5, 9}
\end{verbatim}

Now we can count the number of unique elements in the list by getting the length \texttt{len()} of the set \texttt{set()}:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{len}\NormalTok{(}\BuiltInTok{set}\NormalTok{(mylist))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 4
\end{verbatim}

We can now use the \texttt{set()} function to convert the list of all words (\texttt{alice\_words}) into a set of \emph{unique} words and then count them:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{len}\NormalTok{(}\BuiltInTok{set}\NormalTok{(alice\_words)) }\CommentTok{\# counts unique elements in a data structure}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 5295
\end{verbatim}

There are 5295 unique words in the text.

\hypertarget{exercise-0-3}{%
\subsection{Exercise 0}\label{exercise-0-3}}

\textbf{Reading text from a file \& splitting}

\emph{Alice's Adventures in Wonderland} is full of memorable characters. The main characters from the story are listed, one-per-line, in the file named \texttt{Characters.txt}.

NOTE: we will not always explicitly demonstrate everything you need to know in order to complete an exercise. Instead we focus on teaching you how to discover available methods and how use the help function to learn how to use them. It is expected that you will spend some time during the exercises looking for appropriate methods and perhaps reading documentation.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Open the \texttt{Characters.txt} file and read its contents.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Split text on newlines to produce a list with one element per line. Store the result as \texttt{alice\_characters}. HINT: you can split on newlines using the \texttt{\textbackslash{}n} separator.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 0 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Open the Characters.txt file and read its contents.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{characters\_file }\OperatorTok{=} \BuiltInTok{open}\NormalTok{(}\StringTok{"Characters.txt"}\NormalTok{)}
\NormalTok{characters\_txt }\OperatorTok{=}\NormalTok{ characters\_file.read()}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Split text on newlines to produce a list with one element per line.
  Store the result as ``alice\_characters''.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alice\_characters }\OperatorTok{=}\NormalTok{ characters\_txt.split(sep}\OperatorTok{=}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{alice\_characters}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ['Alice', 'White Rabbit', 'Mouse', 'Dodo', 'Lory', 'Eaglet', 'Duck', 'Pat', 'Bill the Lizard', 'Puppy', 'Caterpillar', 'Duchess', 'Cheshire Cat', 'March Hare', 'Hatter', 'Dormouse', 'Queen of Hearts', 'Knave of Hearts', 'King of Hearts', 'Gryphon', 'Mock Turtle', '']
\end{verbatim}

\end{alert}

\hypertarget{control-flow}{%
\subsection{Control flow}\label{control-flow}}

Sometimes we may want to control the flow of code in an analysis using \textbf{choices},
such as \texttt{if} and \texttt{else} statements, which allow you to run different code depending on the input.
The basic form is:

\begin{verbatim}
```python
if (condition) true_action else false_action
```

If `condition` is `TRUE`, `true_action` is evaluated; if `condition` is `FALSE`,
the optional `false_action` is evaluated.
\end{verbatim}

The conditions that are evaluated use \textbf{logical and relational operators} to determine equivalence or make some other relational comparisons.

\hypertarget{logical-relational-operators-1}{%
\subsection{Logical \& relational operators}\label{logical-relational-operators-1}}

Here's a table of commonly used relational operators:

\begin{longtable}[]{@{}ll@{}}
\toprule
Operator & Meaning\tabularnewline
\midrule
\endhead
\texttt{==} & equal to\tabularnewline
\texttt{!=} & not equal to\tabularnewline
\texttt{\textgreater{}} & greater than\tabularnewline
\texttt{\textgreater{}=} & greater than or equal to\tabularnewline
\texttt{\textless{}} & less than\tabularnewline
\texttt{\textless{}=} & less than or equal to\tabularnewline
\bottomrule
\end{longtable}

These relational operators may be combined with logical operators, such as \texttt{and} or \texttt{or}, as we'll see below.

\hypertarget{counting-list-elements}{%
\subsection{Counting list elements}\label{counting-list-elements}}

Now that we know how to split a string and how to work with the resulting list, we can split on chapter markers to count the number of chapters. All we need to do is specify the string to split on. Since each chapter is marked with the string \texttt{\textquotesingle{}CHAPTER\ \textquotesingle{}} followed by the chapter number, we can split the text up into chapters using this as the separator.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alice\_chapters }\OperatorTok{=}\NormalTok{ alice\_txt.split(}\StringTok{"CHAPTER "}\NormalTok{)}
\BuiltInTok{len}\NormalTok{(alice\_chapters)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 13
\end{verbatim}

Since the first element contains the material \emph{before} the first chapter, this tells us there are twelve chapters in the book.

We can also count the number of times the ``Bunny'' and ``Duck'' characters appear in a given Chapter, say Chapter 2:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bunny\_count\_ch2 }\OperatorTok{=}\NormalTok{ alice\_chapters[}\DecValTok{2}\NormalTok{].count(}\StringTok{"Bunny"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(bunny\_count\_ch2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{duck\_count\_ch2 }\OperatorTok{=}\NormalTok{ alice\_chapters[}\DecValTok{2}\NormalTok{].count(}\StringTok{"Duck"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(duck\_count\_ch2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 1
\end{verbatim}

By combining choice statements with logical and/or relational operators, we can then determine which of these two characters
appears more often in Chapter 2:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{ bunny\_count\_ch2 }\OperatorTok{\textless{}}\NormalTok{ duck\_count\_ch2:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Bunny count is less than Duck count in Chapter II."}\NormalTok{)}
\ControlFlowTok{elif}\NormalTok{ bunny\_count\_ch2 }\OperatorTok{\textgreater{}}\NormalTok{ duck\_count\_ch2:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Bunny count is larger than Duck count in Chapter II."}\NormalTok{)}
\ControlFlowTok{else}\NormalTok{:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Bunny count is equal to Duck count in Chapter II."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Bunny count is less than Duck count in Chapter II.
\end{verbatim}

We can count paragraphs in a similar way to chapters. Paragraphs are indicated by a blank line, i.e., two newlines in a row. When working with strings we can represent newlines with \texttt{\textbackslash{}n}. Paragraphs are indicated by two new lines, and so our basic paragraph separator is \texttt{\textbackslash{}n\textbackslash{}n}. We can see this separator by looking at the content.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(alice\_txt[:}\DecValTok{500}\NormalTok{]) }\CommentTok{\# explicit printing {-}{-}{-} formats text nicely}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ﻿ALICE'S ADVENTURES IN WONDERLAND
## 
## by
## 
## Lewis Carroll
## 
## CHAPTER I. Down the Rabbit-Hole
## 
## Alice was beginning to get very tired of sitting by her sister on the
## bank, and of having nothing to do: once or twice she had peeped into the
## book her sister was reading, but it had no pictures or conversations in
## it, 'and what is the use of a book,' thought Alice 'without pictures or
## conversations?'
## 
## So she was considering in her own mind (as well as she could, for the
## hot day made her feel very sleepy and s
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alice\_txt[:}\DecValTok{500}\NormalTok{] }\CommentTok{\# returns content without printing it}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## "\ufeffALICE'S ADVENTURES IN WONDERLAND\n\nby\n\nLewis Carroll\n\nCHAPTER I. Down the Rabbit-Hole\n\nAlice was beginning to get very tired of sitting by her sister on the\nbank, and of having nothing to do: once or twice she had peeped into the\nbook her sister was reading, but it had no pictures or conversations in\nit, 'and what is the use of a book,' thought Alice 'without pictures or\nconversations?'\n\nSo she was considering in her own mind (as well as she could, for the\nhot day made her feel very sleepy and s"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alice\_paragraphs }\OperatorTok{=}\NormalTok{ alice\_txt.split(}\StringTok{"}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Before counting the number of paragraphs, I want to inspect the result to see if it looks correct:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(alice\_paragraphs[}\DecValTok{0}\NormalTok{], }\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{=========="}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ﻿ALICE'S ADVENTURES IN WONDERLAND 
## ==========
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(alice\_paragraphs[}\DecValTok{1}\NormalTok{], }\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{=========="}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## by 
## ==========
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(alice\_paragraphs[}\DecValTok{2}\NormalTok{], }\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{=========="}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Lewis Carroll 
## ==========
\end{verbatim}

We're counting the title, author, and chapter lines as paragraphs, but this will do for a rough count.

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{len}\NormalTok{(alice\_paragraphs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 830
\end{verbatim}

Now let's use a logical operator to find out if ``Alice'' or ``Eaglet'' appear in paragraph 11:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alice\_eaglet\_exist }\OperatorTok{=} \StringTok{"Alice"} \KeywordTok{in}\NormalTok{ alice\_paragraphs[}\DecValTok{10}\NormalTok{] }\KeywordTok{or} \StringTok{"Eaglet"} \KeywordTok{in}\NormalTok{ alice\_paragraphs[}\DecValTok{10}\NormalTok{]}
\NormalTok{alice\_eaglet\_exist}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## True
\end{verbatim}

\hypertarget{exercise-1-4}{%
\subsection{Exercise 1}\label{exercise-1-4}}

\textbf{Count the number of main characters}

So far we've learned that there are 12 chapters, around 830 paragraphs, and about 26 thousand words in \emph{Alice's Adventures in Wonderland}. Along the way we've also learned how to open a file and read its contents, split strings, calculate the length of objects, discover methods for string and list objects, and index/subset lists in Python. Now it is time for you to put these skills to use to learn something about the main characters in the story.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Count the number of main characters in the story (i.e., get the length of the list you created in previous exercise).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Extract and print just the first character from the list you created in the previous exercise.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Test whether the length of the 3rd and 8th character's names are equal. Test whether the length of
  the 3rd character's name is greater than or equal to the length of the 6th character's name. Now test
  whether EITHER of the above conditions are true. HINT: use the \texttt{len()} function.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  (BONUS, optional): Sort the list you created in step 2 alphabetically,
  and then extract the last element.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 1 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Count the number of main characters in the story (i.e., get the length of the list you created in previous exercise).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{len}\NormalTok{(alice\_characters)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 22
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Extract and print just the first character from the list you created in the previous exercise.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(alice\_characters[}\DecValTok{0}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Alice
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Test whether the length of the 3rd and 8th character's names are equal. Test whether the length of
  the 3rd character's name is greater than or equal to the length of the 6th character's name. Now test
  whether EITHER of the above conditions are true. HINT: use the \texttt{len()} function.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{len}\NormalTok{(alice\_characters[}\DecValTok{2}\NormalTok{]) }\OperatorTok{==} \BuiltInTok{len}\NormalTok{(alice\_characters[}\DecValTok{7}\NormalTok{]) }\KeywordTok{or} \BuiltInTok{len}\NormalTok{(alice\_characters[}\DecValTok{2}\NormalTok{]) }\OperatorTok{\textgreater{}=} \BuiltInTok{len}\NormalTok{(alice\_characters[}\DecValTok{5}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## False
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  (BONUS, optional): Sort the list you created in step 2 alphabetically,
  and then extract the last element.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alice\_characters.sort()}
\NormalTok{alice\_characters[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'White Rabbit'
\end{verbatim}

\end{alert}

\hypertarget{iterating-over-collections-of-data}{%
\section{Iterating over collections of data}\label{iterating-over-collections-of-data}}

\begin{alert}

\textbf{GOAL: To learn how to automate repetitive tasks by iterating over collections of data.} We will do this using the Alice text to count:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Words nested within paragraphs
\item
  Paragraphs nested within chapters
\end{enumerate}

\end{alert}

This far our analysis has treated the text as a ``flat'' data structure. For example, when we counted words we just counted words in the whole document, rather than counting the number of words in each chapter. If we want to treat our document as a nested structure, with words forming sentences, sentences forming paragraphs, paragraphs forming chapters, and chapters forming the book, we need to learn some additional tools. Specifically, we need to learn how to iterate over lists (or other collections) and do things with each element in a collection.

There are several ways to iterate in Python, of which we will focus on \emph{for loops}.

\hypertarget{iterating-over-lists-using-for-loops}{%
\subsection{Iterating over lists using for-loops}\label{iterating-over-lists-using-for-loops}}

A \emph{for loop} is a way of cycling through the elements of a collection and doing something with each one. The for loop logic is:

\includegraphics{Python/PythonIntro/images/for_loop_pic_small.png}

The for loop syntax is:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for} \OperatorTok{\textless{}}\NormalTok{thing}\OperatorTok{\textgreater{}} \KeywordTok{in} \OperatorTok{\textless{}}\NormalTok{collection}\OperatorTok{\textgreater{}}\NormalTok{:}
\NormalTok{    do stuff }\ControlFlowTok{with} \OperatorTok{\textless{}}\NormalTok{thing}\OperatorTok{\textgreater{}}
\end{Highlighting}
\end{Shaded}

\includegraphics{Python/PythonIntro/images/python_for_loop_small.png}

Notice that:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{the body of the for-loop is indented}. This is important, because it is this indentation that defines the \emph{body} of the loop --- the place where things are done.
\item
  \textbf{White space matters in Python!}
\end{enumerate}

A simple example:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{):}
    \BuiltInTok{print}\NormalTok{(i)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 0
## 1
## 2
## 3
## 4
## 5
## 6
## 7
## 8
## 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}DONE.\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## DONE.
\end{verbatim}

Notice that ``DONE.'' is only printed once, since \texttt{print(\textquotesingle{}DONE.\textquotesingle{})} is not indented and is therefore outside of the body of the loop.

As a simple example using the Alice text, we can cycle through the first 6 paragraphs and print each one. Cycling through with a loop makes it easy to insert a separator between the paragraphs, making it much clearer to read the output:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ paragraph }\KeywordTok{in}\NormalTok{ alice\_paragraphs[:}\DecValTok{6}\NormalTok{]:}
    \BuiltInTok{print}\NormalTok{(paragraph)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}==================================\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ﻿ALICE'S ADVENTURES IN WONDERLAND
## ==================================
## by
## ==================================
## Lewis Carroll
## ==================================
## CHAPTER I. Down the Rabbit-Hole
## ==================================
## Alice was beginning to get very tired of sitting by her sister on the
## bank, and of having nothing to do: once or twice she had peeped into the
## book her sister was reading, but it had no pictures or conversations in
## it, 'and what is the use of a book,' thought Alice 'without pictures or
## conversations?'
## ==================================
## So she was considering in her own mind (as well as she could, for the
## hot day made her feel very sleepy and stupid), whether the pleasure
## of making a daisy-chain would be worth the trouble of getting up and
## picking the daisies, when suddenly a White Rabbit with pink eyes ran
## close by her.
## ==================================
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{\textquotesingle{}DONE.\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## DONE.
\end{verbatim}

Loops in Python are great because the syntax is relatively simple, and because they are very powerful. Inside of the body of a loop you can use all the tools you use elsewhere in Python.

Here is one more example of a loop, this time iterating over all the chapters and calculating the number of paragraphs in each chapter.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ chapter }\KeywordTok{in}\NormalTok{ alice\_chapters[}\DecValTok{1}\NormalTok{:]:}
\NormalTok{    paragraphs }\OperatorTok{=}\NormalTok{ chapter.split(}\StringTok{"}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{"}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\BuiltInTok{len}\NormalTok{(paragraphs))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 33
## 29
## 51
## 45
## 81
## 84
## 108
## 74
## 95
## 88
## 77
## 73
\end{verbatim}

\hypertarget{organizing-results-in-dictionaries}{%
\subsection{Organizing results in dictionaries}\label{organizing-results-in-dictionaries}}

It's often useful to store separate pieces of data that are related to one another in a \texttt{dict} (i.e., ``dictionary''), which is designed to store key-value pairs. For example, we can calculate the number of times ``Alice'' is mentioned per chapter and associate each count with the chapter title it corresponds to.

The dictionary structure looks like:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# mydict = \{key1:value1, key2:value2, key3:value3\}}
\end{Highlighting}
\end{Shaded}

A simple example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydict }\OperatorTok{=}\NormalTok{ \{}\StringTok{"apple"}\NormalTok{:}\DecValTok{5}\NormalTok{, }\StringTok{"pear"}\NormalTok{:}\DecValTok{6}\NormalTok{, }\StringTok{"grape"}\NormalTok{:}\DecValTok{10}\NormalTok{\}}
\BuiltInTok{print}\NormalTok{(mydict)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## {'apple': 5, 'pear': 6, 'grape': 10}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compare the above dict to a list}
\NormalTok{mylist }\OperatorTok{=}\NormalTok{[}\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{10}\NormalTok{]}
\BuiltInTok{print}\NormalTok{(mylist)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [5, 6, 10]
\end{verbatim}

To associate chapter titles with ``Alice'' counts, we will first need to learn how to \textbf{append} elements to a list:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{container }\OperatorTok{=}\NormalTok{ [] }\CommentTok{\# a list}

\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{10}\NormalTok{):}
\NormalTok{    container.append(i) }\CommentTok{\# append elements to the list}

\BuiltInTok{print}\NormalTok{(container)    }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
\end{verbatim}

Now, with the Alice text, first we can iterate over each chapter and grab just the first line (that is, the chapter titles). These will become our \textbf{keys}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{chapter\_titles }\OperatorTok{=}\NormalTok{ []}

\ControlFlowTok{for}\NormalTok{ chapter }\KeywordTok{in}\NormalTok{ alice\_chapters[}\DecValTok{1}\NormalTok{:]:}
\NormalTok{    chapter\_titles.append(chapter.split(sep}\OperatorTok{=}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)[}\DecValTok{0}\NormalTok{])}

\BuiltInTok{print}\NormalTok{(chapter\_titles)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ['I. Down the Rabbit-Hole', 'II. The Pool of Tears', 'III. A Caucus-Race and a Long Tale', 'IV. The Rabbit Sends in a Little Bill', 'V. Advice from a Caterpillar', 'VI. Pig and Pepper', 'VII. A Mad Tea-Party', "VIII. The Queen's Croquet-Ground", "IX. The Mock Turtle's Story", 'X. The Lobster Quadrille', 'XI. Who Stole the Tarts?', "XII. Alice's Evidence"]
\end{verbatim}

Next, we can iterate over each chapter and count the number of times ``Alice'' was mentioned. These will become our \textbf{values}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{chapter\_Alice }\OperatorTok{=}\NormalTok{ []}

\ControlFlowTok{for}\NormalTok{ chapter }\KeywordTok{in}\NormalTok{ alice\_chapters[}\DecValTok{1}\NormalTok{:]:}
\NormalTok{    chapter\_Alice.append(chapter.count(}\StringTok{"Alice"}\NormalTok{))}

\BuiltInTok{print}\NormalTok{(chapter\_Alice)  }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [28, 24, 23, 31, 35, 43, 51, 39, 52, 30, 16, 23]
\end{verbatim}

Finally we can combine the chapter titles (\textbf{keys}) and ``Alice'' counts (\textbf{values}) and convert them to a dictionary.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# combine titles and counts}
\NormalTok{mydict }\OperatorTok{=} \BuiltInTok{dict}\NormalTok{(}\BuiltInTok{zip}\NormalTok{(chapter\_titles, chapter\_Alice))}

\BuiltInTok{print}\NormalTok{(mydict)}

\CommentTok{\# help(zip)         }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## {'I. Down the Rabbit-Hole': 28, 'II. The Pool of Tears': 24, 'III. A Caucus-Race and a Long Tale': 23, 'IV. The Rabbit Sends in a Little Bill': 31, 'V. Advice from a Caterpillar': 35, 'VI. Pig and Pepper': 43, 'VII. A Mad Tea-Party': 51, "VIII. The Queen's Croquet-Ground": 39, "IX. The Mock Turtle's Story": 52, 'X. The Lobster Quadrille': 30, 'XI. Who Stole the Tarts?': 16, "XII. Alice's Evidence": 23}
\end{verbatim}

\hypertarget{exercise-2-3}{%
\subsection{Exercise 2}\label{exercise-2-3}}

\textbf{Iterating \& counting things}

Now that we know how to iterate using for-loops, the possibilities really start to open up. For example, we can use these techniques to count the number of times each character appears in the story.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Make sure you have both the text and the list of characters.
\end{enumerate}

Open and read both ``Alice\_in\_wonderland.txt'' and
``Characters.txt'' if you have not already done so.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Which chapter has the most words?
\end{enumerate}

Split the text into chapters (i.e., split on ``CHAPTER'') and use a for-loop to iterate over the chapters.
For each chapter, split it into words and calculate the length.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  How many times is each character mentioned in the text?
\end{enumerate}

Iterate over the list of characters using a for-loop.
For each character, call the count method with that character as the argument.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  (BONUS, optional): Put the character counts computed
  above in a dictionary with character names as the keys and
  counts as the values.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 2 Solution}

\begin{alert}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Make sure you have both the text and the list of characters.
  Open and read both ``Alice\_in\_wonderland.txt'' and ``Characters.txt'' if you have not already done so.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{characters\_txt }\OperatorTok{=} \BuiltInTok{open}\NormalTok{(}\StringTok{"Characters.txt"}\NormalTok{).read()}
\NormalTok{alice\_txt }\OperatorTok{=} \BuiltInTok{open}\NormalTok{(}\StringTok{"Alice\_in\_wonderland.txt"}\NormalTok{).read()}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Which chapter has the most words?
  Split the text into chapters (i.e., split on ``CHAPTER'') and use a for-loop to iterate over the chapters.
  For each chapter, split it into words and calculate the length.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{words\_per\_chapter }\OperatorTok{=}\NormalTok{ []}

\ControlFlowTok{for}\NormalTok{ chapter }\KeywordTok{in}\NormalTok{ alice\_chapters:}
\NormalTok{    words\_per\_chapter.append(}\BuiltInTok{len}\NormalTok{(chapter.split()))}

\BuiltInTok{print}\NormalTok{(words\_per\_chapter)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [7, 2184, 2098, 1701, 2614, 2185, 2592, 2286, 2486, 2271, 2028, 1877, 2104]
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  How many times is each character mentioned in the text?
  Iterate over the list of characters using a for-loop.
  For each character, call the count method with that character as the argument.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{num\_per\_character }\OperatorTok{=}\NormalTok{ []}

\ControlFlowTok{for}\NormalTok{ character }\KeywordTok{in}\NormalTok{ characters\_txt.split(sep}\OperatorTok{=}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{):}
\NormalTok{    num\_per\_character.append(alice\_txt.count(character))}

\BuiltInTok{print}\NormalTok{(num\_per\_character)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [395, 20, 30, 13, 7, 3, 3, 3, 0, 0, 27, 42, 4, 30, 55, 40, 3, 3, 0, 55, 53, 144403]
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  (BONUS, optional): Put the character counts computed above in a
  dictionary with character names as the keys and counts as the values.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{characters }\OperatorTok{=}\NormalTok{ characters\_txt.split(sep}\OperatorTok{=}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\BuiltInTok{dict}\NormalTok{(}\BuiltInTok{zip}\NormalTok{(characters, num\_per\_character))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## {'Alice': 395, 'White Rabbit': 20, 'Mouse': 30, 'Dodo': 13, 'Lory': 7, 'Eaglet': 3, 'Duck': 3, 'Pat': 3, 'Bill the Lizard': 0, 'Puppy': 0, 'Caterpillar': 27, 'Duchess': 42, 'Cheshire Cat': 4, 'March Hare': 30, 'Hatter': 55, 'Dormouse': 40, 'Queen of Hearts': 3, 'Knave of Hearts': 3, 'King of Hearts': 0, 'Gryphon': 55, 'Mock Turtle': 53, '': 144403}
\end{verbatim}

\end{alert}

\hypertarget{importing-packages}{%
\section{Importing packages}\label{importing-packages}}

\begin{alert}

\textbf{GOAL: To learn how to expand Python's functionality by importing packages.}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Import \texttt{numpy}
\item
  Calculate simple statistics
\end{enumerate}

\end{alert}

Now that we know how to iterate over lists and calculate numbers for each element, we may wish to do some simple math using these numbers. For example, we may want to calculate the mean and standard deviation of the distribution of the number of paragraphs in each chapter. Python has a handful of math functions built-in (e.g., \texttt{min()} and \texttt{max()}) but built-in math support is pretty limited.

When you find that something isn't available in Python itself, its time to look for a package that does it. Although it is somewhat overkill for simply calculating a mean we're going to use a popular package called \texttt{numpy} for this. The \texttt{numpy} package is included in the Anaconda Python distribution we are using, so we don't need to install it separately.

To use \texttt{numpy} or other packages, you must first import them.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# import \textless{}package{-}name\textgreater{}}
\end{Highlighting}
\end{Shaded}

We can import \texttt{numpy} as follows:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy}
\end{Highlighting}
\end{Shaded}

To use functions from a package, we can prefix the function with the package name, separated by a period:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# \textless{}package{-}name\textgreater{}.\textless{}function\_name\textgreater{}()}
\end{Highlighting}
\end{Shaded}

The \texttt{numpy} package is very popular and includes a lot of useful functions. For example, we can use it to calculate means and standard deviations:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(numpy.mean(chapter\_Alice))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 32.916666666666664
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(numpy.std(chapter\_Alice))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 10.92747556493366
\end{verbatim}

\hypertarget{wrap-up-5}{%
\section{Wrap-up}\label{wrap-up-5}}

\hypertarget{feedback-5}{%
\subsection{Feedback}\label{feedback-5}}

These workshops are a work in progress, please provide any feedback to: \href{mailto:help@iq.harvard.edu}{\nolinkurl{help@iq.harvard.edu}}

\hypertarget{resources-7}{%
\subsection{Resources}\label{resources-7}}

\begin{itemize}
\tightlist
\item
  IQSS

  \begin{itemize}
  \tightlist
  \item
    Workshops: \url{https://dss.iq.harvard.edu/workshop-materials}
  \item
    Data Science Services: \url{https://dss.iq.harvard.edu/}
  \item
    Research Computing Environment: \url{https://iqss.github.io/dss-rce/}
  \end{itemize}
\item
  HBS

  \begin{itemize}
  \tightlist
  \item
    Research Computing Services workshops: \url{https://training.rcs.hbs.org/workshops}
  \item
    Other HBS RCS resources: \url{https://training.rcs.hbs.org/workshop-materials}
  \item
    RCS consulting email: \url{mailto:research@hbs.edu}
  \end{itemize}
\item
  Graphics

  \begin{itemize}
  \tightlist
  \item
    matplotlib: \url{https://matplotlib.org/}
  \item
    seaborn: \url{https://seaborn.pydata.org/}
  \item
    plotly: \url{https://plot.ly/python/}
  \end{itemize}
\item
  Quantitative Data Analysis

  \begin{itemize}
  \tightlist
  \item
    numpy: \url{http://www.numpy.org/}
  \item
    scipy: \url{https://www.scipy.org/}
  \item
    pandas: \url{https://pandas.pydata.org/}
  \item
    scikit-learn: \url{http://scikit-learn.org/stable/}
  \item
    statsmodels: \url{http://www.statsmodels.org/stable/}
  \end{itemize}
\item
  Text analysis

  \begin{itemize}
  \tightlist
  \item
    textblob: \url{https://textblob.readthedocs.io/en/dev/}
  \item
    nltk: \url{http://www.nltk.org/}
  \item
    Gensim: \url{https://radimrehurek.com/gensim/}
  \end{itemize}
\item
  Webscraping

  \begin{itemize}
  \tightlist
  \item
    scrapy: \url{https://scrapy.org/}
  \item
    requests: \url{http://docs.python-requests.org/en/master/}
  \item
    lxml: \url{https://lxml.de/}
  \item
    BeautifulSoup: \url{https://www.crummy.com/software/BeautifulSoup/}
  \end{itemize}
\item
  Social Network Analysis

  \begin{itemize}
  \tightlist
  \item
    networkx: \url{https://networkx.github.io/}
  \item
    graph-tool: \url{https://graph-tool.skewed.de/}
  \end{itemize}
\end{itemize}

\hypertarget{python-web-scraping}{%
\chapter{Python Web-Scraping}\label{python-web-scraping}}

\textbf{Topics}

\begin{itemize}
\tightlist
\item
  Web basics
\item
  Making web requests
\item
  Inspecting web sites
\item
  Retrieving JSON data
\item
  Using Xpaths to retrieve \texttt{html} content
\item
  Parsing \texttt{html} content
\item
  Cleaning and storing text from \texttt{html}
\end{itemize}

\hypertarget{setup-5}{%
\section{Setup}\label{setup-5}}

\hypertarget{software-and-materials-5}{%
\subsection{Software and Materials}\label{software-and-materials-5}}

Follow the \href{./PythonInstall.html}{Python Installation} instructions and ensure that you can successfully start JupyterLab.

\hypertarget{class-structure-5}{%
\subsection{Class Structure}\label{class-structure-5}}

Informal - Ask questions at any time. Really!

Collaboration is encouraged - please spend a minute introducing yourself to your neighbors!

\hypertarget{prerequisites-5}{%
\subsection{Prerequisites}\label{prerequisites-5}}

This is an intermediate / advanced Python course:

\begin{itemize}
\tightlist
\item
  Assumes knowledge of Python, including:

  \begin{itemize}
  \tightlist
  \item
    lists
  \item
    dictionaries
  \item
    logical indexing
  \item
    iteration with for-loops
  \end{itemize}
\item
  Assumes basic knowledge of web page structure
\item
  Relatively fast-paced
\end{itemize}

If you need an introduction to Python or a refresher, we recommend our \href{https://iqss.github.io/dss-workshops/PythonIntro.html}{Python Introduction}.

\hypertarget{goals-4}{%
\subsection{Goals}\label{goals-4}}

\begin{alert}

This workshop is organized into two main parts:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Retrive information in JSON format
\item
  Parse HTML files
\end{enumerate}

Note that this workshop will not teach you everything you need to know in order to retrieve data from any web service you might wish to scrape.

\end{alert}

\hypertarget{web-scraping-background}{%
\section{Web scraping background}\label{web-scraping-background}}

\hypertarget{what-is-web-scraping}{%
\subsection{What is web scraping?}\label{what-is-web-scraping}}

Web scraping is the activity of automating retrieval of information from a web service designed for human interaction.

\hypertarget{is-web-scraping-legal-is-it-ethical}{%
\subsection{Is web scraping legal? Is it ethical?}\label{is-web-scraping-legal-is-it-ethical}}

It depends. If you have legal questions seek legal counsel. You can mitigate some ethical issues by building delays and restrictions into your web scraping program so as to avoid impacting the availability of the web service for other users or the cost of hosting the service for the service provider.

\hypertarget{web-scraping-approaches}{%
\subsection{Web scraping approaches}\label{web-scraping-approaches}}

No two websites are identical --- websites are built for different purposes by different people and so have different underlying structures. Because they are heterogeneous, there is no single way to scrape a website. \textbf{The scraping approach therefore has to be tailored to each individual site.} Here are some commonly used approaches:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use requests to extract information from structured JSON / XML files
\item
  Use requests to extract information from HTML
\item
  Automate a browser to retrieve information from HTML
\end{enumerate}

Bear in mind that even once you've decided upon the best approach for a particular site, it will be necessary to modify that approach to suit your particular use-case.

\hypertarget{how-does-the-web-work}{%
\subsection{How does the web work?}\label{how-does-the-web-work}}

\hypertarget{components}{%
\subsubsection{Components}\label{components}}

Computers connected to the web are called \textbf{clients} and \textbf{servers}. A simplified diagram of how they interact might look like this:

\includegraphics{Python/PythonWebScrape/images/client_server.png}

\begin{itemize}
\tightlist
\item
  \textbf{Clients} are the typical web user's internet-connected devices (for example, your computer connected to your Wi-Fi) and web-accessing software available on those devices (usually a web browser like Firefox or Chrome).
\item
  \textbf{Servers} are computers that store webpages, sites, or apps. When a client device wants to access a webpage, a copy of the webpage is downloaded from the server onto the client machine to be displayed in the user's web browser.
\item
  \textbf{HTTP} is a language for clients and servers to speak to each other.
\end{itemize}

\hypertarget{so-what-happens}{%
\subsubsection{So what happens?}\label{so-what-happens}}

When you type a web address into your browser:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The browser finds the address of the server that the website lives on.
\item
  The browser sends an \textbf{HTTP request message} to the server, asking it to send a copy of the website to the client.
\item
  If the server approves the client's request, the server sends the client a \texttt{200\ OK} message, and then starts displaying the website in the browser.
\end{enumerate}

\hypertarget{retrieve-data-in-json-format-if-you-can}{%
\section{Retrieve data in JSON format if you can}\label{retrieve-data-in-json-format-if-you-can}}

\begin{alert}

\textbf{GOAL: To retrieve information in JSON format and organize it into a spreadsheet.}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Inspect the website to check if the content is stored in JSON format
\item
  Make a request to the website server to retrieve the JSON file
\item
  Convert from JSON format into a Python dictionary
\item
  Extract the data from the dictionary and store in a .csv file
\end{enumerate}

\end{alert}

We wish to extract information from \url{https://www.harvardartmuseums.org/collections}. Like most modern web pages, a lot goes on behind the scenes to produce the page we see in our browser. Our goal is to pull back the curtain to see what the website does when we interact with it. Once we see how the website works we can start retrieving data from it.

If we are lucky we'll find a resource that returns the data we're looking for in a structured format like \href{https://json.org/}{JSON} or \href{https://en.wikipedia.org/wiki/XML}{XML}.

\includegraphics{Python/PythonWebScrape/images/json-format.png}

This is useful because it is very easy to convert data from JSON or XML into a spreadsheet type format --- like a csv or Excel file.

\hypertarget{examine-the-websites-structure}{%
\subsection{Examine the website's structure}\label{examine-the-websites-structure}}

The basic strategy is pretty much the same for most scraping projects. We will use our web browser (Chrome or Firefox recommended) to examine the page you wish to retrieve data from, and copy/paste information from your web browser into your scraping program.

We start by opening the collections web page in a web browser and inspecting it.

\includegraphics{Python/PythonWebScrape/images/dev_tools.png}

\includegraphics{Python/PythonWebScrape/images/dev_tools_pane.png}

If we scroll down to the bottom of the Collections page, we'll see a button that says ``Load More''. Let's see what happens when we click on that button. To do so, click on ``Network'' in the developer tools window, then click the ``Load More Collections'' button. You should see a list of requests that were made as a result of clicking that button, as shown below.

\includegraphics{Python/PythonWebScrape/images/dev_tools_network.png}

If we look at that second request, the one to a script named \texttt{browse}, we'll see that it returns all the information we need, in a convenient format called \texttt{JSON}. All we need to retrieve collection data is to make \texttt{GET} requests to \url{https://www.harvardartmuseums.org/browse} with the correct parameters.

\hypertarget{launch-jupyterlab-2}{%
\subsection{Launch JupyterLab}\label{launch-jupyterlab-2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Start the \texttt{Anaconda\ Navigator} program
\item
  Click the \texttt{Launch} button under \texttt{Jupyter\ Lab}
\item
  A browser window will open with your computer's files listed on the left hand side of the page. Navigate to the folder called \texttt{PythonWebScrape} that you downloaded to your desktop and double-click on the folder
\item
  Within the \texttt{PythonWebScrape} folder, double-click on the file with the word ``BLANK'' in the name (\texttt{PythonWebScrape\_BLANK.ipynb}). A pop-up window will ask you to \texttt{Select\ Kernal} --- you should select the Python 3 kernal. The Jupyter Notebook should now open on the right hand side of the page
\end{enumerate}

A Jupyter Notebook contains one or more \emph{cells} containing notes or code. To insert a new cell click the \texttt{+} button in the upper left. To execute a cell, select it and press \texttt{Control+Enter} or click the \texttt{Run} button at the top.

\hypertarget{making-requests}{%
\subsection{Making requests}\label{making-requests}}

To retrieve information from the website (i.e., make a request), we need to know the location of the information we want to collect. The Uniform Resource Locator (URL) --- commonly know as a ``web address'', specifies the location of a resource (such as a web page) on the internet.

A URL is usually composed of 5 parts:

\includegraphics{Python/PythonWebScrape/images/URL.png}

The 4th part, the ``query string'', contains one or more \textbf{parameters}. The 5th part, the ``fragment'', is an internal page reference and may not be present.

For example, the URL we want to retrieve data from has the following structure:

\begin{verbatim}
protocol                    domain    path  parameters
   https www.harvardartmuseums.org  browse  load_amount=10&offset=0
\end{verbatim}

It is often convenient to create variables containing the domain(s) and path(s) you'll be working with, as this allows you to swap out paths and parameters as needed. Note that the path is separated from the domain with \texttt{/} and the parameters are separated from the path with \texttt{?}. If there are multiple parameters they are separated from each other with a \texttt{\&}.

For example, we can define the domain and path of the collections URL as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{museum\_domain }\OperatorTok{=} \StringTok{\textquotesingle{}https://www.harvardartmuseums.org\textquotesingle{}}
\NormalTok{collection\_path }\OperatorTok{=} \StringTok{\textquotesingle{}browse\textquotesingle{}}

\NormalTok{collection\_url }\OperatorTok{=}\NormalTok{ (museum\_domain}
                  \OperatorTok{+} \StringTok{"/"}
                  \OperatorTok{+}\NormalTok{ collection\_path)}

\BuiltInTok{print}\NormalTok{(collection\_url)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'https://www.harvardartmuseums.org/browse'
\end{verbatim}

Note that we omit the parameters here because it is usually easier to pass them as a \texttt{dict} when using the \texttt{requests} library in Python. This will become clearer shortly.

Now that we've constructed the URL we wish to interact with, we're ready to make our first request in Python.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ requests}

\NormalTok{collections1 }\OperatorTok{=}\NormalTok{ requests.get(}
\NormalTok{    collection\_url,}
\NormalTok{    params }\OperatorTok{=}\NormalTok{ \{}\StringTok{\textquotesingle{}load\_amount\textquotesingle{}}\NormalTok{: }\DecValTok{10}\NormalTok{,}
                  \StringTok{\textquotesingle{}offset\textquotesingle{}}\NormalTok{: }\DecValTok{0}\NormalTok{\}}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note that the parameters \texttt{load\_amount} and \texttt{offset} are essentially another way of setting page numbers --- they refer to the amount of information retrieved at one time and the starting position, respectively.

\hypertarget{parsing-json-data}{%
\subsection{Parsing JSON data}\label{parsing-json-data}}

We already know from inspecting network traffic in our web browser that this URL returns JSON, but we can use Python to verify this assumption.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{collections1.headers[}\StringTok{\textquotesingle{}Content{-}Type\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'application/json'
\end{verbatim}

Since JSON is a structured data format, parsing it into Python data structures is easy. In fact, there's a method for that!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{collections1 }\OperatorTok{=}\NormalTok{ collections1.json()}
\CommentTok{\# print(collections1)}
\end{Highlighting}
\end{Shaded}

That's it. Really, we are done here. Everyone go home!

OK not really, there is still more we can learn. But you have to admit that was pretty easy. If you can identify a service that returns the data you want in structured from, web scraping becomes a pretty trivial enterprise. We'll discuss several other scenarios and topics, but for some web scraping tasks this is really all you need to know.

\hypertarget{organizing-saving-the-data}{%
\subsection{Organizing \& saving the data}\label{organizing-saving-the-data}}

The records we retrieved from \url{https://www.harvardartmuseums.org/browse} are arranged as a list of dictionaries. We can easily select the fields of arrange these data into a pandas \texttt{DataFrame} to facilitate subsequent analysis.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{records1 }\OperatorTok{=}\NormalTok{ pd.DataFrame.from\_records(collections1[}\StringTok{\textquotesingle{}records\textquotesingle{}}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(records1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   copyright  contextualtextcount  ...                         colors                         people
## 0      None                    0  ...                            NaN                            NaN
## 1      None                    0  ...  [{'color': '#7d7d7d', 'spe...                            NaN
## 2      None                    0  ...  [{'color': '#c8c8af', 'spe...  [{'role': 'Artist', 'birth...
## 3      None                    0  ...  [{'color': '#646464', 'spe...                            NaN
## 4      None                    0  ...  [{'color': '#e1e1c8', 'spe...  [{'role': 'Artist', 'birth...
## 5      None                    0  ...  [{'color': '#e1e1c8', 'spe...                            NaN
## 6      None                    0  ...                            NaN  [{'role': 'Artist', 'birth...
## 7      None                    0  ...  [{'color': '#af967d', 'spe...  [{'role': 'Artist', 'birth...
## 8      None                    0  ...                            NaN                            NaN
## 9      None                    0  ...  [{'color': '#644b32', 'spe...                            NaN
## 
## [10 rows x 62 columns]
\end{verbatim}

and write the data to a file.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{records1.to\_csv(}\StringTok{"records1.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{iterating-to-retrieve-all-the-data}{%
\subsection{Iterating to retrieve all the data}\label{iterating-to-retrieve-all-the-data}}

Of course we don't want just the first page of collections. How can we retrieve all of them?

Now that we know the web service works, and how to make requests in Python, we can iterate in the usual way.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{records }\OperatorTok{=}\NormalTok{ []}
\ControlFlowTok{for}\NormalTok{ offset }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{10}\NormalTok{):}
\NormalTok{    param\_values }\OperatorTok{=}\NormalTok{ \{}\StringTok{\textquotesingle{}load\_amount\textquotesingle{}}\NormalTok{: }\DecValTok{10}\NormalTok{, }\StringTok{\textquotesingle{}offset\textquotesingle{}}\NormalTok{: offset\}}
\NormalTok{    current\_request }\OperatorTok{=}\NormalTok{ requests.get(collection\_url, params }\OperatorTok{=}\NormalTok{ param\_values)}
\NormalTok{    records.extend(current\_request.json()[}\StringTok{\textquotesingle{}records\textquotesingle{}}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\# convert list of dicts to a \textasciigrave{}DataFrame\textasciigrave{}}
\NormalTok{records\_final }\OperatorTok{=}\NormalTok{ pd.DataFrame.from\_records(records)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# write the data to a file.}
\NormalTok{records\_final.to\_csv(}\StringTok{"records\_final.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(records\_final)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                         copyright  contextualtextcount  ...                         people                        details
## 0                            None                    0  ...                            NaN                            NaN
## 1                            None                    0  ...                            NaN                            NaN
## 2                            None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 3                            None                    0  ...                            NaN                            NaN
## 4                            None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 5                            None                    0  ...                            NaN                            NaN
## 6                            None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 7                            None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 8                            None                    0  ...                            NaN                            NaN
## 9                            None                    0  ...                            NaN                            NaN
## 10  © Jasper Johns and ULAE/Li...                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 11  © Aperture Foundation Inc....                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 12                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 13  © Courtesy of Hiroshi Sugi...                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 14                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 15                           None                    0  ...                            NaN                            NaN
## 16                           None                    1  ...                            NaN  {'technical': [{'text': 'X...
## 17                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 18  © The Estate of Edward Ste...                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 19                           None                    0  ...                            NaN                            NaN
## 20                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 21  © Julian Faulhaber / Artis...                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 22                           None                    0  ...                            NaN                            NaN
## 23                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 24  © Artists Rights Society (...                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 25  © Artists Rights Society (...                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 26  © Estate of THeordore Rosz...                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 27             © 2004 Glenn Ligon                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 28                           None                    1  ...                            NaN  {'technical': [{'text': 'I...
## 29                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 30                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 31                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 32                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 33                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 34                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 35                           None                    1  ...                            NaN                            NaN
## 36                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 37                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 38                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 39  © Jenny Holzer / Artists R...                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 40                           None                    0  ...                            NaN                            NaN
## 41                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 42                           None                    0  ...                            NaN                            NaN
## 43  © Estate of Pablo Picasso ...                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 44                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 45                           None                    0  ...                            NaN                            NaN
## 46                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 47                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 48                           None                    0  ...  [{'role': 'Artist', 'birth...                            NaN
## 49                           None                    0  ...                            NaN                            NaN
## 
## [50 rows x 63 columns]
\end{verbatim}

\hypertarget{exercise-0-4}{%
\subsection{Exercise 0}\label{exercise-0-4}}

\textbf{Retrieve exhibits data}

In this exercise you will retrieve information about the art exhibitions at Harvard Art Museums from \url{https://www.harvardartmuseums.org/exhibitions}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Using a web browser (Firefox or Chrome recommended) inspect the
  page at \url{https://www.harvardartmuseums.org/exhibitions}. Examine
  the network traffic as you interact with the page. Try to find
  where the data displayed on that page comes from.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Make a \texttt{get} request in Python to retrieve the data from the URL
  identified in step1.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Write a \emph{loop} or \emph{list comprehension} in Python to retrieve data
  for the first 5 pages of exhibitions data.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Bonus (optional): Convert the data you retrieved into a pandas
  \texttt{DataFrame} and save it to a \texttt{.csv} file.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 0 Solution}

\begin{alert}

Question \#1:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{museum\_domain }\OperatorTok{=} \StringTok{"https://www.harvardartmuseums.org"}
\NormalTok{exhibit\_path }\OperatorTok{=} \StringTok{"search/load\_next"}
\NormalTok{exhibit\_url }\OperatorTok{=}\NormalTok{ museum\_domain }\OperatorTok{+} \StringTok{"/"} \OperatorTok{+}\NormalTok{ exhibit\_path}
\BuiltInTok{print}\NormalTok{(exhibit\_url)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'https://www.harvardartmuseums.org/search/load_next'
\end{verbatim}

Question \#2:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ requests}
\ImportTok{from}\NormalTok{ pprint }\ImportTok{import}\NormalTok{ pprint }\ImportTok{as} \BuiltInTok{print} 
\NormalTok{exhibit1 }\OperatorTok{=}\NormalTok{ requests.get(exhibit\_url, params }\OperatorTok{=}\NormalTok{ \{}\StringTok{\textquotesingle{}type\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}past{-}exhibition\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}page\textquotesingle{}}\NormalTok{: }\DecValTok{1}\NormalTok{\})}
\BuiltInTok{print}\NormalTok{(exhibit1.headers[}\StringTok{"Content{-}Type"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'application/json'
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{exhibit1 }\OperatorTok{=}\NormalTok{ exhibit1.json()}
\CommentTok{\# print(exhibit1)}
\end{Highlighting}
\end{Shaded}

Questions \#3+4 (loop solution):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{firstFivePages }\OperatorTok{=}\NormalTok{ []}
\ControlFlowTok{for}\NormalTok{ page }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{6}\NormalTok{):}
\NormalTok{    records\_per\_page }\OperatorTok{=}\NormalTok{ requests.get(exhibit\_url, params }\OperatorTok{=}\NormalTok{ \{}\StringTok{\textquotesingle{}type\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}past{-}exhibition\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}page\textquotesingle{}}\NormalTok{: page\}).json()[}\StringTok{\textquotesingle{}records\textquotesingle{}}\NormalTok{]}
\NormalTok{    firstFivePages.extend(records\_per\_page)}
\NormalTok{firstFivePages\_records }\OperatorTok{=}\NormalTok{ pd.DataFrame.from\_records(firstFivePages)}
\BuiltInTok{print}\NormalTok{(firstFivePages\_records)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                  shortdescription                         images  ...                   publications                         videos
## 0                            None  [{'date': None, 'copyright...  ...                            NaN                            NaN
## 1                            None  [{'date': '2018-11-09', 'c...  ...                            NaN                            NaN
## 2                            None  [{'date': '2018-06-04', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 3                            None  [{'date': '2001-03-01', 'c...  ...                            NaN                            NaN
## 4                            None  [{'date': '2005-04-18', 'c...  ...                            NaN                            NaN
## 5                            None  [{'date': '2018-06-29', 'c...  ...                            NaN  [{'description': 'Marina I...
## 6                            None  [{'date': '2018-03-15', 'c...  ...                            NaN                            NaN
## 7                            None  [{'date': '2016-10-17', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 8                            None  [{'date': '2017-02-16', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 9                            None  [{'date': '2018-01-23', 'c...  ...                            NaN                            NaN
## 10                           None  [{'date': '2001-04-01', 'c...  ...                            NaN                            NaN
## 11                           None  [{'date': '2016-06-10', 'c...  ...                            NaN  [{'description': 'Fernando...
## 12                           None  [{'date': '2008-10-27', 'c...  ...                            NaN                            NaN
## 13                           None  [{'date': '2017-10-05', 'c...  ...                            NaN                            NaN
## 14                           None  [{'date': '2002-05-01', 'c...  ...                            NaN                            NaN
## 15                           None  [{'date': '2007-08-01', 'c...  ...                            NaN                            NaN
## 16                           None  [{'date': '2003-03-21', 'c...  ...                            NaN                            NaN
## 17                           None  [{'date': '2017-05-08', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 18                           None  [{'date': '2002-08-01', 'c...  ...                            NaN  [{'description': 'Symposiu...
## 19                           None  [{'date': '2016-07-05', 'c...  ...                            NaN                            NaN
## 20                           None  [{'date': '2017-03-29', 'c...  ...                            NaN                            NaN
## 21                           None  [{'date': '2015-03-22', 'c...  ...  [{'publicationplace': 'Cam...  [{'description': 'The Phil...
## 22                           None  [{'date': '2017-03-07', 'c...  ...                            NaN                            NaN
## 23  Harvard professor Ewa Laje...  [{'date': '2001-03-01', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 24  This exhibition features w...  [{'date': '2016-07-12', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 25                           None  [{'date': '2017-02-08', 'c...  ...                            NaN                            NaN
## 26                           None  [{'date': '2001-06-01', 'c...  ...                            NaN                            NaN
## 27                           None  [{'date': '2005-11-03', 'c...  ...                            NaN                            NaN
## 28                           None  [{'date': '2015-04-06', 'c...  ...                            NaN  [{'description': 'Wolfgang...
## 29                    In progress  [{'date': '2016-07-28', 'c...  ...                            NaN                            NaN
## 30                           None  [{'date': None, 'copyright...  ...                            NaN                            NaN
## 31                           None  [{'date': '2016-03-21', 'c...  ...                            NaN                            NaN
## 32                           None  [{'date': '2007-04-18', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 33                           None  [{'date': '2015-04-01', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 34                           None  [{'date': '2016-01-12', 'c...  ...                            NaN                            NaN
## 35                           None  [{'date': '2002-07-01', 'c...  ...                            NaN                            NaN
## 36                           None  [{'date': '2007-02-27', 'c...  ...                            NaN                            NaN
## 37                           None  [{'date': '2006-01-18', 'c...  ...                            NaN                            NaN
## 38                           None  [{'date': '2015-10-29', 'c...  ...                            NaN                            NaN
## 39                           None  [{'date': '2014-08-12', 'c...  ...  [{'publicationplace': 'Cam...  [{'description': 'Teaser: ...
## 40                           None  [{'date': '2005-11-03', 'c...  ...                            NaN                            NaN
## 41                           None  [{'date': '1989-08-01', 'c...  ...                            NaN                            NaN
## 42  This multi-component insta...  [{'date': '2014-03-31', 'c...  ...                            NaN                            NaN
## 43                           None  [{'date': '2009-11-30', 'c...  ...                            NaN                            NaN
## 44  Harvard Art Museums’ new p...  [{'date': '2012-06-29', 'c...  ...                            NaN  [{'description': 'Mark Rot...
## 45                           None  [{'date': '2014-11-10', 'c...  ...                            NaN                            NaN
## 46  In the Japanese context, a...  [{'date': '2012-07-17', 'c...  ...                            NaN                            NaN
## 47  World’s Fairs were created...  [{'date': '2005-12-21', 'c...  ...                            NaN                            NaN
## 48                           None  [{'date': '2005-11-09', 'c...  ...                            NaN                            NaN
## 49  Teaching Galleries\r\n\r\n...  [{'date': '2003-03-18', 'c...  ...                            NaN                            NaN
## 
## [50 rows x 19 columns]
\end{verbatim}

Questions \#3+4 (list comprehension solution):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{first5Pages }\OperatorTok{=}\NormalTok{ [requests.get(exhibit\_url, params }\OperatorTok{=}\NormalTok{ \{}\StringTok{\textquotesingle{}type\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}past{-}exhibition\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}page\textquotesingle{}}\NormalTok{: page\}).json()[}\StringTok{\textquotesingle{}records\textquotesingle{}}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ page }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{6}\NormalTok{)]}
\ImportTok{from}\NormalTok{ itertools }\ImportTok{import}\NormalTok{ chain}
\NormalTok{first5Pages }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(chain.from\_iterable(first5Pages))}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\NormalTok{first5Pages\_records }\OperatorTok{=}\NormalTok{ pd.DataFrame.from\_records(first5Pages)}
\BuiltInTok{print}\NormalTok{(first5Pages\_records)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                  shortdescription                         images  ...                   publications                         videos
## 0                            None  [{'date': None, 'copyright...  ...                            NaN                            NaN
## 1                            None  [{'date': '2018-11-09', 'c...  ...                            NaN                            NaN
## 2                            None  [{'date': '2018-06-04', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 3                            None  [{'date': '2001-03-01', 'c...  ...                            NaN                            NaN
## 4                            None  [{'date': '2005-04-18', 'c...  ...                            NaN                            NaN
## 5                            None  [{'date': '2018-06-29', 'c...  ...                            NaN  [{'description': 'Marina I...
## 6                            None  [{'date': '2018-03-15', 'c...  ...                            NaN                            NaN
## 7                            None  [{'date': '2016-10-17', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 8                            None  [{'date': '2017-02-16', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 9                            None  [{'date': '2018-01-23', 'c...  ...                            NaN                            NaN
## 10                           None  [{'date': '2001-04-01', 'c...  ...                            NaN                            NaN
## 11                           None  [{'date': '2016-06-10', 'c...  ...                            NaN  [{'description': 'Fernando...
## 12                           None  [{'date': '2008-10-27', 'c...  ...                            NaN                            NaN
## 13                           None  [{'date': '2017-10-05', 'c...  ...                            NaN                            NaN
## 14                           None  [{'date': '2002-05-01', 'c...  ...                            NaN                            NaN
## 15                           None  [{'date': '2007-08-01', 'c...  ...                            NaN                            NaN
## 16                           None  [{'date': '2003-03-21', 'c...  ...                            NaN                            NaN
## 17                           None  [{'date': '2017-05-08', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 18                           None  [{'date': '2002-08-01', 'c...  ...                            NaN  [{'description': 'Symposiu...
## 19                           None  [{'date': '2016-07-05', 'c...  ...                            NaN                            NaN
## 20                           None  [{'date': '2017-03-29', 'c...  ...                            NaN                            NaN
## 21                           None  [{'date': '2015-03-22', 'c...  ...  [{'publicationplace': 'Cam...  [{'description': 'The Phil...
## 22                           None  [{'date': '2017-03-07', 'c...  ...                            NaN                            NaN
## 23  Harvard professor Ewa Laje...  [{'date': '2001-03-01', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 24  This exhibition features w...  [{'date': '2016-07-12', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 25                           None  [{'date': '2017-02-08', 'c...  ...                            NaN                            NaN
## 26                           None  [{'date': '2001-06-01', 'c...  ...                            NaN                            NaN
## 27                           None  [{'date': '2005-11-03', 'c...  ...                            NaN                            NaN
## 28                           None  [{'date': '2015-04-06', 'c...  ...                            NaN  [{'description': 'Wolfgang...
## 29                    In progress  [{'date': '2016-07-28', 'c...  ...                            NaN                            NaN
## 30                           None  [{'date': None, 'copyright...  ...                            NaN                            NaN
## 31                           None  [{'date': '2016-03-21', 'c...  ...                            NaN                            NaN
## 32                           None  [{'date': '2007-04-18', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 33                           None  [{'date': '2015-04-01', 'c...  ...  [{'publicationplace': 'Cam...                            NaN
## 34                           None  [{'date': '2016-01-12', 'c...  ...                            NaN                            NaN
## 35                           None  [{'date': '2002-07-01', 'c...  ...                            NaN                            NaN
## 36                           None  [{'date': '2007-02-27', 'c...  ...                            NaN                            NaN
## 37                           None  [{'date': '2006-01-18', 'c...  ...                            NaN                            NaN
## 38                           None  [{'date': '2015-10-29', 'c...  ...                            NaN                            NaN
## 39                           None  [{'date': '2014-08-12', 'c...  ...  [{'publicationplace': 'Cam...  [{'description': 'Teaser: ...
## 40                           None  [{'date': '2005-11-03', 'c...  ...                            NaN                            NaN
## 41                           None  [{'date': '1989-08-01', 'c...  ...                            NaN                            NaN
## 42  This multi-component insta...  [{'date': '2014-03-31', 'c...  ...                            NaN                            NaN
## 43                           None  [{'date': '2009-11-30', 'c...  ...                            NaN                            NaN
## 44  Harvard Art Museums’ new p...  [{'date': '2012-06-29', 'c...  ...                            NaN  [{'description': 'Mark Rot...
## 45                           None  [{'date': '2014-11-10', 'c...  ...                            NaN                            NaN
## 46  In the Japanese context, a...  [{'date': '2012-07-17', 'c...  ...                            NaN                            NaN
## 47  World’s Fairs were created...  [{'date': '2005-12-21', 'c...  ...                            NaN                            NaN
## 48                           None  [{'date': '2005-11-09', 'c...  ...                            NaN                            NaN
## 49  Teaching Galleries\r\n\r\n...  [{'date': '2003-03-18', 'c...  ...                            NaN                            NaN
## 
## [50 rows x 19 columns]
\end{verbatim}

\end{alert}

\hypertarget{parsing-html-if-you-have-to}{%
\section{Parsing HTML if you have to}\label{parsing-html-if-you-have-to}}

\begin{alert}

\textbf{GOAL: To retrieve information in HTML format and organize it into a spreadsheet.}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Make a request to the website server to retrieve the HTML
\item
  Inspect the HTML to determine the XPATHs that point to the data we want
\item
  Extract the information from the location the XPATHs point to and store in a dictionary
\item
  Convert from a dictionary to a .csv file
\end{enumerate}

\end{alert}

As we've seen, you can often inspect network traffic or other sources to locate the source of the data you are interested in and the API used to retrieve it. You should always start by looking for these shortcuts and using them where possible. If you are really lucky, you'll find a shortcut that returns the data as JSON or XML. If you are not quite so lucky, you will have to parse HTML to retrieve the information you need.

\hypertarget{document-object-model-dom}{%
\subsection{Document Object Model (DOM)}\label{document-object-model-dom}}

To parse HTML, we need to have a nice tree structure that contains the whole HTML file through which we can locate the information. This tree-like structure is the \textbf{Document Object Model (DOM)}. DOM is a cross-platform and language-independent interface that treats an XML or HTML document as a tree structure wherein each node is an object representing a part of the document. The DOM represents a document with a logical tree. \emph{Each branch of the tree ends in a node, and each node contains objects}. DOM methods allow programmatic access to the tree; with them one can change the structure, style or content of a document. The following is an example of DOM hierarchy in an HTML document:

\includegraphics{Python/PythonWebScrape/images/DOM.png}

\hypertarget{retrieving-html}{%
\subsection{Retrieving HTML}\label{retrieving-html}}

When I inspect the network traffic while interacting with \url{https://www.harvardartmuseums.org/calendar} I don't see any requests that return JSON data. The best we can do appears to be to return HTML.

To retrieve data on the events listed in the calender, the first step is the same as before: we make a \texttt{get} request.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calendar\_path }\OperatorTok{=} \StringTok{\textquotesingle{}calendar\textquotesingle{}}

\NormalTok{calendar\_url }\OperatorTok{=}\NormalTok{ (museum\_domain }\CommentTok{\# recall that we defined museum\_domain earlier}
                  \OperatorTok{+} \StringTok{"/"}
                  \OperatorTok{+}\NormalTok{ calendar\_path)}

\BuiltInTok{print}\NormalTok{(calendar\_url)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'https://www.harvardartmuseums.org/calendar'
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{events }\OperatorTok{=}\NormalTok{ requests.get(calendar\_url)}
\end{Highlighting}
\end{Shaded}

As before, we can check the headers to see what type of content we received in response to our request.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{events.headers[}\StringTok{\textquotesingle{}Content{-}Type\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'text/html; charset=UTF-8'
\end{verbatim}

\hypertarget{parsing-html-using-the-lxml-library}{%
\subsection{Parsing HTML using the lxml library}\label{parsing-html-using-the-lxml-library}}

Like JSON, HTML is structured; unlike JSON, it is designed to be rendered into a human-readable page rather than simply to store and exchange data in a computer-readable format. Consequently, parsing HTML and extracting information from it is somewhat more difficult than parsing JSON.

While JSON parsing is built into the Python \texttt{requests} library, parsing HTML requires a separate library. I recommend using the HTML parser from the \texttt{lxml} library; others prefer an alternative called \texttt{beautifulsoup4}.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ lxml }\ImportTok{import}\NormalTok{ html}

\CommentTok{\# convert a html text representation (\textasciigrave{}events.text\textasciigrave{}) into }
\CommentTok{\# a tree{-}structure (DOM) html representation (\textasciigrave{}events\_html\textasciigrave{})}
\NormalTok{events\_html }\OperatorTok{=}\NormalTok{ html.fromstring(events.text)}
\end{Highlighting}
\end{Shaded}

\hypertarget{using-xpath-to-extract-content-from-html}{%
\subsection{Using XPath to extract content from HTML}\label{using-xpath-to-extract-content-from-html}}

\texttt{XPath} is a tool for identifying particular elements within a HTML document. The developer tools built into modern web browsers make it easy to generate \texttt{XPath}s that can be used to identify the elements of a web page that we wish to extract.

We can open the html document we retrieved and inspect it using our web browser.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{html.open\_in\_browser(events\_html, encoding }\OperatorTok{=} \StringTok{\textquotesingle{}UTF{-}8\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Python/PythonWebScrape/images/dev_tools_right_click.png}

\includegraphics{Python/PythonWebScrape/images/dev_tools_inspect.png}

Once we identify the element containing the information of interest we can use our web browser to copy the \texttt{XPath} that uniquely identifies that element.

\includegraphics{Python/PythonWebScrape/images/dev_tools_xpath.png}

Next we can use Python to extract the element of interest:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{events\_list\_html }\OperatorTok{=}\NormalTok{ events\_html.xpath(}\StringTok{\textquotesingle{}//*[@id="events\_list"]/article\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Let's just extract the second element in our events list.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{second\_event\_html }\OperatorTok{=}\NormalTok{ events\_list\_html[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Once again, we can use a web browser to inspect the HTML we're currently working with - from the second event - and to figure out what we want to extract from it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{html.open\_in\_browser(second\_event\_html, encoding }\OperatorTok{=} \StringTok{\textquotesingle{}UTF{-}8\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

As before we can use our browser to find the xpath of the elements we want.

\includegraphics{Python/PythonWebScrape/images/dev_tools_figcaption.png}

(Note that the \texttt{html.open\_in\_browser} function adds enclosing \texttt{html} and \texttt{body} tags in order to create a complete web page for viewing. This requires that we adjust the \texttt{xpath} accordingly.)

By repeating this process for each element we want, we can build a list of the xpaths to those elements.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{elements\_we\_want }\OperatorTok{=}\NormalTok{ \{}\StringTok{\textquotesingle{}figcaption\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}div/figure/div/figcaption\textquotesingle{}}\NormalTok{,}
                    \StringTok{\textquotesingle{}date\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}div/div/header/time\textquotesingle{}}\NormalTok{,}
                    \StringTok{\textquotesingle{}title\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}div/div/header/h2/a\textquotesingle{}}\NormalTok{,}
                    \StringTok{\textquotesingle{}time\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}div/div/div/p[1]/time\textquotesingle{}}\NormalTok{,}
                    \StringTok{\textquotesingle{}description\textquotesingle{}}\NormalTok{: }\StringTok{\textquotesingle{}div/div/div/p[3]\textquotesingle{}}
\NormalTok{                    \}}
\end{Highlighting}
\end{Shaded}

Finally, we can iterate over the elements we want and extract them.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{second\_event\_values }\OperatorTok{=}\NormalTok{ \{\}}
\ControlFlowTok{for}\NormalTok{ key }\KeywordTok{in}\NormalTok{ elements\_we\_want.keys():}
\NormalTok{    element }\OperatorTok{=}\NormalTok{ second\_event\_html.xpath(elements\_we\_want[key])[}\DecValTok{0}\NormalTok{]}
\NormalTok{    second\_event\_values[key] }\OperatorTok{=}\NormalTok{ element.text\_content().strip()}

\BuiltInTok{print}\NormalTok{(second\_event\_values)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## {'date': 'Thursday, August 27, 2020',
##  'description': 'We’ll take a close look at a late 18th-century book '
##                 'illustration by French artists Pierre-Paul Prud’hon and '
##                 'Barthélemy Roger.',
##  'figcaption': 'Pierre-Paul Prud’hon (design and etching) and Barthélemy '
##                'Joseph Fulcran Roger (engraving), French, Phrosine and '
##                'Mélidore, 1797. Etching and engraving. Harvard Art '
##                'Museums/Fogg Museum, Gray Collection of Engravings Fund and '
##                'the Jakob Rosenberg Fund, G9063.',
##  'time': '2:00pm - 2:30pm',
##  'title': 'Art Talk Live: One Print—Five Stories'}
\end{verbatim}

\hypertarget{iterating-to-retrieve-content-from-a-list-of-html-elements}{%
\subsection{Iterating to retrieve content from a list of HTML elements}\label{iterating-to-retrieve-content-from-a-list-of-html-elements}}

So far we've retrieved information only for the second event. To
retrieve data for all the events listed on the page we need to iterate
over the events. If we are very lucky, each event will have exactly
the same information structured in exactly the same way and we can
simply extend the code we wrote above to iterate over the events list.

Unfortunately, not all these elements are available for every event, so
we need to take care to handle the case where one or more of these
elements is not available. We can do that by \textbf{defining a function} that
tries to retrieve a value and returns an empty string if it fails.

If you're not familiar with Python functions, here's the basic syntax:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# anatomy of a function}

\KeywordTok{def}\NormalTok{ name\_of\_function(arg1, arg2, ...argn):  }\CommentTok{\# define the function name and arguments}
    \OperatorTok{\textless{}}\NormalTok{body of function}\OperatorTok{\textgreater{}}   \CommentTok{\# specify calculations}
    \ControlFlowTok{return} \OperatorTok{\textless{}}\NormalTok{result}\OperatorTok{\textgreater{}}      \CommentTok{\# output result of calculations}
\end{Highlighting}
\end{Shaded}

Here's an example of a simple function:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ square\_fun(x):}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ x}\OperatorTok{**}\DecValTok{2} \CommentTok{\# exponentiation}
    \ControlFlowTok{return}\NormalTok{ y}

\NormalTok{square\_fun(}\DecValTok{4}\NormalTok{)    }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 16
\end{verbatim}

Here's a function to perform our actual task:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ get\_event\_info(event, path):}
    \ControlFlowTok{try}\NormalTok{:}
\NormalTok{        info }\OperatorTok{=}\NormalTok{ event.xpath(path)[}\DecValTok{0}\NormalTok{].text\_content().strip()}
    \ControlFlowTok{except}\NormalTok{:}
\NormalTok{        info }\OperatorTok{=} \StringTok{\textquotesingle{}\textquotesingle{}}
    \ControlFlowTok{return}\NormalTok{ info}
\end{Highlighting}
\end{Shaded}

Armed with this function we can iterate over the list of events and extract the available information for each one.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all\_event\_values }\OperatorTok{=}\NormalTok{ \{\}}
\ControlFlowTok{for}\NormalTok{ key }\KeywordTok{in}\NormalTok{ elements\_we\_want.keys():}
\NormalTok{    key\_values }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{for}\NormalTok{ event }\KeywordTok{in}\NormalTok{ events\_list\_html: }
\NormalTok{        key\_values.append(get\_event\_info(event, elements\_we\_want[key]))}
\NormalTok{    all\_event\_values[key] }\OperatorTok{=}\NormalTok{ key\_values}
\end{Highlighting}
\end{Shaded}

For convenience we can arrange these values in a pandas \texttt{DataFrame} and save them as .csv files, just as we did with our exhibitions data earlier.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all\_event\_values }\OperatorTok{=}\NormalTok{ pd.DataFrame.from\_dict(all\_event\_values)}

\NormalTok{all\_event\_values.to\_csv(}\StringTok{"all\_event\_values.csv"}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(all\_event\_values)}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercise-1-5}{%
\subsection{Exercise 1}\label{exercise-1-5}}

\textbf{parsing HTML}

In this exercise you will retrieve information about the physical layout of the Harvard Art Museums. The web page at
\url{https://www.harvardartmuseums.org/visit/floor-plan} contains this information in HTML from.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Using a web browser (Firefox or Chrome recommended) inspect the
  page at \url{https://www.harvardartmuseums.org/visit/floor-plan}. Copy
  the \texttt{XPath} to the element containing the list of level
  information. (HINT: the element if interest is a \texttt{ul}, i.e.,
  \texttt{unordered\ list}.)
\item
  Make a \texttt{get} request in Python to retrieve the web page at
  \url{https://www.harvardartmuseums.org/visit/floor-plan}. Extract the
  content from your request object and parse it using \texttt{html.fromstring}
  from the \texttt{lxml} library.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Use your web browser to find the \texttt{XPath}s to the facilities housed on
  level one. Use Python to extract the text from those \texttt{Xpath}s.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Bonus (optional): Write a \emph{for loop} or \emph{list comprehension} in Python
  to retrieve data for all the levels.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 1 Solution}

\begin{alert}

Question \#2:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ lxml }\ImportTok{import}\NormalTok{ html}
\NormalTok{floor\_plan }\OperatorTok{=}\NormalTok{ requests.get(}\StringTok{\textquotesingle{}https://www.harvardartmuseums.org/visit/floor{-}plan\textquotesingle{}}\NormalTok{)}
\NormalTok{floor\_plan\_html }\OperatorTok{=}\NormalTok{ html.fromstring(floor\_plan.text)}
\end{Highlighting}
\end{Shaded}

Question \#3:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{level\_one }\OperatorTok{=}\NormalTok{ floor\_plan\_html.xpath(}\StringTok{\textquotesingle{}/html/body/main/section/ul/li[5]/div[2]/ul\textquotesingle{}}\NormalTok{)[}\DecValTok{0}\NormalTok{]}
\BuiltInTok{print}\NormalTok{(}\BuiltInTok{type}\NormalTok{(level\_one))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## <class 'lxml.html.HtmlElement'>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\BuiltInTok{len}\NormalTok{(level\_one))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{level\_one\_facilities }\OperatorTok{=}\NormalTok{ floor\_plan\_html.xpath(}\StringTok{\textquotesingle{}/html/body/main/section/ul/li[5]/div[2]/ul/li\textquotesingle{}}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\BuiltInTok{len}\NormalTok{(level\_one\_facilities))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{([facility.text\_content() }\ControlFlowTok{for}\NormalTok{ facility }\KeywordTok{in}\NormalTok{ level\_one\_facilities])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## ['Admissions', 'Collection Galleries', 'Courtyard', 'Shop', 'Café', 'Coatroom']
\end{verbatim}

Question \#4:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all\_levels }\OperatorTok{=}\NormalTok{ floor\_plan\_html.xpath(}\StringTok{\textquotesingle{}/html/body/main/section/ul/li\textquotesingle{}}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\BuiltInTok{len}\NormalTok{(all\_levels))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{all\_levels\_facilities }\OperatorTok{=}\NormalTok{ []}
\ControlFlowTok{for}\NormalTok{ level }\KeywordTok{in}\NormalTok{ all\_levels:}
\NormalTok{    level\_facilities }\OperatorTok{=}\NormalTok{ []}
\NormalTok{    level\_facilities\_collection }\OperatorTok{=}\NormalTok{ level.xpath(}\StringTok{\textquotesingle{}div[2]/ul/li\textquotesingle{}}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ level\_facility }\KeywordTok{in}\NormalTok{ level\_facilities\_collection:}
\NormalTok{        level\_facilities.append(level\_facility.text\_content())}
\NormalTok{    all\_levels\_facilities.append(level\_facilities)}
\BuiltInTok{print}\NormalTok{(all\_levels\_facilities)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [['Conservation Center / Lightbox Gallery'],
##  ['Art Study Center'],
##  ['Collection Galleries',
##   'Special Exhibitions Gallery',
##   'University Galleries'],
##  ['Collections Galleries'],
##  ['Admissions',
##   'Collection Galleries',
##   'Courtyard',
##   'Shop',
##   'Café',
##   'Coatroom'],
##  ['Lower Lobby',
##   'Lecture Halls',
##   'Seminar Room',
##   'Materials Lab',
##   'Coatroom',
##   'Offices']]
\end{verbatim}

\end{alert}

\hypertarget{scrapy-for-large-complex-projects}{%
\section{\texorpdfstring{\texttt{Scrapy}: for large / complex projects}{Scrapy: for large / complex projects}}\label{scrapy-for-large-complex-projects}}

Scraping websites using the \texttt{requests} library to make GET and POST requests, and the \texttt{lxml} library to process HTML is a good way to learn basic web scraping techniques. It is a good choice for small to medium size projects. For very large or complicated scraping tasks the \texttt{scrapy} library offers a number of conveniences, including asynchronous retrieval, session management, convenient methods for extracting and storing values, and more. More information about \texttt{scrapy} can be found at \url{https://doc.scrapy.org}.

\hypertarget{browser-drivers-a-last-resort}{%
\section{Browser drivers: a last resort}\label{browser-drivers-a-last-resort}}

It is sometimes necessary (or sometimes just easier) to use a web browser as an intermediary rather than communicate directly with a web service. This method of using a ``browser driver'' has the advantage of being able to use the javascript engine and session management features of a web browser; the main disadvantage is that it is slower and tends to be more fragile than using \texttt{requests} or \texttt{scrapy} to make requests directly from Python. For small scraping projects involving complicated sites with CAPTHAs or lots of complicated javascript using a browser driver can be a good option. More information is available at \url{https://www.seleniumhq.org/docs/03_webdriver.jsp}.

\hypertarget{wrap-up-6}{%
\section{Wrap-up}\label{wrap-up-6}}

\hypertarget{feedback-6}{%
\subsection{Feedback}\label{feedback-6}}

These workshops are a work in progress, please provide any feedback to: \href{mailto:help@iq.harvard.edu}{\nolinkurl{help@iq.harvard.edu}}

\hypertarget{resources-8}{%
\subsection{Resources}\label{resources-8}}

\begin{itemize}
\tightlist
\item
  IQSS

  \begin{itemize}
  \tightlist
  \item
    Workshops: \url{https://dss.iq.harvard.edu/workshop-materials}
  \item
    Data Science Services: \url{https://dss.iq.harvard.edu/}
  \item
    Research Computing Environment: \url{https://iqss.github.io/dss-rce/}
  \end{itemize}
\item
  HBS

  \begin{itemize}
  \tightlist
  \item
    Research Computing Services workshops: \url{https://training.rcs.hbs.org/workshops}
  \item
    Other HBS RCS resources: \url{https://training.rcs.hbs.org/workshop-materials}
  \item
    RCS consulting email: \url{mailto:research@hbs.edu}
  \end{itemize}
\end{itemize}

\hypertarget{part-stata}{%
\part{Stata}\label{part-stata}}

\hypertarget{stata-installation}{%
\chapter{Stata Installation}\label{stata-installation}}

\begin{alert}

\textbf{Your professional conduct is greatly appreciated. Out of respect to your fellow workshop attendees and instructors, please arrive at your workshop on time, having pre-installed all necessary software and materials. This will likely take 10-15 minutes.}

\end{alert}

\hypertarget{troubleshooting}{%
\section{Troubleshooting}\label{troubleshooting}}

Unfortunately, we are not able to help with any Stata download or installation problems you may encounter. \textbf{If you are unable to download or install Stata SE or MP, please contact your vendor (e.g., HUIT or Stata Corp.) prior to the start of the workshop.}
Once the workshop starts we will \textbf{NOT} be able to give you one-to-one assistance with setting up Stata. Likewise, if you arrive late, please do \textbf{NOT} expect one-to-one assistance for anything covered at the beginning of the workshop.

\hypertarget{software-2}{%
\section{Software}\label{software-2}}

\textbf{If you are from Harvard FAS:}

You have access to the licensed Stata MP program. Go to the software download page: \url{https://downloads.fas.harvard.edu/download}, log in your Harvard key, and download Stata MP from there.

\textbf{If you are from MIT or other Harvard schools:}

\begin{itemize}
\tightlist
\item
  You want to first check with your school or department whether they provide you free access to Stata SE or Stata MP.
\item
  If not, you can download the program from Stata Corporation with an annual license fee of close to \$300. Their website is \url{https://www.stata.com/}
\item
  Stata version MP is faster than SE when working with large datasets. However, in this workshop, it doesn't matter which version you use, since we will not be performing computational intensive jobs.
\end{itemize}

\begin{alert}

After you successfully installed Stata, you should be able to open the program with the following start page:

\end{alert}

\includegraphics{Stata/StataInstall/images/Stata_start_panel.png}

\hypertarget{materials-2}{%
\section{Materials}\label{materials-2}}

Download class materials for your workshop:

\begin{itemize}
\tightlist
\item
  Stata Introduction: \url{https://github.com/IQSS/dss-workshops-stata/raw/master/Stata/StataIntro.zip}
\item
  Stata Data Management: \url{https://github.com/IQSS/dss-workshops-stata/raw/master/Stata/StataDatMan.zip}
\item
  Stata Modeling: \url{https://github.com/IQSS/dss-workshops-stata/raw/master/Stata/StataMod.zip}
\item
  Stata Graphics: \url{https://github.com/IQSS/dss-workshops-stata/raw/master/Stata/StataGraph.zip}
\end{itemize}

Extract materials from the zipped directory (Right-click -\textgreater{} Extract All on Windows, double-click on Mac) and move them to your desktop.

It will be useful when you view the above materials for you to see the different file extensions on your computer. Here are instructions for enabling this:

\begin{itemize}
\tightlist
\item
  \href{https://support.apple.com/guide/mac-help/show-or-hide-filename-extensions-on-mac-mchlp2304/mac}{Mac OS}
\item
  \href{http://kb.winzip.com/kb/entry/26/}{Windows OS}
\end{itemize}

\hypertarget{resources-9}{%
\section{Resources}\label{resources-9}}

\begin{itemize}
\tightlist
\item
  IQSS

  \begin{itemize}
  \tightlist
  \item
    Workshops: \url{https://dss.iq.harvard.edu/workshop-materials}
  \item
    Data Science Services: \url{https://dss.iq.harvard.edu/}
  \item
    Research Computing Environment: \url{https://iqss.github.io/dss-rce/}
  \end{itemize}
\item
  HBS

  \begin{itemize}
  \tightlist
  \item
    Research Computing Services workshops: \url{https://training.rcs.hbs.org/workshops}
  \item
    Other HBS RCS resources: \url{https://training.rcs.hbs.org/workshop-materials}
  \item
    RCS consulting email: \url{mailto:research@hbs.edu}
  \end{itemize}
\end{itemize}

\hypertarget{stata-introduction}{%
\chapter{Stata Introduction}\label{stata-introduction}}

\textbf{Topics}

\begin{itemize}
\tightlist
\item
  Stata interface and Do-files
\item
  Reading and writing data
\item
  Basic summary statistics
\item
  Basic graphs
\item
  Basic data management
\item
  Bivariate analyses
\end{itemize}

\hypertarget{setup-6}{%
\section{Setup}\label{setup-6}}

\hypertarget{class-structure-and-organization}{%
\subsection{Class Structure and organization}\label{class-structure-and-organization}}

\begin{itemize}
\tightlist
\item
  Informal --- Ask questions at any time. Really!
\item
  Collaboration is encouraged - please spend a minute introducing yourself to your neighbors!
\item
  If you are using a laptop, you will need to adjust file paths accordingly
\item
  Make comments in your Do-file - save on flash drive or email to yourself
\end{itemize}

\hypertarget{prerequisites-6}{%
\subsection{Prerequisites}\label{prerequisites-6}}

This is an introductory Stata course:

\begin{itemize}
\tightlist
\item
  Assumes no prior knowledge of \textbf{how to use} Stata
\item
  We do assume you know \textbf{why} you want to learn Stata. If you don't, and want a comparison of Stata to other statistical software, see our \href{./DataScienceTools.html}{Data Science Tools} workshop
\item
  Relatively slow-paced
\end{itemize}

\hypertarget{goals-5}{%
\subsection{Goals}\label{goals-5}}

\begin{alert}

We will learn about the Stata language by analyzing data from the general social survey (gss).
In particular, our goals are to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Familiarize yourself with the Stata interface
\item
  Get data in and out of Stata
\item
  Compute statistics and construct graphical displays
\item
  Compute new variables and transformations
\item
  Perform univariate and bivariate data analyses
\end{enumerate}

\end{alert}

\hypertarget{stata-basics}{%
\section{Stata basics}\label{stata-basics}}

\begin{alert}

\textbf{GOAL: To learn the basics about Stata, how to interact with Stata, and how to read in and save data.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What is Stata, why use Stata, and advantages of using Stata
\item
  Three ways of interacing with Stata
\item
  Set the working directory
\item
  Read, save, and write data
\end{enumerate}

\end{alert}

\hypertarget{what-is-stata}{%
\subsection{What is Stata?}\label{what-is-stata}}

\begin{itemize}
\tightlist
\item
  Stata is a statistical software package that you can use to perform data analysis and management, as well as create graphics
\item
  Stata is commonly used among health, sociology, and economics researchers, particularly those working with large data sets
\end{itemize}

\hypertarget{why-use-stata}{%
\subsection{Why use Stata?}\label{why-use-stata}}

\begin{itemize}
\tightlist
\item
  It is easy to learn and is supported by a wide range of introductory textbooks
\item
  It offers a wide range of statistical models in a consistent interface
\item
  It presents results in a clear format
\item
  It has very good built-in help documentation and a broad user community where you can seek help
\item
  Student and other discount packages are available at reasonable cost
\end{itemize}

\hypertarget{how-does-stata-work}{%
\subsection{How does Stata work?}\label{how-does-stata-work}}

When Stata is running, variables, data, etc., are \textbf{stored in memory}.
The user can use \texttt{clear} command to clear up memory before running further commands,
unless they want to \texttt{save} their changes in the original dataset or a new dataset.

\hypertarget{interfaces-2}{%
\subsection{Interfaces}\label{interfaces-2}}

\includegraphics{Stata/StataIntro/images/StataInterface.png}

\begin{itemize}
\tightlist
\item
  Review and Variable windows can be closed (user preference)
\item
  Command window can be shortened (recommended)
\end{itemize}

\hypertarget{gui-and-command-window}{%
\subsubsection{GUI and command window}\label{gui-and-command-window}}

There are two ways of interacting with Stata that will not result in a saveable record of what you have done:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{GUI}. The Graphical User Interface (GUI) allows you to perform analyses using drop-down menus, rather than writing code. This can be easier for first time users and Stata will helpfully display the command and proper syntax for the operation that you have selected. However, we strongly recommend not using the GUI, since it does not produce a script --- a record of what you have done --- and thus leads to analyses that are unreproducible.
\item
  \textbf{Command window}. From the command window you can type commands to manage and analyze your data.

  \begin{itemize}
  \tightlist
  \item
    The advantage is that you can quickly produce output of a single command.
  \item
    The disadvantage is that you cannot store your syntax in a script to reproduce in the future.
  \end{itemize}
\end{enumerate}

\hypertarget{do-file}{%
\subsubsection{Do-file}\label{do-file}}

The third way of interacting with Stata does provide you with a saveable record of your work:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Do-file}. A do-file is a plain text file within which you can write and save commands for later use. There are several advantages to using a do-file and we strongly recommend that you always interact with Stata in this way:

  \begin{itemize}
  \tightlist
  \item
    Allows you to submit more than one command to Stata at once.
  \item
    Has specialized features for programmers such as syntax highlighting, code folding, autocompletion, and bookmarks to important lines in your code, brace matching, and more.
  \item
    With a do-file, it is easy to \textbf{save, review, change, and share} your code with others --- including your future self!
  \end{itemize}
\end{enumerate}

Here are some resources for learning more about Stata and do-files:

\begin{itemize}
\tightlist
\item
  \url{https://www.stata.com/}
\item
  \url{https://www.stata.com/manuals13/gsw13.pdf}
\item
  \url{https://sociology.fas.harvard.edu/files/sociology/files/creating_a_do_file.pdf}
\end{itemize}

\hypertarget{stata-help}{%
\subsection{Stata help}\label{stata-help}}

To get help in Stata type \texttt{help} followed by topic or command, e.g., \texttt{help\ codebook}.

\hypertarget{syntax-rules-2}{%
\subsection{Syntax rules}\label{syntax-rules-2}}

\begin{itemize}
\item
  Most Stata commands follow the same basic syntax: \texttt{Command\ varlist,\ options}.
\item
  Use comments liberally --- start with a comment describing your do-file and use comments throughout

  \begin{itemize}
  \tightlist
  \item
    Use \texttt{*} to comment a line and \texttt{//} for in-line comments
  \item
    Use \texttt{///} to break varlists over multiple lines
  \end{itemize}
\end{itemize}

\hypertarget{exercise-0-5}{%
\subsection{Exercise 0}\label{exercise-0-5}}

Launch the Stata program (MP or SE, does not matter unless doing computationally intensive work)
* Open up a new do-file
* Run our first Stata code!

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Try to get Stata to say ``Hello World!''. Search \texttt{help\ display}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Try to get Stata to break ``Hello World!'' over two lines:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 0 Solution}

\begin{alert}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{disp }\StringTok{"Hello "} \StringTok{"World!"} \CommentTok{// \textquotesingle{}disp\textquotesingle{} is short for \textquotesingle{}display\textquotesingle{}}

\NormalTok{disp }\StringTok{"Hello"} \CommentTok{///}
     \StringTok{" World!"}
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{working-directory}{%
\subsection{Working directory}\label{working-directory}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  print current working directory
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pwd }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  change working directory
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cd C:\textbackslash{}Users\textbackslash{}yiw640\textbackslash{}Desktop\textbackslash{}StataIntro\textbackslash{}}
\end{Highlighting}
\end{Shaded}

\hypertarget{a-note-about-file-path-names}{%
\subsubsection{A note about file path names}\label{a-note-about-file-path-names}}

\begin{itemize}
\tightlist
\item
  If your file path has no spaces in the name (that means all directories, folders, file names, etc. can have no spaces), you can write the file path as it is
\item
  If there are spaces, you need to put your file path name in quotes
\item
  Best to get in the habit of quoting file paths
\end{itemize}

\hypertarget{reading-data-2}{%
\subsection{Reading data}\label{reading-data-2}}

\hypertarget{data-file-commands}{%
\subsubsection{Data file commands}\label{data-file-commands}}

\begin{itemize}
\tightlist
\item
  Next, we want to open our data file
\item
  Open / save data sets with \texttt{use} and \texttt{save}:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// open the gss.dta data set }
\KeywordTok{use}\NormalTok{ gss.dta, }\KeywordTok{clear}

\CommentTok{// save data file}
\KeywordTok{save}\NormalTok{ newgss.dta, }\KeywordTok{replace} \CommentTok{// \textasciigrave{}replace\textasciigrave{} option means OK to overwrite existing file}
\end{Highlighting}
\end{Shaded}

\hypertarget{wheres-my-data}{%
\subsubsection{Where's my data?}\label{wheres-my-data}}

\begin{itemize}
\tightlist
\item
  Data editor (\textbf{browse})
\item
  Data editor (\textbf{edit})

  \begin{itemize}
  \tightlist
  \item
    Using the data editor is discouraged (why?)
  \end{itemize}
\item
  Always keep any changes to your data in your do-file
\item
  Avoid temptation of making manual changes by viewing data via the browser rather than editor
\end{itemize}

\hypertarget{reading-non-stata-data}{%
\subsubsection{Reading non-Stata data}\label{reading-non-stata-data}}

\begin{itemize}
\tightlist
\item
  Import / export delimited text files
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// import data from a .csv file}
\NormalTok{import delimited gss.csv, }\KeywordTok{clear}

\CommentTok{// save data to a .csv file}
\KeywordTok{export}\NormalTok{ delimited gss\_new.csv, }\KeywordTok{replace}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  Import / export Excel files
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// import/export Excel files}
\KeywordTok{clear}
\NormalTok{import excel gss.xlsx}
\KeywordTok{export}\NormalTok{ excel gss\_new, }\KeywordTok{replace}
\end{Highlighting}
\end{Shaded}

What if my data is from another statistical software program?

\begin{itemize}
\tightlist
\item
  SPSS/PASW will allow you to save your data as a Stata file

  \begin{itemize}
  \tightlist
  \item
    Go to: file -\textgreater{} save as -\textgreater{} Stata (use most recent version available)
  \item
    Then you can just go into Stata and open it
  \end{itemize}
\item
  Another option is \texttt{StatTransfer}, a program that converts data from/to many common formats, including SAS, SPSS, Stata, and many more.
\end{itemize}

\hypertarget{statistics-graphs}{%
\section{Statistics \& graphs}\label{statistics-graphs}}

\begin{alert}

\textbf{GOAL: To learn the basic commands to review, inspect, and plot data in Stata.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Learn more about the variables in our dataset --- using the \texttt{describe}, \texttt{codebook}, and \texttt{browse} commands
\item
  Produce univariate distributions using \texttt{histogram}, and bivariate distribution using \texttt{scatterplot}
\item
  Tabulate or summarize your data within certain groups using \texttt{bysort}
\end{enumerate}

\end{alert}

The most frequently used commands for reviewing and inspecting data are summarized below:

\begin{longtable}[]{@{}ll@{}}
\toprule
Command & Description\tabularnewline
\midrule
\endhead
\texttt{describe} & labels, storage type etc.\tabularnewline
\texttt{sum} & statistical summary (mean, sd, min/max etc.)\tabularnewline
\texttt{codebook} & storage type, unique values, labels\tabularnewline
\texttt{list} & print actual values\tabularnewline
\texttt{tab} & (cross) tabulate variables\tabularnewline
\texttt{browse} & view the data in a spreadsheet-like window\tabularnewline
\bottomrule
\end{longtable}

First, let's ask Stata for help about these commands:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{help} \KeywordTok{sum}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use}\NormalTok{ gss.dta, }\KeywordTok{clear}

\KeywordTok{sum}\NormalTok{ educ }\CommentTok{// statistical summary of education}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{codebook}\NormalTok{ region }\CommentTok{// information about how region is coded}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tab}\NormalTok{ sex }\CommentTok{// numbers of male and female participants}
\end{Highlighting}
\end{Shaded}

Note --- if you run these commands without specifying variables, Stata will produce output for every variable

\hypertarget{basic-graphing-commands}{%
\subsection{Basic graphing commands}\label{basic-graphing-commands}}

Univariate distribution(s) using \texttt{hist}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Histograms }
\KeywordTok{hist}\NormalTok{ educ}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// histogram with normal curve; see \textasciigrave{}help hist\textasciigrave{} for other options}
\KeywordTok{hist}\NormalTok{ age, }\FunctionTok{normal}  
\end{Highlighting}
\end{Shaded}

View bivariate distributions with scatterplots:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// scatterplots }
\KeywordTok{twoway}\NormalTok{ (}\KeywordTok{scatter}\NormalTok{ educ age)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{graph} \FunctionTok{matrix}\NormalTok{ educ age inc}
\end{Highlighting}
\end{Shaded}

\hypertarget{the-by-command}{%
\subsection{\texorpdfstring{The \texttt{by} command}{The by command}}\label{the-by-command}}

Sometimes, you'd like to generate output based on different categories of a grouping variable, for example:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  you want to know the distribution of happiness seperately for men and women: tabulate \texttt{happy} by \texttt{sex}:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{bysort}\NormalTok{ sex: }\KeywordTok{tab}\NormalTok{ happy}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  you want to know the mean level of education for different marital status: summarize \texttt{education} by marital status (\texttt{marital}):
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{bysort}\NormalTok{ marital: }\KeywordTok{sum}\NormalTok{ educ }
\end{Highlighting}
\end{Shaded}

Save your changes to the original \texttt{gss.dta} dataset.

\hypertarget{exercise-1-6}{%
\subsection{Exercise 1}\label{exercise-1-6}}

We are using The Generations of Talent Study (\texttt{talent.dta}) to practice reading in data, plotting data, and calculating descriptive statistics. The dataset includes information on quality of employment as experienced by today's multigenerational workforces. Here is a codebook of a subset of variables:

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.17\columnwidth}\raggedright
Variable name\strut
\end{minipage} & \begin{minipage}[b]{0.77\columnwidth}\raggedright
Label\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.17\columnwidth}\raggedright
job\strut
\end{minipage} & \begin{minipage}[t]{0.77\columnwidth}\raggedright
type of main job\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
workload\strut
\end{minipage} & \begin{minipage}[t]{0.77\columnwidth}\raggedright
how long hours do you work per week\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
otherjob\strut
\end{minipage} & \begin{minipage}[t]{0.77\columnwidth}\raggedright
do you have other paid jobs beside main job\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
schedule\strut
\end{minipage} & \begin{minipage}[t]{0.77\columnwidth}\raggedright
which best describes your work schedule\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
fulltime\strut
\end{minipage} & \begin{minipage}[t]{0.77\columnwidth}\raggedright
Does your employer consider you a full-time or part-time employee\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
B3A\strut
\end{minipage} & \begin{minipage}[t]{0.77\columnwidth}\raggedright
How important are the following to you? Your work\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
B3B\strut
\end{minipage} & \begin{minipage}[t]{0.77\columnwidth}\raggedright
How important are the following to you? Your family\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
B3C\strut
\end{minipage} & \begin{minipage}[t]{0.77\columnwidth}\raggedright
How important are the following to you? Your friends\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
marital\strut
\end{minipage} & \begin{minipage}[t]{0.77\columnwidth}\raggedright
Which of the following best describes your current marital status\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
I3\strut
\end{minipage} & \begin{minipage}[t]{0.77\columnwidth}\raggedright
Sex/gender\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.17\columnwidth}\raggedright
income\strut
\end{minipage} & \begin{minipage}[t]{0.77\columnwidth}\raggedright
What was your total household income during last year\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

Create a new do-file for the following exercise prompts. After the exercise save the do-file to your working directory.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Read in the dataset \texttt{talent.dta}:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Examine a few selected variables using the \texttt{describe}, \texttt{sum} and \texttt{codebook} commands:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Produce a histogram of hours worked (\texttt{workload}) and add a normal curve:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Summarize the total household income last year (\texttt{income}) by marital status (\texttt{marital}):
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Cross-tabulate marital status (\texttt{marital}) with respondents' type of main job (\texttt{job}):
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 1 Solution}

\begin{alert}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use}\NormalTok{ talent.dta, }\KeywordTok{clear}
\KeywordTok{describe}\NormalTok{ workperweek}
\KeywordTok{tab}\NormalTok{ I3}
\KeywordTok{sum}\NormalTok{ income}
\KeywordTok{codebook}\NormalTok{ job}

\KeywordTok{hist}\NormalTok{ workload, }\FunctionTok{normal} 

\KeywordTok{bysort}\NormalTok{ marital: }\KeywordTok{sum}\NormalTok{ income}
\KeywordTok{bysort}\NormalTok{ job: }\KeywordTok{tab}\NormalTok{ marital }
\KeywordTok{summarize}\NormalTok{ income }\KeywordTok{if}\NormalTok{ marital == 1}

\KeywordTok{save}\NormalTok{ talent.dta, }\KeywordTok{replace} 
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{basic-data-management}{%
\section{Basic data management}\label{basic-data-management}}

\begin{alert}

\textbf{GOAL: To learn how to add \emph{variable labels} and \emph{value labels}, as well as create \emph{new variables} in Stata.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use \texttt{label} and \texttt{rename} to set / modify variable and value labels
\item
  Use \texttt{generate} and \texttt{replace} to create a new variables based on values of existing variables/recode a variable
\end{enumerate}

\end{alert}

\hypertarget{variable-value-labels}{%
\subsection{Variable \& value labels}\label{variable-value-labels}}

\hypertarget{variable-labels}{%
\subsubsection{Variable labels}\label{variable-labels}}

It's good practice to ALWAYS label every variable, no matter how insignificant it may seem.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Labelling and renaming }
\CommentTok{// Label variable inc "household income"}
\KeywordTok{label} \KeywordTok{var}\NormalTok{ inc }\StringTok{"household income"}

\CommentTok{// change the name "educ" to "education"}
\KeywordTok{rename}\NormalTok{ educ education}

\CommentTok{// you can search names and labels with \textasciigrave{}lookfor\textasciigrave{}}
\KeywordTok{lookfor}\NormalTok{ household}
\end{Highlighting}
\end{Shaded}

\hypertarget{value-labels}{%
\subsubsection{Value labels}\label{value-labels}}

Value labels are a little more complicated, with a two step process: define a value label, then assign defined label to variable(s)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// define a value label for sex }
\KeywordTok{label} \KeywordTok{define}\NormalTok{ mySexLabel 1 }\StringTok{"Male"}\NormalTok{ 2 }\StringTok{"Female"}

\CommentTok{// assign our label set to the sex variable}
\KeywordTok{label} \KeywordTok{values}\NormalTok{ sex mySexLabel}
\end{Highlighting}
\end{Shaded}

\hypertarget{working-on-subsets}{%
\subsection{Working on subsets}\label{working-on-subsets}}

It is often useful to select just those rows of your data where some condition holds --- for example select only rows where sex is 1 (male). The following operators allow you to do this:

\begin{longtable}[]{@{}ll@{}}
\toprule
Operator & Meaning\tabularnewline
\midrule
\endhead
== & equal to\tabularnewline
!= & not equal to\tabularnewline
\textgreater{} & greater than\tabularnewline
\textgreater= & greater than or equal to\tabularnewline
\textless{} & less than\tabularnewline
\textless= & less than or equal to\tabularnewline
\& & and\tabularnewline
\textbar{} & or\tabularnewline
\bottomrule
\end{longtable}

Note the double equals signs for testing equality.

\hypertarget{generating-replacing-variables}{%
\subsection{Generating \& replacing variables}\label{generating-replacing-variables}}

Often, it can be useful to start with a new variable composed of blank values and fill values in based on the values of existing variables:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// generate a column of missings}
\KeywordTok{gen}\NormalTok{ age\_wealth = .}

\CommentTok{// Next, start adding your qualifications}
\KeywordTok{replace}\NormalTok{ age\_wealth=1 }\KeywordTok{if}\NormalTok{ age \textless{} 30 \& inc \textless{} 10}
\KeywordTok{replace}\NormalTok{ age\_wealth=2 }\KeywordTok{if}\NormalTok{ age \textless{} 30 \& inc \textgreater{} 10}
\KeywordTok{replace}\NormalTok{ age\_wealth=3 }\KeywordTok{if}\NormalTok{ age \textgreater{} 30 \& inc \textless{} 10}
\KeywordTok{replace}\NormalTok{ age\_wealth=4 }\KeywordTok{if}\NormalTok{ age \textgreater{} 30 \& inc \textgreater{} 10}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercise-2-4}{%
\subsection{Exercise 2}\label{exercise-2-4}}

Open the \texttt{talent.dta} data, use the basic data management tools we have learned to add labels and generate new variables:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Tabulate the variable, marital status (\texttt{marital}), with and without labels:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Summarize the total household income last year (\texttt{income}) for married individuals only:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Generate a new \texttt{overwork} dummy variable from the original variable \texttt{workperweek} that will take on a value of 1 if a person works more than 40 hours per week, and 0 if a person works equal to or less than 40 hours per week:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Generate a new \texttt{marital\_dummy} dummy variable from the original variable \texttt{marital} that will take on a value of 1 if a person is either married or partnered and 0 otherwise:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Rename the \texttt{Sex} variable and give it a more intuitive name:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Give a variable label and value labels for the variable \texttt{overwork}:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Generate a new variable called \texttt{work\_family} and code it as 2 if a respondent perceived work to be more important than family, 1 if a respondent perceived family to be more important than work, and 0 if the two are of equal importance:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Save the changes to \texttt{newtalent.dta}
\end{enumerate}

{Click for Exercise 2 Solution}

\begin{alert}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use}\NormalTok{ talent.dta, }\KeywordTok{clear}

\KeywordTok{tab}\NormalTok{ marital}
\KeywordTok{tab}\NormalTok{ marital, nol }

\KeywordTok{gen}\NormalTok{ overwork = .}
\KeywordTok{replace}\NormalTok{ overwork = 1 }\KeywordTok{if}\NormalTok{ workperweek \textgreater{} 40}
\KeywordTok{replace}\NormalTok{ overwork = 0 }\KeywordTok{if}\NormalTok{ workperweek \textless{}= 40}
\KeywordTok{tab}\NormalTok{ overwork}

\KeywordTok{gen}\NormalTok{ marital\_dummy = .}
\KeywordTok{replace}\NormalTok{ marital\_dummy = 1 }\KeywordTok{if}\NormalTok{ marital == 1 | marital == 2}
\KeywordTok{replace}\NormalTok{ marital\_dummy = 0 }\KeywordTok{if}\NormalTok{ marital != 1 \& marital != 2}
\KeywordTok{tab}\NormalTok{ marital\_dummy}

\KeywordTok{rename}\NormalTok{ I3 Sex}

\KeywordTok{label} \KeywordTok{variable}\NormalTok{ overwork }\StringTok{"whether someone works more than 40 hours per week"}
\KeywordTok{label} \KeywordTok{define}\NormalTok{ overworklabel 1 }\StringTok{"Yes"}\NormalTok{ 0 }\StringTok{"No"}
\KeywordTok{label} \KeywordTok{values}\NormalTok{ overwork overworklabel}

\KeywordTok{gen}\NormalTok{ work\_family = .}
\KeywordTok{replace}\NormalTok{ work\_family = 2 }\KeywordTok{if}\NormalTok{ B3A \textgreater{} B3B}
\KeywordTok{replace}\NormalTok{ work\_family = 1 }\KeywordTok{if}\NormalTok{ B3A \textless{} B3B}
\KeywordTok{replace}\NormalTok{ work\_family = 0 }\KeywordTok{if}\NormalTok{ B3A == B3B}

\KeywordTok{save}\NormalTok{ newtalent.dta, }\KeywordTok{replace} 
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{bivariate-analyses}{%
\section{Bivariate analyses}\label{bivariate-analyses}}

\begin{alert}

\textbf{GOAL: To learn the basic commands for performing the following bivariate analyses.}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Chi-squared test
\item
  Independent group t-test
\item
  One-way ANOVA
\end{enumerate}

\end{alert}

\hypertarget{chi-squared-test}{%
\subsection{Chi-squared test}\label{chi-squared-test}}

The Chi-squared statistic is commonly used for testing relationships between categorical variables.

In Stata, both the \texttt{tabulate} and \texttt{tabi} commands conduct the Pearson's Chi-square test.

\begin{itemize}
\tightlist
\item
  The \texttt{tabulate} (may be abbreviated as \texttt{tab}) command produces one- or two-way frequency tables given one or two raw variables
\item
  The \texttt{tabi} command is used to re-analyze a published table without access to the raw data
\item
  These commands also can run a Chi-square test using the \texttt{chi2} option:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tab}\NormalTok{ sex happy, }\FunctionTok{chi2} 
\end{Highlighting}
\end{Shaded}

The first command below conducts a Chi-square test for a 2x2 table, while the second and third commands run the test for 3x2 and 2x3 tables, respectively.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tabi}\NormalTok{ 33 48 \textbackslash{} 37 52, }\FunctionTok{chi2}
\KeywordTok{tabi}\NormalTok{ 33 48 \textbackslash{} 37 52 \textbackslash{} 36 42, }\FunctionTok{chi2}
\KeywordTok{tabi}\NormalTok{ 33 48 26 \textbackslash{} 37 52 38, }\FunctionTok{chi2}
\end{Highlighting}
\end{Shaded}

\hypertarget{t-test}{%
\subsection{t-test}\label{t-test}}

The t-test is a type of inferential statistic that can be used to determine if a sample mean differs from a postulated population mean, or if two sample means came from the same population.

Types of t-test:

\begin{itemize}
\tightlist
\item
  Independent group t-test: designed to compare means of same variable between two groups. For example, test GRE scores between students from two countries
\item
  Other t-tests: single sample t-test; paired t-test. More details see: \url{https://www.stata.com/manuals13/rttest.pdf}
\end{itemize}

In our example, we conduct an independent group t-test to compare mean income (\texttt{inc}) between males and females (\texttt{sex}):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ttest}\NormalTok{ inc, }\KeywordTok{by}\NormalTok{(sex)}
\end{Highlighting}
\end{Shaded}

\hypertarget{one-way-anova}{%
\subsection{One-way ANOVA}\label{one-way-anova}}

One-way ANOVA allows us to test the equality of more than two sample means (i.e., whether they could plausibly have come from the same population). For example, our dataset contains income (\texttt{inc}) and four regions of the country (\texttt{region}). Using one-way ANOVA, we can simultaneously test the equality of the income means across all regions.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{oneway}\NormalTok{ inc region }
\end{Highlighting}
\end{Shaded}

Now we find evidence that the means are different, but perhaps we are interested only in testing whether the means for the North (region==1) and South (region==4) are different. We also use one-way ANOVA, which in this case would be equivelant to the independent group t-test:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{oneway}\NormalTok{ inc region }\KeywordTok{if}\NormalTok{ region==1 | region==4}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercise-3-4}{%
\subsection{Exercise 3}\label{exercise-3-4}}

Open the \texttt{newtalent.dta} data, use the basic data management tools we have learned to conduct bivariate analysis.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Test the relationship between two variables \texttt{sex} and type of main job (\texttt{job}):
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Test if there is a significant difference in hours worked per week (\texttt{workload}) and \texttt{sex}:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Test if there is a significant difference in hours worked per week (\texttt{workload}) and marital status (\texttt{marital}):
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 3 Solution}

\begin{alert}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use}\NormalTok{ newtalent.dta, }\KeywordTok{clear} 

\KeywordTok{tab}\NormalTok{ Sex job, }\FunctionTok{chi2} 

\KeywordTok{ttest}\NormalTok{ workload, }\KeywordTok{by}\NormalTok{(Sex)}
\KeywordTok{oneway}\NormalTok{ workload marital }

\KeywordTok{save}\NormalTok{ newtalent.dta, }\KeywordTok{replace} 
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{wrap-up-7}{%
\section{Wrap-up}\label{wrap-up-7}}

\hypertarget{feedback-7}{%
\subsection{Feedback}\label{feedback-7}}

These workshops are a work in progress, please provide any feedback to: \href{mailto:help@iq.harvard.edu}{\nolinkurl{help@iq.harvard.edu}}

\hypertarget{resources-10}{%
\subsection{Resources}\label{resources-10}}

\begin{itemize}
\tightlist
\item
  IQSS

  \begin{itemize}
  \tightlist
  \item
    Workshops: \url{https://dss.iq.harvard.edu/workshop-materials}
  \item
    Data Science Services: \url{https://dss.iq.harvard.edu/}
  \item
    Research Computing Environment: \url{https://iqss.github.io/dss-rce/}
  \end{itemize}
\item
  HBS

  \begin{itemize}
  \tightlist
  \item
    Research Computing Services workshops: \url{https://training.rcs.hbs.org/workshops}
  \item
    Other HBS RCS resources: \url{https://training.rcs.hbs.org/workshop-materials}
  \item
    RCS consulting email: \url{mailto:research@hbs.edu}
  \end{itemize}
\item
  Stata

  \begin{itemize}
  \tightlist
  \item
    UCLA website: \url{http://www.ats.ucla.edu/stat/Stata/}
  \item
    Stata website: \url{http://www.stata.com/help.cgi?contents}
  \item
    Email list: \url{http://www.stata.com/statalist/}
  \end{itemize}
\end{itemize}

\hypertarget{stata-data-management}{%
\chapter{Stata Data Management}\label{stata-data-management}}

\textbf{Topics}

\begin{itemize}
\tightlist
\item
  Generating and replacing variables
\item
  Missing values
\item
  Variable types and conversion
\item
  Merging, appending, and joining
\item
  Creating summarized data sets
\end{itemize}

\hypertarget{setup-7}{%
\section{Setup}\label{setup-7}}

\hypertarget{class-structure-and-organization-1}{%
\subsection{Class structure and organization}\label{class-structure-and-organization-1}}

\begin{itemize}
\tightlist
\item
  Please feel free to ask questions at any point if they are relevant to the current topic (or if you are lost!)
\item
  Collaboration is encouraged - please introduce yourself to your neighbors!
\item
  If you are using a laptop, you will need to adjust file paths accordingly
\item
  Make comments in your do-file - save on flash drive or email to yourself
\end{itemize}

\hypertarget{prerequisites-7}{%
\subsection{Prerequisites}\label{prerequisites-7}}

\begin{itemize}
\tightlist
\item
  This is an introduction to data management in Stata
\item
  Assumes basic knowledge of Stata
\item
  Not appropriate for people already familiar with Stata
\item
  If you are catching on before the rest of the class, experiment with command features described in help files
\end{itemize}

\hypertarget{goals-6}{%
\subsection{Goals}\label{goals-6}}

\begin{alert}

We will learn about the Stata language by analyzing data from the general social survey (gss). In particular, our goals are to learn:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Basic data manipulation commands
\item
  Dealing with missing values
\item
  Variable types and conversion
\item
  Merging and appending datasets
\end{enumerate}

\end{alert}

\hypertarget{opening-files}{%
\section{Opening Files}\label{opening-files}}

\begin{alert}

\textbf{GOAL: To understand the working directory of Stata, how to change working directory, and open files from the working directory.} In particular:

\end{alert}

Look at bottom left hand corner of Stata screen, this is the directory Stata is currently reading from. Files are located in the \texttt{StataDatMan} folder in your user directory. Let's start by telling Stata where to look for these:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// change directory}
\NormalTok{cd }\StringTok{"\textasciitilde{}/Desktop/dss{-}workshops/Stata/StataDatMan"}

\CommentTok{// Use dir to see what is in the directory:}
\OtherTok{dir}
\OtherTok{dir}\NormalTok{ dataSets}
\end{Highlighting}
\end{Shaded}

Now we can read in the \texttt{gss.dta} dataset:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use}\NormalTok{ dataSets/gss.dta}
\end{Highlighting}
\end{Shaded}

\hypertarget{generating-replacing-variables-1}{%
\section{Generating \& replacing variables}\label{generating-replacing-variables-1}}

\begin{alert}

\textbf{GOAL: You'll learn how to generate new variables or recode existing variables.} In particular, we will learn to use:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{generate} (\texttt{gen}) to create new variables
\item
  \texttt{egenerate} (\texttt{egen}) to create new variables using more complicated calculations than \texttt{gen} allows
\item
  \texttt{replace} to replace existing variables
\item
  \texttt{recode} to change existing categorical variables
\end{enumerate}

\end{alert}

\hypertarget{generate-replace}{%
\subsection{Generate \& Replace}\label{generate-replace}}

The \texttt{generate} command creates a new variables. Often, this is used in combination with the \texttt{replace} command and logic statements to create a new variable. Available logical operators include the following:

\begin{longtable}[]{@{}ll@{}}
\toprule
Operator & Meaning\tabularnewline
\midrule
\endhead
== & equal to\tabularnewline
!= & not equal to\tabularnewline
\textgreater{} & greater than\tabularnewline
\textgreater= & greater than or equal to\tabularnewline
\textless{} & less than\tabularnewline
\textless= & less than or equal to\tabularnewline
\& & and\tabularnewline
&\tabularnewline
\bottomrule
\end{longtable}

For example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{//create "hapnew" variable}
\KeywordTok{gen}\NormalTok{ hapnew = .}
\CommentTok{//set to 0 if happy equals 1}
\KeywordTok{replace}\NormalTok{ hapnew=0 }\KeywordTok{if}\NormalTok{ happy==1 }
\CommentTok{//set to 1 if happy both and hapmar are greater than 3}
\KeywordTok{replace}\NormalTok{ hapnew=1 }\KeywordTok{if}\NormalTok{ happy\textgreater{}3 \& hapmar\textgreater{}3 }
\CommentTok{// tabulate the new }
\KeywordTok{tab}\NormalTok{ hapnew}
\end{Highlighting}
\end{Shaded}

\hypertarget{recode}{%
\subsection{Recode}\label{recode}}

The \texttt{recode} command is basically \texttt{generate} and \texttt{replace} combined. You can \texttt{recode} an existing variable OR use \texttt{recode} to create a new variable (via the \texttt{gen} option).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// recode the wrkstat variable }
\KeywordTok{recode}\NormalTok{ wrkstat (1=8) (2=7) (3=6) (4=5) (5=4) (6=3) (7=2) (8=1)}
\CommentTok{// recode wrkstat into a new variable named wrkstat2}
\KeywordTok{recode}\NormalTok{ wrkstat (1=8), }\KeywordTok{gen}\NormalTok{(wrkstat2)}
\CommentTok{// tabulate workstat}
\KeywordTok{tab}\NormalTok{ wrkstat}
\end{Highlighting}
\end{Shaded}

The table below illustrates common forms of recoding:

\begin{longtable}[]{@{}lll@{}}
\toprule
Rule & Example & Meaning\tabularnewline
\midrule
\endhead
\#=\# & 3=1 & 3 recoded to 1\tabularnewline
\#\#=\# & 2.=9 & 2 and . recoded to 9\tabularnewline
\#/\#=\# & 1/5=4 & 1 through 5 recoded to 4\tabularnewline
nonmissing=\# & nonmiss=8 & nonmissing recoded to 8\tabularnewline
missing=\# & miss=9 & missing recoded to 9\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{egen}{%
\subsection{egen}\label{egen}}

The \texttt{egen} command (``extensions'' to the \texttt{gen} command) reaches beyond simple computations (var1 + var2, log(var1), etc.) to add descriptive stats, standardizations and more. For example, we can use \texttt{egen} to create a new variable that counts the number of ``yes'' responses on computer, email and internet use:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// count number of yes on use comp email and net }
\KeywordTok{egen}\NormalTok{ compuser = }\FunctionTok{anycount}\NormalTok{(usecomp usemail usenet), }\KeywordTok{values}\NormalTok{(1)}
\KeywordTok{tab}\NormalTok{ compuser}
\end{Highlighting}
\end{Shaded}

Here are some additional examples of \texttt{egen} in action:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// assess how much missing data each participant has:}
\KeywordTok{egen}\NormalTok{ countmiss = }\FunctionTok{rowmiss}\NormalTok{(age{-}wifeft)}
\KeywordTok{codebook}\NormalTok{ countmiss}
\CommentTok{// compare values on multiple variables}
\KeywordTok{egen}\NormalTok{ ftdiff = }\FunctionTok{diff}\NormalTok{(wkftwife wkfthusb)}
\KeywordTok{codebook}\NormalTok{ ftdiff}
\end{Highlighting}
\end{Shaded}

You will need to refer to the documentation to discover what else \texttt{egen} can do: type \texttt{help\ egen} in Stata to get a complete list of available functions.

\hypertarget{exercise-0-6}{%
\subsection{Exercise 0}\label{exercise-0-6}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Open the \texttt{gss.dta} data, \texttt{generate} a new variable that represents the squared value of \texttt{age}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \texttt{generate} a new variable equal to ``1'' if \texttt{income} is greater than ``19''.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Create a new variable that counts the number of missing responses for each respondent. What is the maximum number of missing variables?
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 0 Solution}

\begin{alert}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use}\NormalTok{ dataSets/gss.dta, }\KeywordTok{clear}
\KeywordTok{gen}\NormalTok{ age2 = age\^{}2}

\KeywordTok{describe}\NormalTok{ income}
\KeywordTok{label} \OtherTok{list}\NormalTok{ income}
\KeywordTok{recode}\NormalTok{ income (99=.) (98=.)}
\KeywordTok{gen}\NormalTok{ highincome =0 }\KeywordTok{if}\NormalTok{ income != .}
\KeywordTok{replace}\NormalTok{ highincome=1 }\KeywordTok{if}\NormalTok{ income\textgreater{}19}
\KeywordTok{sum}\NormalTok{ highincome}

\KeywordTok{egen}\NormalTok{ nmissing = }\FunctionTok{rowmiss}\NormalTok{(}\DataTypeTok{\_all}\NormalTok{)}
\KeywordTok{sum}\NormalTok{ nmissing}
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{missing-values}{%
\section{Missing values}\label{missing-values}}

\begin{alert}

\textbf{GOAL: Learn how missing values are coded and how to recode them.}

\end{alert}

Stata's symbol for a missing value is a period \texttt{.} and this value is coded and treated as \textbf{positive infinity} (i.e., the largest possible value), so it's easy to make mistakes when making logical and relational comparisons!

\hypertarget{making-sure-missingness-is-preserved}{%
\subsection{Making sure missingness is preserved}\label{making-sure-missingness-is-preserved}}

To identify highly educated women, we might use the command:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// generate and replace without considering missing values}
\KeywordTok{gen}\NormalTok{ hi\_ed=0}
\KeywordTok{replace}\NormalTok{ hi\_ed=1 }\KeywordTok{if}\NormalTok{ wifeduc\textgreater{}15}
\CommentTok{// What happens to our missing values?}
\KeywordTok{tab}\NormalTok{ hi\_ed, }\FunctionTok{mi}\NormalTok{ nola}
\end{Highlighting}
\end{Shaded}

It looks like around 66\% have higher education, but look closer:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// generate hi\_ed2, but only set a value if wifeduc is not missing}
\KeywordTok{gen}\NormalTok{ hi\_ed2 = 0 }\KeywordTok{if}\NormalTok{ wifeduc != . }
\CommentTok{// only replace non{-}missing values}
\KeywordTok{replace}\NormalTok{ hi\_ed2=1 }\KeywordTok{if}\NormalTok{ wifeduc \textgreater{}15 \& wifeduc !=. }
\CommentTok{//check to see that missingness is preserved}
\KeywordTok{tab}\NormalTok{ hi\_ed2, }\FunctionTok{mi}
\end{Highlighting}
\end{Shaded}

The correct value is 10\%. Moral of the story? Be careful with missing values and remember that Stata considers missing values to be \textbf{positive infinity}!

\hypertarget{bulk-conversion-to-missing-values}{%
\subsection{Bulk Conversion to missing values}\label{bulk-conversion-to-missing-values}}

Often the data collection / generating procedure will have used some other value besides \texttt{.} to represent missing values. The \texttt{mvdecode} command will convert all these values to missing. For example:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mvdecode} \DataTypeTok{\_all}\NormalTok{, mv(999)}
\end{Highlighting}
\end{Shaded}

The \texttt{\_all} command tells Stata to perform this conversion for all variables. Use this command carefully! If you have any variables where ``999'' is a legitimate value, Stata is going to recode it to missing. As an alternative, you could list var names separately rather than using \texttt{\_all}.

\hypertarget{variable-types}{%
\section{Variable types}\label{variable-types}}

\begin{alert}

\textbf{GOAL: Learn about the two main types of variables that Stata uses: string and numeric.}

\end{alert}

To be able to perform any mathematical operations, your variables need to be in a numeric format. Stata can store numbers with differing levels of precision, as described in the table below:

\begin{longtable}[]{@{}lllll@{}}
\toprule
type & Minimum & Maximum & being 0 & bytes\tabularnewline
\midrule
\endhead
byte & -127 & 100 & +/-1 & 1\tabularnewline
int & -32,767 & 32,740 & +/-1 & 2\tabularnewline
long & -2,147,483,647 & 2,147,483,620 & +/-1 & 4\tabularnewline
float & -1.70141173319*1038 & 1.70141173319*1038 & +/-10-38 & 4\tabularnewline
double & -8.9884656743*10307 & 8.9884656743*10307 & +/-10-323 & 8\tabularnewline
\bottomrule
\end{longtable}

Precision for float is 3.795x10-8. Precision for double is 1.414x10-16.

\hypertarget{converting-to-from-strings}{%
\subsection{Converting to \& from Strings}\label{converting-to-from-strings}}

Stata provides several ways to convert to and from strings. You can use \texttt{tostring} and \texttt{destring} to convert from one type to the other:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// convert degree to a string}
\KeywordTok{tostring}\NormalTok{ degree, }\KeywordTok{gen}\NormalTok{(degree\_s)}
\CommentTok{// and back to a number}
\KeywordTok{destring}\NormalTok{ degree\_s, }\KeywordTok{gen}\NormalTok{(degree\_n)}
\end{Highlighting}
\end{Shaded}

Use \texttt{decode} and \texttt{encode} to convert to / from variable labels:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// convert degree to a descriptive string}
\KeywordTok{decode}\NormalTok{ degree, }\KeywordTok{gen}\NormalTok{(degree\_s2)}
\CommentTok{// and back to a number with labels}
\KeywordTok{encode}\NormalTok{ degree\_s2, }\KeywordTok{gen}\NormalTok{(degree\_n2)}
\end{Highlighting}
\end{Shaded}

\hypertarget{converting-strings-to-date-time}{%
\subsection{Converting strings to date / time}\label{converting-strings-to-date-time}}

Often date / time variables start out as strings --- you'll need to convert them to numbers using one of the conversion functions listed below:

\begin{longtable}[]{@{}lll@{}}
\toprule
Format & Meaning & String-to-numeric conversion function\tabularnewline
\midrule
\endhead
\%tc & milliseconds & clock(string, mask)\tabularnewline
\%td & days & date(string, mask)\tabularnewline
\%tw & weeks & weekly(string, mask)\tabularnewline
\%tm & months & monthly(string, mask)\tabularnewline
\%tq & quarters & quarterly(string, mask)\tabularnewline
\%ty & years & yearly(string, mask)\tabularnewline
\bottomrule
\end{longtable}

Date / time variables are stored as the number of units elapsed since 01 January 1960 00:00:00.000. For example, the \texttt{date} function returns the number of days since that time, and the \texttt{clock} function returns the number of milliseconds since that time.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// create string variable and convert to date}
\KeywordTok{gen} \FunctionTok{date}\NormalTok{ = }\StringTok{"November 9 2020"}
\KeywordTok{gen}\NormalTok{ date1 = }\FunctionTok{date}\NormalTok{(}\FunctionTok{date}\NormalTok{, }\StringTok{"MDY"}\NormalTok{)}
\OtherTok{list}\NormalTok{ date1 }\KeywordTok{in}\NormalTok{ 1/5}
\end{Highlighting}
\end{Shaded}

\hypertarget{formatting-numbers-as-dates}{%
\subsection{Formatting numbers as dates}\label{formatting-numbers-as-dates}}

Once you have converted a string to a number you can format it for display. You can either accept the defaults used by your formatting string or provide details to customize it.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// format so humans can read the date}
\KeywordTok{format}\NormalTok{ date1 \%}\KeywordTok{d}
\OtherTok{list}\NormalTok{ date1 }\KeywordTok{in}\NormalTok{ 1/5}
\CommentTok{// format with detail}
\KeywordTok{format}\NormalTok{ date1 \%tdMonth\_dd,\_CCYY}
\OtherTok{list}\NormalTok{ date1 }\KeywordTok{in}\NormalTok{ 1/5}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercise-1-7}{%
\subsection{Exercise 1}\label{exercise-1-7}}

\textbf{Missing values, string conversion, \& by processing}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Recode values ``99'' and ``98'' on the variable \texttt{hrs1} as missing.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Recode the \texttt{marital} variable into a string variable and then back into a numeric variable.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Create a new variable that associates each individual with the average number of hours worked among individuals with matching educational degrees (see the last \texttt{by} example for inspiration).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 1 Solution}

\begin{alert}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use}\NormalTok{ dataSets/gss.dta, }\KeywordTok{clear}
\KeywordTok{sum}\NormalTok{ hrs1}
\KeywordTok{recode}\NormalTok{ hrs1 (99=.) (98=.) }
\KeywordTok{sum}\NormalTok{ hrs1}

\KeywordTok{tostring}\NormalTok{ marital, }\KeywordTok{gen}\NormalTok{(marstring)}
\KeywordTok{destring}\NormalTok{ marstring, }\KeywordTok{gen}\NormalTok{(mardstring)}
\CommentTok{//compare with}
\KeywordTok{decode}\NormalTok{ marital, }\KeywordTok{gen}\NormalTok{(marital\_s)}
\KeywordTok{encode}\NormalTok{ marital\_s, }\KeywordTok{gen}\NormalTok{(marital\_n)}

\KeywordTok{describe}\NormalTok{ marital marstring mardstring marital\_s marital\_n}
\KeywordTok{sum}\NormalTok{ marital marstring mardstring marital\_s marital\_n}

\KeywordTok{bysort}\NormalTok{ degree: }\KeywordTok{egen}\NormalTok{ hrsdegree = }\KeywordTok{mean}\NormalTok{(hrs1)}
\KeywordTok{tab}\NormalTok{ hrsdegree}
\KeywordTok{tab}\NormalTok{ hrsdegree degree }
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{merging-appending-collapsing}{%
\section{Merging, appending, \& collapsing}\label{merging-appending-collapsing}}

\begin{alert}

\textbf{GOAL: To learn the basic commands to merge, append, or join two dataset in Stata.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  How to append datasets
\item
  How to merge datasets and types of merge
\item
  Collapse from master data and create a new dataset of summary statistics
\end{enumerate}

\end{alert}

\hypertarget{appending-datasets}{%
\subsection{Appending datasets}\label{appending-datasets}}

Sometimes you have observations in two different datasets, or you'd like to add observations to an existing dataset. In this case you can use the \texttt{append} command to add observations to the end of the observations in the master dataset. For example:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{clear}
\CommentTok{// from the append help file}
\KeywordTok{webuse}\NormalTok{ even}
\OtherTok{list}
\KeywordTok{webuse}\NormalTok{ odd}
\OtherTok{list}
\CommentTok{// Append even data to the end of the odd data}
\KeywordTok{append} \KeywordTok{using} \StringTok{"http://www.stata{-}press.com/data/r14/even"}
\OtherTok{list}
\KeywordTok{clear}
\end{Highlighting}
\end{Shaded}

To keep track of where observations came from, use the \texttt{generate} option as shown below:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{webuse}\NormalTok{ odd}
\KeywordTok{append} \KeywordTok{using} \StringTok{"http://www.stata{-}press.com/data/r14/even"}\NormalTok{, }\KeywordTok{generate}\NormalTok{(observesource)}
\OtherTok{list}
\KeywordTok{clear}
\end{Highlighting}
\end{Shaded}

There is a \texttt{force} option will allow for data type mismatches, but this is not recommended. Remember, \texttt{append} is for adding observations (i.e., rows) from a second data set to your current dataset.

\hypertarget{merging-datasets}{%
\subsection{Merging datasets}\label{merging-datasets}}

You can \texttt{merge} variables from a second dataset to the dataset you're currently working with. There are different ways that you might be interested in merging data:

\begin{itemize}
\tightlist
\item
  Two datasets with same participant pool, one row per participant (1:1)
\item
  A dataset with one participant per row with a dataset with multiple rows per participant (1:many or many:1)
\end{itemize}

Before you begin:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Identify the \texttt{ID} that you will use to merge your two datasets
\item
  Determine which variables you'd like to merge
\item
  Variable types must match across datasets (there is a \texttt{force} option to get around this, but it is not recommended)
\end{enumerate}

Note --- data do NOT have to be sorted prior to merging.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Adapted from the merge help page}
\KeywordTok{webuse}\NormalTok{ autosize }
\OtherTok{list}
\KeywordTok{webuse}\NormalTok{ autoexpense}
\OtherTok{list}

\KeywordTok{webuse}\NormalTok{ autosize}
\KeywordTok{merge}\NormalTok{ 1:1 make }\KeywordTok{using} \StringTok{"http://www.stata{-}press.com/data/r14/autoexpense"}
\OtherTok{list}
\KeywordTok{clear}

\CommentTok{// keep only the matches (AKA "inner join")}
\KeywordTok{webuse}\NormalTok{ autosize, }\KeywordTok{clear}
\KeywordTok{merge}\NormalTok{ 1:1 make }\KeywordTok{using} \StringTok{"http://www.stata{-}press.com/data/r14/autoexpense"}\NormalTok{, }\KeywordTok{keep}\NormalTok{(}\FunctionTok{match}\NormalTok{) nogen}
\OtherTok{list}
\KeywordTok{clear}
\end{Highlighting}
\end{Shaded}

Remember, \texttt{merge} is for adding variables (i.e., columns) from a second data set.

\hypertarget{merge-options}{%
\subsection{Merge Options}\label{merge-options}}

There are several options that provide more fine-grain control over what happens to non-id columns contained in both data sets. If you've carefully cleaned and prepared the data prior to merging this shouldn't be an issue, but here are some details about how Stata handles this situation.

\begin{itemize}
\tightlist
\item
  In standard merge, the current active dataset is the authority and WON'T CHANGE
\item
  If your current dataset has missing data and some of those values are not missing in your new dataset, specify \texttt{update} -- this will fill in missing data in the current dataset
\item
  If you want data from your new dataset to overwrite that in your current dataset, specify \texttt{replace\ update} --- this will replace current data with new data UNLESS the value is missing in the new dataset
\end{itemize}

\hypertarget{many-to-many-merges---joinby-command}{%
\subsection{Many-to-many merges - joinby command}\label{many-to-many-merges---joinby-command}}

Stata allows you to specify merges like \texttt{merge\ m:m\ id} using \texttt{newdata.dta}, but it is difficult to imagine a situation where this would be useful. If you are thinking about using \texttt{merge\ m:m} chances are good that you actually need \texttt{joinby}. Please refer to the \texttt{joinby} help page for details.

\hypertarget{collapse}{%
\subsection{Collapse}\label{collapse}}

\texttt{collapse} will take your current active dataset and create a new dataset of summary statistics

\begin{itemize}
\tightlist
\item
  Useful in hierarchical linear modeling if you'd like to create aggregate, summary statistics
\item
  Can generate group summary data for many descriptive stats
\item
  Can also attach weights
\end{itemize}

Before you \texttt{collapse}:

\begin{itemize}
\tightlist
\item
  Save your current dataset and then save it again under a new name (this will prevent \texttt{collapse} from writing over your original data
\item
  Consider issues of missing data. Do you want Stata to use all possible observations? If not, the \texttt{cw} (casewise) option will make casewise deletions
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Adapted from the collapse help page}
\KeywordTok{clear}
\KeywordTok{webuse}\NormalTok{ college}
\OtherTok{list}
\CommentTok{// mean and sd by hospital}
\KeywordTok{collapse}\NormalTok{ (}\KeywordTok{mean}\NormalTok{) mean\_gpa = gpa mean\_hour = hour (}\FunctionTok{sd}\NormalTok{) sd\_gpa = gpa sd\_hour = hour, }\KeywordTok{by}\NormalTok{(}\FunctionTok{year}\NormalTok{)}
\OtherTok{list}
\KeywordTok{clear}
\end{Highlighting}
\end{Shaded}

You could also generate different statistics for multiple variables.

\hypertarget{exercise-2-5}{%
\subsection{Exercise 2}\label{exercise-2-5}}

\textbf{Append, merge, \& collapse}

Open the \texttt{gss2.dta} dataset. This dataset contains only half of the variables that are in the complete gss dataset.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Merge dataset \texttt{gss1.dta} with dataset \texttt{gss2.dta}. The identification variable is \texttt{id}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Open the \texttt{gss.dta} dataset and merge in data from the \texttt{marital.dta} dataset, which includes income information grouped by individuals' marital status. The \texttt{marital.dta} dataset contains collapsed data regarding average statistics of individuals based on their marital status.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Open the \texttt{gssAppend.dta} dataset and create a new dataset that combines the observations in \texttt{gssAppend.dta} with those in \texttt{gssAddObserve.dta}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Open the \texttt{gss.dta} dataset and create a new dataset that summarizes the mean and standard deviation of income based on individuals' degree status (\texttt{degree}). In the process of creating this new dataset, rename your three new variables.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 2 Solution}

\begin{alert}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use}\NormalTok{ dataSets/gss2.dta, }\KeywordTok{clear}
\KeywordTok{merge}\NormalTok{ 1:1 id }\KeywordTok{using}\NormalTok{ dataSets/gss1.dta}
\KeywordTok{save}\NormalTok{ gss3.dta, }\KeywordTok{replace}

\KeywordTok{use}\NormalTok{ dataSets/gss.dta, }\KeywordTok{clear}
\KeywordTok{merge} \FunctionTok{m}\NormalTok{:1 marital }\KeywordTok{using}\NormalTok{ dataSets/marital.dta, nogenerate }\KeywordTok{replace}\NormalTok{ update}
\KeywordTok{save}\NormalTok{ gss4.dta, }\KeywordTok{replace}

\KeywordTok{use}\NormalTok{ dataSets/gssAppend.dta, }\KeywordTok{clear}
\KeywordTok{append} \KeywordTok{using}\NormalTok{ dataSets/gssAddObserve, }\KeywordTok{generate}\NormalTok{(observe) }

\KeywordTok{use}\NormalTok{ dataSets/gss.dta, }\KeywordTok{clear}
\KeywordTok{save}\NormalTok{ collapse2.dta, }\KeywordTok{replace}
\KeywordTok{use}\NormalTok{ collapse2.dta, }\KeywordTok{clear}
\KeywordTok{collapse}\NormalTok{ (}\KeywordTok{mean}\NormalTok{) meaninc=income (}\FunctionTok{sd}\NormalTok{) sdinc=income, }\KeywordTok{by}\NormalTok{(marital)}
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{wrap-up-8}{%
\section{Wrap-up}\label{wrap-up-8}}

\hypertarget{feedback-8}{%
\subsection{Feedback}\label{feedback-8}}

These workshops are a work-in-progress, please provide any feedback to: \href{mailto:help@iq.harvard.edu}{\nolinkurl{help@iq.harvard.edu}}

\hypertarget{resources-11}{%
\subsection{Resources}\label{resources-11}}

\begin{itemize}
\tightlist
\item
  IQSS

  \begin{itemize}
  \tightlist
  \item
    Workshops: \url{https://dss.iq.harvard.edu/workshop-materials}
  \item
    Data Science Services: \url{https://dss.iq.harvard.edu/}
  \item
    Research Computing Environment: \url{https://iqss.github.io/dss-rce/}
  \end{itemize}
\item
  HBS

  \begin{itemize}
  \tightlist
  \item
    Research Computing Services workshops: \url{https://training.rcs.hbs.org/workshops}
  \item
    Other HBS RCS resources: \url{https://training.rcs.hbs.org/workshop-materials}
  \item
    RCS consulting email: \url{mailto:research@hbs.edu}
  \end{itemize}
\item
  Stata

  \begin{itemize}
  \tightlist
  \item
    UCLA website: \url{http://www.ats.ucla.edu/stat/Stata/}
  \item
    Stata website: \url{http://www.stata.com/help.cgi?contents}
  \item
    Email list: \url{http://www.stata.com/statalist/}
  \end{itemize}
\end{itemize}

\hypertarget{stata-regression-models}{%
\chapter{Stata Regression Models}\label{stata-regression-models}}

\textbf{Topics}

\begin{itemize}
\tightlist
\item
  Models with continuous outcomes

  \begin{itemize}
  \tightlist
  \item
    OLS regression
  \item
    OLS model assumptions and diagnostics
  \item
    Including interaction terms
  \item
    Including categorical predictors
  \end{itemize}
\item
  Models with binary outcomes

  \begin{itemize}
  \tightlist
  \item
    Logistic regression
  \item
    Obtaining odds ratios
  \end{itemize}
\item
  Exporting \& saving results

  \begin{itemize}
  \tightlist
  \item
    Regression tables
  \item
    Model comparison
  \end{itemize}
\item
  Obtaining quantities of interest

  \begin{itemize}
  \tightlist
  \item
    Margins of responses

    \begin{itemize}
    \tightlist
    \item
      APM: Average Predictive Margins
    \item
      PMM: Predictive Margins at the Means
    \item
      PMR: Predictive Margins at Representative values
    \end{itemize}
  \item
    Margins of changes in responses

    \begin{itemize}
    \tightlist
    \item
      AME: Average Marginal Effects
    \item
      MEM: Marginal Effects at the Means
    \item
      MER: Marginal Effects at Representative values
    \end{itemize}
  \end{itemize}
\end{itemize}

\hypertarget{setup-8}{%
\section{Setup}\label{setup-8}}

\hypertarget{class-structure-and-organization-2}{%
\subsection{Class structure and organization}\label{class-structure-and-organization-2}}

\begin{itemize}
\tightlist
\item
  Informal --- Ask questions at any time. Really!
\item
  Collaboration is encouraged - please spend a minute introducing yourself to your neighbors!
\item
  If you are using a laptop, you will need to adjust file paths accordingly
\item
  Make comments in your do-file - save on flash drive or email to yourself
\end{itemize}

\hypertarget{prerequisites-8}{%
\subsection{Prerequisites}\label{prerequisites-8}}

This is an intermediate-level Stata modeling workshop

\begin{itemize}
\tightlist
\item
  Assumes basic knowledge of Stata
\item
  Not appropriate for people already well familiar with modeling in Stata
\item
  If you are catching on before the rest of the class, experiment with command features described in help files
\end{itemize}

\hypertarget{goals-7}{%
\subsection{Goals}\label{goals-7}}

\begin{alert}

\textbf{We will learn about the Stata modeling ecosystem by analyzing data from three datasets.} In particular, our goals are to learn about:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Modeling workflow
\item
  Modeling continuous outcomes\\
\item
  Modeling binary outcomes
\item
  Producing regression tables
\item
  Obtaining margins of responses
\item
  Obtaining margins of changes in responses
\end{enumerate}

\end{alert}

\hypertarget{modeling-workflow-1}{%
\section{Modeling workflow}\label{modeling-workflow-1}}

Before we delve into the details of how to fit models in Stata, it's worth taking a step back and thinking more broadly about the components of the modeling process. These can roughly be divided into 3 stages:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Pre-estimation
\item
  Estimation
\item
  Post-estimaton
\end{enumerate}

At each stage, the goal is to complete a different task (e.g., to clean data, fit a model, test a hypothesis),
but the process is sequential --- we move through the stages in order (though often many times in one project!)

\includegraphics{Stata/StataMod/images/Stata_model_pipeline.png}

Throughout this workshop we will go through these stages several times as we fit different types of model.

\hypertarget{before-fitting-a-model-1}{%
\section{Before fitting a model}\label{before-fitting-a-model-1}}

\begin{alert}

\textbf{GOAL: To learn about the data by creating summaries and visualizations.}

\end{alert}

\hypertarget{the-dataset}{%
\subsection{The dataset}\label{the-dataset}}

We have a dataset (\texttt{states.dta}) on a variety of variables for all 50 states. Variables include population, density, energy use, voting tendencies, graduation rates, income, etc.

We're going to ask the question: does the amount of money spent on education (\texttt{expense}), family income(\texttt{income}), and percentage of students taking SATs (\texttt{percent}) affect the mean SAT score (\texttt{csat}) in a state?

\hypertarget{set-working-directory}{%
\subsection{Set working directory}\label{set-working-directory}}

Files are located in the \texttt{dataSets} folder in \texttt{StataMod}. Start by telling Stata where to look for these:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// change directory}
\NormalTok{cd }\StringTok{"\textasciitilde{}/Desktop/Stata/StataMod"}
\end{Highlighting}
\end{Shaded}

Use \texttt{dir} to see what is in the directory:

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{dir}
\NormalTok{cd dataSets}
\end{Highlighting}
\end{Shaded}

\hypertarget{load-the-data-1}{%
\subsection{Load the data}\label{load-the-data-1}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// use the states data set}
\KeywordTok{use}\NormalTok{ dataSets/states.dta}
\end{Highlighting}
\end{Shaded}

\hypertarget{examine-descriptive-statistics}{%
\subsection{Examine descriptive statistics}\label{examine-descriptive-statistics}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// descriptive statistics }
\KeywordTok{sum}\NormalTok{ expense income }\KeywordTok{percent}\NormalTok{ csat}
\end{Highlighting}
\end{Shaded}

\hypertarget{visualize-the-data}{%
\subsection{Visualize the data}\label{visualize-the-data}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// visualize data }
\KeywordTok{scatter}\NormalTok{ expense income}
\KeywordTok{scatter}\NormalTok{ expense }\KeywordTok{percent} 
\end{Highlighting}
\end{Shaded}

\hypertarget{models-with-continuous-outcomes-1}{%
\section{Models with continuous outcomes}\label{models-with-continuous-outcomes-1}}

\begin{alert}

\textbf{GOAL: To learn about the Stata modeling ecosystem by using the \texttt{regress} command to fit ordinary least squares (OLS) models.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Stata syntax for model specification
\item
  Model diagnostics for checking OLS assumptions
\item
  Including interaction terms
\item
  Including categorical predictors
\end{enumerate}

\end{alert}

\hypertarget{fit-the-model}{%
\subsection{Fit the model}\label{fit-the-model}}

To fit a model in Stata, we first have to convert our theoretical model into
Stata syntax --- a symbolic representation of the model:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// model specification}
\NormalTok{command outcome pred1 pred2 pred3}
\end{Highlighting}
\end{Shaded}

Note that immediately after the modeling command comes the outcome variable, followed by numerous predictors.

For example, the following model predicts SAT scores based on the amount of money spent on education (\texttt{expense}), family income(\texttt{income}), and percentage of students taking SATs (\texttt{percent}) in a state. Here's the theoretical model:

\begin{alert}

\[
SATscores_i = \beta_01 + \beta_1expenditures_i + \beta_2income_i +\beta_3SATpercent_i + \epsilon_i
\]

\end{alert}

And here's how we use the \texttt{regress} command to fit this model in Stata:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{regress}\NormalTok{ csat expense income }\KeywordTok{percent} 
\end{Highlighting}
\end{Shaded}

\hypertarget{ols-assumptions}{%
\subsection{OLS assumptions}\label{ols-assumptions}}

OLS regression relies on several assumptions, including:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The model includes all relevant variables (i.e., no omitted variable bias).
\item
  The model is linear in the parameters (i.e., the coefficients and error term).
\item
  The error term has an expected value of zero.
\item
  All right-hand-side variables are uncorrelated with the error term.
\item
  No right-hand-side variables are a perfect linear function of other RHS variables.
\item
  Observations of the error term are uncorrelated with each other.
\item
  The error term has constant variance (i.e., homoscedasticity).
\item
  (Optional - only needed for inference). The error term is normally distributed.
\end{enumerate}

We can investigate assumptions \#7 and \#8 by plotting model diagnostics. A simple histogram of the residuals can be informative:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// graph the residual values of csat}
\KeywordTok{predict} \KeywordTok{resid}\NormalTok{, residual}
\KeywordTok{histogram} \KeywordTok{resid}\NormalTok{, }\FunctionTok{normal} 
\end{Highlighting}
\end{Shaded}

We can also examine homoscedasticity:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rvfplot}\NormalTok{, }\KeywordTok{yline}\NormalTok{(0)}
\end{Highlighting}
\end{Shaded}

Type \texttt{-help\ regress\ postestimation} --- for more information about model diagnostics. If assumptions are not met, alter the specification and refit the model.

\hypertarget{interactions}{%
\subsection{Interactions}\label{interactions}}

What if we wanted to test an interaction between \texttt{percent} and \texttt{high}?

Option 1: generate product terms by hand:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// generate product of percent and high}
\KeywordTok{gen}\NormalTok{ percenthigh = }\KeywordTok{percent}\NormalTok{*high }
\KeywordTok{regress}\NormalTok{ csat expense income }\KeywordTok{percent}\NormalTok{ high percenthigh}
\end{Highlighting}
\end{Shaded}

Option 2: let Stata do your dirty work:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// use the \# sign to represent interactions }
\KeywordTok{regress}\NormalTok{ csat }\KeywordTok{percent}\NormalTok{ high c.percent\#c.high}
\CommentTok{// same as: regress csat c.percent\#\#c.high}
\end{Highlighting}
\end{Shaded}

\hypertarget{categorical-predictors}{%
\subsection{Categorical predictors}\label{categorical-predictors}}

For categorical variables, we first need to dummy code. Let's use \texttt{region} as an example.

Option 1: create dummy codes before fitting regression model:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// create region dummy codes using tab }
\KeywordTok{tab}\NormalTok{ region, }\KeywordTok{gen}\NormalTok{(region)}

\CommentTok{// regress csat on region}
\KeywordTok{regress}\NormalTok{ csat region1 region2 region3}
\end{Highlighting}
\end{Shaded}

Option 2: let Stata do it for you:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// regress csat on region using fvvarlist syntax}
\CommentTok{// see \textasciigrave{}help fvvarlist\textasciigrave{} for details}
\KeywordTok{regress}\NormalTok{ csat i.region}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercise-0-7}{%
\subsection{Exercise 0}\label{exercise-0-7}}

\textbf{Regression with continuous outcomes}

Open the datafile, \texttt{gss.dta}.

Fit an OLS regression model to predict general happiness (\texttt{happy}) based on respondent's sex (\texttt{sex}), marital status (\texttt{marital}), highest year of school completed (\texttt{educ}), and respondent's income for last year (\texttt{rincome}).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Before running the regression, examine descriptive statistics of the variables and generate a few scatterplots.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Run your regression model.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Examine the plausibility of the assumptions of normality and homoscedasticity.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Add on to the regression equation by generating an interaction term between \texttt{sex} and \texttt{educ} and testing the interaction.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 0 Solution}

\begin{alert}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// 1.  Before running the regression, examine descriptive statistics of the variables and generate a few scatterplots.}

\KeywordTok{sum}\NormalTok{ happy educ rincome }
\KeywordTok{tab}\NormalTok{ sex }
\KeywordTok{tab}\NormalTok{ marital }

\KeywordTok{scatter}\NormalTok{ happy rincome}

\CommentTok{// 2.  Run your regression model. }

\KeywordTok{regress}\NormalTok{ happy i.sex educ i.marital rincome}

\CommentTok{// 3.  Examine the plausibility of the assumptions of normality and homoscedasticity. }

\KeywordTok{hist}\NormalTok{ happy, }\FunctionTok{normal} 
\KeywordTok{rvfplot}\NormalTok{,}\KeywordTok{yline}\NormalTok{(0)}

\CommentTok{// 4.  Add on to the regression equation by generating an interaction term between \textasciigrave{}sex\textasciigrave{} and \textasciigrave{}educ\textasciigrave{} and testing the interaction.}

\KeywordTok{regress}\NormalTok{ happy i.sex\#\#c.educ i.marital rincome}
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{models-with-binary-outcomes-1}{%
\section{Models with binary outcomes}\label{models-with-binary-outcomes-1}}

\begin{alert}

\textbf{GOAL: To learn how to use the \texttt{logit} command to model binary outcomes.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Run the model to obtain estimates on the log odds scale
\item
  Transform model coefficients into odds ratios
\end{enumerate}

\end{alert}

\hypertarget{the-dataset-1}{%
\subsection{The Dataset}\label{the-dataset-1}}

Using the \texttt{states.dta} data, we're going to ask the question: does people per square mile (\texttt{density}), percent HS graduates taking SAT (\texttt{percent}), and per pupil expenditures for primary and secondary school (\texttt{expense}) affect the probability of having an SAT score greater than or equal to 1000 (\texttt{sat\_binary})?

\hypertarget{load-the-dataset}{%
\subsection{Load the dataset}\label{load-the-dataset}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// use the states data set}
\KeywordTok{use}\NormalTok{ dataSets/states.dta}
\end{Highlighting}
\end{Shaded}

\hypertarget{recode-the-outcome-variable}{%
\subsection{Recode the outcome variable}\label{recode-the-outcome-variable}}

Recode the composite SAT score (\texttt{csat}) into two categories: \textbf{whether a region's mean SAT score is greater than or equal to 1000, or less than 1000.}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{gen}\NormalTok{ sat\_binary = .}
\KeywordTok{replace}\NormalTok{ sat\_binary = 0 }\KeywordTok{if}\NormalTok{ csat \textless{} 1000}
\KeywordTok{replace}\NormalTok{ sat\_binary = 1 }\KeywordTok{if}\NormalTok{ csat \textgreater{}= 1000}
\end{Highlighting}
\end{Shaded}

\hypertarget{run-summary-statistics}{%
\subsection{Run summary statistics}\label{run-summary-statistics}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tab}\NormalTok{ sat\_binary}
\KeywordTok{sum}\NormalTok{ density }\KeywordTok{percent}\NormalTok{ expense }
\end{Highlighting}
\end{Shaded}

\hypertarget{run-the-logistic-model}{%
\subsection{Run the logistic model}\label{run-the-logistic-model}}

Let's predict the probability of having mean SAT score greater than or equal to 1000 based on \texttt{density}, \texttt{percent}, and \texttt{expense}.

Here's the theoretical model:

\begin{alert}

\[
logit(p(SAT1000_i = 1)) = \beta_{0}1 + \beta_1density_i + \beta_2SATpercent_i + \beta_3expenditures_i 
\]

\end{alert}

where \(logit(\cdot)\) is the non-linear link function that relates a linear expression of the predictors to the expectation of the binary response:

\begin{alert}

\[
logit(p(SAT1000_i = 1)) = ln \left( \frac{p(SAT1000_i = 1)}{1-p(SAT1000_i = 1)} \right) = ln \left( \frac{p(SAT1000_i = 1)}{p(SAT1000_i = 0)} \right)
\]

\end{alert}

And here's how we use the \texttt{logit} command to fit this model in Stata:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// logit regression with estimates on the log odds scale }
\KeywordTok{logit}\NormalTok{ sat\_binary density }\KeywordTok{percent}\NormalTok{ expense}

\CommentTok{// logit regression with estimates on the odds ratio scale }
\KeywordTok{logit}\NormalTok{ sat\_binary density }\KeywordTok{percent}\NormalTok{ expense, }\KeywordTok{or} 
\end{Highlighting}
\end{Shaded}

\hypertarget{exercise-1-8}{%
\subsection{Exercise 1}\label{exercise-1-8}}

\textbf{Regression with binary outcomes}

Use the data file, \texttt{gss.dta}. Examine how age of a respondent (\texttt{age}), highest year of school completed (\texttt{degree}), hours per day watching TV (\texttt{tvhours}), and total family income for last year (\texttt{income}) relate to whether someone uses internet (\texttt{usenet}).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Load the dataset.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Run summary statistics, delete subjects who did not provide an answer to the \texttt{usenet} question.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 1 Solution}

\begin{alert}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// 1.  Load the dataset. }

\KeywordTok{use}\NormalTok{ gss.dta, }\KeywordTok{clear} 

\CommentTok{// 2.  Run summary statistics, delete subjects who did not provide an answer to the \textasciigrave{}usenet\textasciigrave{} question.}

\KeywordTok{tab}\NormalTok{ usenet }
\KeywordTok{drop} \KeywordTok{if}\NormalTok{ usenet == 9}
\KeywordTok{tab}\NormalTok{ degree }
\KeywordTok{sum}\NormalTok{ age tvhours income }
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{exporting-saving-results}{%
\section{Exporting \& saving results}\label{exporting-saving-results}}

\begin{alert}

\textbf{GOAL: To learn how to store and export Stata models.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  How to store results from models
\item
  How to compare models
\item
  How to export Stata model output to Excel
\end{enumerate}

\end{alert}

\hypertarget{storing-results}{%
\subsection{Storing results}\label{storing-results}}

Stata offers several user-friendly options for storing and viewing regression output from multiple models. First, download the necessary packages:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// install outreg2 package}
\KeywordTok{findit}\NormalTok{ outreg2}
\end{Highlighting}
\end{Shaded}

Then store the results of some regression models using the \texttt{estimates} command and \texttt{store} option:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// fit two regression models and store the results}
\KeywordTok{regress}\NormalTok{ csat expense income }\KeywordTok{percent}\NormalTok{ high}
\KeywordTok{estimates} \KeywordTok{store}\NormalTok{ Model1}
  
\KeywordTok{regress}\NormalTok{ csat expense income }\KeywordTok{percent}\NormalTok{ high i.region}
\KeywordTok{estimates} \KeywordTok{store}\NormalTok{ Model2}
\end{Highlighting}
\end{Shaded}

The stored models can be recalled by name using the \texttt{estimates} command and \texttt{replay} option:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// display Model1}
\KeywordTok{estimates} \FunctionTok{replay}\NormalTok{ Model1}
\end{Highlighting}
\end{Shaded}

\hypertarget{comparing-models-1}{%
\subsection{Comparing models}\label{comparing-models-1}}

The stored models can be compared by name using the \texttt{estimates} command and \texttt{table} option. For a more formal comparison, the \texttt{lrtest} command can be used to perform a likelihhod ratio test:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// compare Model1 and Model2 coefficients}
\KeywordTok{estimates} \KeywordTok{table}\NormalTok{ Model1 Model2}

\CommentTok{// compare Model1 and Model2 fit }
\KeywordTok{lrtest}\NormalTok{ Model1 Model2 }
\end{Highlighting}
\end{Shaded}

\hypertarget{exporting-to-excel}{%
\subsection{Exporting to Excel}\label{exporting-to-excel}}

To avoid human error when transferring coefficients into tables, Excel can be used to format publication-ready tables:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{outreg2 [Model1 Model2] }\KeywordTok{using}\NormalTok{ csatprediction.xls, }\KeywordTok{replace}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercise-2-6}{%
\subsection{Exercise 2}\label{exercise-2-6}}

\textbf{Exporting \& saving results}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Fit the logistic model and save it as \texttt{Model1}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Add another predictor (\texttt{hrs1}) in the model and save the new model as \texttt{Model2} and compare between \texttt{Model1} and \texttt{Model2}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Save the output of the better fitted model to a word document.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 2 Solution}

\begin{alert}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// 1.  Fit the logistic model and save it as \textasciigrave{}Model1\textasciigrave{}.  }

\KeywordTok{logit}\NormalTok{ usenet age i.degree tvhours income }
\KeywordTok{est} \KeywordTok{store}\NormalTok{ Model1}

\CommentTok{// 2.  Add another predictor (\textasciigrave{}hrs1\textasciigrave{}) in the model and save the new model as \textasciigrave{}Model2\textasciigrave{} and compare between \textasciigrave{}Model1\textasciigrave{} and \textasciigrave{}Model2\textasciigrave{}. }

\KeywordTok{logit}\NormalTok{ usenet age i.degree tvhours income hrs1}
\KeywordTok{est} \KeywordTok{store}\NormalTok{ Model2 }

\KeywordTok{lrtest}\NormalTok{ Model1 Model2}

\CommentTok{// 3.  Save the better fitted model output to a word document. }

\KeywordTok{logit}\NormalTok{ usenet age i.degree tvhours income hrs1}
\NormalTok{outreg2 }\KeywordTok{using}\NormalTok{ Mymodel.doc}
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{obtaining-quantities-of-interest}{%
\section{Obtaining quantities of interest}\label{obtaining-quantities-of-interest}}

\begin{alert}

\textbf{GOAL: To obtain easy to interpret output from regression models.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Margins of responses (a.k.a. predictive margins)
\item
  Margins of changes of responses (a.k.a. marginal effects)
\item
  Graphs of margins
\end{enumerate}

\end{alert}

The default summary model output that Stata produces is useful and intuitive for relatively simple models, especially if the outcome is continuous. For more complex models, especially non-linear models or those with interactions, the default output only reports a small subset of information from the model and/or presents results on an unintuitive scale. For such models, it is often easier to interpret \textbf{margins} --- specifically, \emph{margins of responses} or \emph{margins of changes in responses}. Margins are statistics calculated from predictions of a previously fit model at fixed values of some covariates and averaging over the remaining covariates. Margins answers the question, \textbf{``What does my model have to say about such-and-such a group or such-and-such a person?''}. It answers this question:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Either conditionally ----- based on fixed values of covariates (e.g., the mean) -\/---- or averaged over the observations in the data.
\item
  In terms of the response given covariate levels (\textbf{margins of responses}), or any other response you can calculate as a function of your estimated parameters -\/---- linear responses, probabilities, hazards, survival times, odds ratios, risk differences. (a.k.a. \emph{predictive margins}, or \emph{adjusted predictions}, or \emph{estimated marginal means}, or \emph{least-squares means}).
\item
  In terms of the \emph{change} in the response for a \emph{change} in covariate levels (\textbf{margins of changes in responses}). (a.k.a. \emph{marginal effects} or \emph{partial effects}).
\item
  Providing standard errors, test statistics, and confidence intervals and those statistics can take the covariates as given or adjust for sampling.
\end{enumerate}

To calculate such effects in Stata, we need a flexible way of obtaining quantities of interest from the model. This is generally done using a \href{https://www.stata.com/manuals13/u20.pdf}{post-estimation tool}. The main post-estimation tool Stata has in its arsenal is the \texttt{margins} command. This is a very flexible tool for producing a variety of quantities of interest from almost all model types that Stata supports. In particular, \texttt{margins} can calculate:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Different types of \emph{margins of responses}:

  \begin{itemize}
  \tightlist
  \item
    \textbf{APM: Average Predictive Margins} (average of the responses among actual people in the data)
  \item
    \textbf{PMM: Predictive Margins at the Means} (expected response for a person with average characteristics)
  \item
    \textbf{PMR: Predictive Margins at Representative values} (expected response across a range of covariate values)
  \end{itemize}
\item
  Difference types of \emph{margins of changes in responses}:

  \begin{itemize}
  \tightlist
  \item
    \textbf{AME: Average Marginal Effects} (average of the changes in responses among actual people in the data)
  \item
    \textbf{MEM: Marginal Effects at the Means} (expected change in response for a person with average characteristics)
  \item
    \textbf{MER: Marginal Effects at Representative values} (expected change in response across a range of covariate values)
  \end{itemize}
\end{enumerate}

The \texttt{margins} command can only be used \emph{after} you've run a regression and acts on the results of the most recent regression command. The \texttt{marginsplot} command can be used to graph any of these margins or comparisons of margins and acts on the results of the most recent \texttt{margins} command.

\hypertarget{margins-of-responses}{%
\section{Margins of responses}\label{margins-of-responses}}

\begin{alert}

\textbf{GOAL: To learn how to produce margins of responses.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  APM: Average Predictive Margins\\
\item
  PMM: Predictive Margins at the Means
\item
  PMR: Predictive Margins at Representative values
\item
  Graph margins of responses
\end{enumerate}

\end{alert}

\hypertarget{the-dataset-2}{%
\subsection{The dataset}\label{the-dataset-2}}

The case study examples use the \texttt{nhanesII} dataset (Second National Health and Nutrition Examination Survey),
which was conducted in the mid to late 1970s. More on the study can be found at \url{https://wwwn.cdc.gov/nchs/nhanes/nhanes2/}. Let's load the data:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use}\NormalTok{ dataSets/nhanesII.dta}
\end{Highlighting}
\end{Shaded}

\hypertarget{fit-a-model}{%
\subsection{Fit a model}\label{fit-a-model}}

We will examine a continuous measure of systolic blood pressure (\texttt{bpsystol}) as a function of a respondent's age (\texttt{age}), whether they have diabetes (\texttt{diabetes}), and what geographical region they come from (\texttt{region}), using OLS regression.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{regress}\NormalTok{ bpsystol age i.diabetes i.region}
\end{Highlighting}
\end{Shaded}

\hypertarget{apm-average-predictive-margins}{%
\subsection{APM: Average Predictive Margins}\label{apm-average-predictive-margins}}

If you just type \texttt{margins} by itself, Stata will calculate the predicted value of the model outcome (\texttt{bpsystol}) for each observation in the data, then report the mean value of those predictions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{margins}
\end{Highlighting}
\end{Shaded}

If \texttt{margins} is followed by a categorical variable, for example, \texttt{region}, Stata first identifies all the levels of the categorical variable. Then, it calculates what the mean predicted value of the model outcome (\texttt{bpsystol}) would be if all observations had that value for \texttt{region}. All other variables are left unchanged.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// margins for dummy variable }
\NormalTok{margins diabetes}

\CommentTok{// margins for multi{-}level categorical variable }
\NormalTok{margins region}
\end{Highlighting}
\end{Shaded}

\hypertarget{pmm-predictive-margins-at-the-means}{%
\subsection{PMM: Predictive Margins at the Means}\label{pmm-predictive-margins-at-the-means}}

By default, \texttt{margins} reports the average of the predictions for each person (i.e., observation) in the data. This is the average response among the actual people in the data. But we can also get \texttt{margins} to report the prediction at the average of the covariates by using the \texttt{atmeans} option. This represents the expected response of a person with average characteristics.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// margins for dummy variable }
\NormalTok{margins diabetes, atmeans}
\end{Highlighting}
\end{Shaded}

\hypertarget{pmr-predictive-margins-at-representative-values}{%
\subsection{PMR: Predictive Margins at Representative values}\label{pmr-predictive-margins-at-representative-values}}

For continuous variables, \texttt{margins} cannot look at all possible values, but we can specify which values we want to examine with the \texttt{at} option:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{margins, }\FunctionTok{at}\NormalTok{(age = (50 80))}
\end{Highlighting}
\end{Shaded}

The previous step calculates the mean predicted value of the model outcome (\texttt{bpsystol}) with \texttt{age} set to 50, and then again with \texttt{age} set to 80. We can also add more values by listing the numbers we want in a \emph{numlist}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// predicted values for ages 50 to 80 in 5 year increments}
\NormalTok{margins, }\FunctionTok{at}\NormalTok{(age=(50(5)80))}
\end{Highlighting}
\end{Shaded}

\hypertarget{graph-margins-of-responses}{%
\subsection{Graph margins of responses}\label{graph-margins-of-responses}}

The previous step calculates the mean predicted value of \texttt{bpsystol} with age set to 50, 55, 60, 65, 70, 75, and 80. We can now use \texttt{marginsplot} to graph the results.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{marginsplot}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercise-3-5}{%
\subsection{Exercise 3}\label{exercise-3-5}}

\textbf{Margins of responses}

Open the datafile \texttt{gss.dta}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Fit an OLS regression model to predict general happiness (\texttt{happy}) based on respondent's sex (\texttt{sex}), marital status (\texttt{marital}), highest year of school completed (\texttt{educ}), and respondent's income for last year (\texttt{rincome}). Obtain average predictive margins for \texttt{happy}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Obtain predictive margins of \texttt{sex} and \texttt{marital}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Obtain predictive margins of \texttt{rincome} from 10000 to 30000, with an interval of 5000.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Create a \texttt{marginsplot} and interpret the results.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\# }
\end{Highlighting}
\end{Shaded}

{Click for Exercise 3 Solution}

\begin{alert}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// 1. Fit an OLS regression model to predict general happiness (\textasciigrave{}happy\textasciigrave{}) based on respondent\textquotesingle{}s sex (\textasciigrave{}sex\textasciigrave{}), marital status (\textasciigrave{}marital\textasciigrave{}), highest year of school completed (\textasciigrave{}educ\textasciigrave{}), and respondent\textquotesingle{}s income for last year (\textasciigrave{}rincome\textasciigrave{}). Obtain average predictive margins for \textasciigrave{}happy\textasciigrave{}.}

\KeywordTok{regress}\NormalTok{ happy i.sex educ i.marital rincome}
\NormalTok{margins }

\CommentTok{// 2. Obtain predictive margins of \textasciigrave{}sex\textasciigrave{} and \textasciigrave{}marital\textasciigrave{}. }

\NormalTok{margins, sex }
\NormalTok{margins, marital}

\CommentTok{// 3. Obtain predictive margins of \textasciigrave{}rincome\textasciigrave{} from 10000 to 30000, with an interval of 5000. }

\NormalTok{margins, }\FunctionTok{at}\NormalTok{(rincome=(10000(5000)30000))}

\CommentTok{// 4. Create a \textasciigrave{}marginsplot\textasciigrave{} and interpret the results. }

\NormalTok{marginsplot }
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{margins-of-changes-in-responses}{%
\section{Margins of changes in responses}\label{margins-of-changes-in-responses}}

\begin{alert}

\textbf{GOAL: To learn how to produce margins of changes in responses.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  AME: Average Marginal Effects
\item
  MEM: Marginal Effects at the Means
\item
  MER: Marginal Effects at Representative values
\item
  Graph margins of changes in responses
\end{enumerate}

\end{alert}

\hypertarget{the-dataset-3}{%
\subsection{The dataset}\label{the-dataset-3}}

We will be using the same dataset as the previous example: the Second National Health and Nutrition Examination Survey (NHANES II). Let's load the data:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use}\NormalTok{ dataSets/nhanesII.dta}
\end{Highlighting}
\end{Shaded}

\hypertarget{fit-a-model-1}{%
\subsection{Fit a model}\label{fit-a-model-1}}

We will predict the probability of someone having diabetes (\texttt{diabetes}), as a function of race (\texttt{black}), sex (\texttt{female}), and age (\texttt{age}), using logistic regression.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{logit}\NormalTok{ diabetes }\BaseNTok{black}\NormalTok{ female age, }\KeywordTok{nolog} 
\end{Highlighting}
\end{Shaded}

\hypertarget{ame-average-marginal-effects}{%
\subsection{AME: Average Marginal Effects}\label{ame-average-marginal-effects}}

We can first obtain the Average Predictive Margins of race (\texttt{black}) and sex (\texttt{female}). Then, we can use the \texttt{dydx} command to estimate changes in the response when the levels of race and sex change. Since, by default, these changes are averaged over each person in the dataset, we obtain Average Marginal Effects. As the current model is logistic, margins automatically back-transforms the APMs and AMEs from the estimation scale (i.e., the log odds scale) to the response scale (i.e., the probability scale).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// obtain Average Predictive Margins }
\NormalTok{margins }\BaseNTok{black}\NormalTok{ female }

\CommentTok{// calculate the average of all the marginal effects }
\NormalTok{margins, }\KeywordTok{dydx}\NormalTok{(}\BaseNTok{black}\NormalTok{ female)}
\end{Highlighting}
\end{Shaded}

\hypertarget{mem-marginal-effects-at-the-mean}{%
\subsection{MEM: Marginal Effects at the Mean}\label{mem-marginal-effects-at-the-mean}}

By default, \texttt{margins} with the \texttt{dydx} command reports the average of the changes in the probability of the response among actual people in the data. But we can also get margins to report the expected change in the probability of the response for a person with average characteristics by using the \texttt{atmeans} option.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// obtain Predictive Margins at the Means}
\NormalTok{margins }\BaseNTok{black}\NormalTok{ female, atmeans}

\CommentTok{// calculate marginal effects with all other covariates fixed at their sample means }
\NormalTok{margins, }\KeywordTok{dydx}\NormalTok{(}\BaseNTok{black}\NormalTok{ female) atmeans}
\end{Highlighting}
\end{Shaded}

\hypertarget{mer-marginal-effects-at-representative-values}{%
\subsection{MER: Marginal Effects at Representative values}\label{mer-marginal-effects-at-representative-values}}

For continuous variables, \texttt{margins} needs us to specify which values we want to examine using the \texttt{at} option. We can calculate the change in the probability of the model outcome (\texttt{diabetes}) when levels of race (\texttt{black}) and sex (\texttt{female}) change, across a range of values for \texttt{age} by supplying a list of numbers to a \emph{numlist}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// obtain Predictive Margins at Representative values}
\CommentTok{// choose range of values for one or more variables}
\CommentTok{// note: the \textasciigrave{}vsquish\textasciigrave{} option omits vertical white space between results}
\NormalTok{margins }\BaseNTok{black}\NormalTok{, }\FunctionTok{at}\NormalTok{(age=(20 30 40 50 60 70)) vsquish }

\CommentTok{// calculate marginal effects across that range }
\NormalTok{margins, }\KeywordTok{dydx}\NormalTok{(}\BaseNTok{black}\NormalTok{ female) }\FunctionTok{at}\NormalTok{(age=(20 30 40 50 60 70)) vsquish }
\end{Highlighting}
\end{Shaded}

\hypertarget{graph-margins-of-changes-in-responses}{%
\subsection{Graph margins of changes in responses}\label{graph-margins-of-changes-in-responses}}

The previous step calculates the average change in the predicted probability of \texttt{diabetes}, when levels of race (\texttt{black}) and sex (\texttt{female}) change, with age set to 20, 30, 40, 50, 60, and 70. We can now use \texttt{marginsplot} to graph the results.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{marginsplot}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercise-4-2}{%
\subsection{Exercise 4}\label{exercise-4-2}}

\textbf{Margins of changes in responses}

Open the datafile \texttt{gss.dta}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Fit a logistic model to examine how whether someone uses internet (\texttt{usenet}) is related to age of the respondent (\texttt{age}), highest year of school completed (\texttt{degree}), hours per day watching TV (\texttt{tvhours}), and total family income for last year (\texttt{income}). Obtain Average Predictive Margins and Average Marginal Effects for \texttt{degree}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\# }
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Obtain Predictive Margins of \texttt{degree} at Representative values of \texttt{tvhours} from 0 to 10 hours, on a 1 hour interval. Examine how the marginal effect of \texttt{degree} differs across the range of \texttt{tvhours} (i.e., obtain Marginal Effects at Representative values).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Create a \texttt{marginsplot} for the marginal effects from \#2.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 4 Solution}

\begin{alert}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// 1. Fit a logistic model to examine how whether someone uses internet (\textasciigrave{}usenet\textasciigrave{}) is related to age of the respondent (\textasciigrave{}age\textasciigrave{}), highest year of school completed (\textasciigrave{}degree\textasciigrave{}), hours per day watching TV (\textasciigrave{}tvhours\textasciigrave{}), and total family income for last year (\textasciigrave{}income\textasciigrave{}). Obtain Average Predictive Margins and Average Marginal Effects for \textasciigrave{}degree\textasciigrave{}.}

\KeywordTok{logit}\NormalTok{ usenet age i.degree tvhours income }

\NormalTok{margins degree}
\NormalTok{margins, }\KeywordTok{dydx}\NormalTok{(degree)}

\CommentTok{// 2. Obtain Predictive Margins of \textasciigrave{}degree\textasciigrave{} at Representative values of \textasciigrave{}tvhours\textasciigrave{} from 0 to 10 hours, on a 1 hour interval. Examine how the marginal effect of \textasciigrave{}degree\textasciigrave{} differs across the range of \textasciigrave{}tvhours\textasciigrave{} (i.e., obtain Marginal Effects at Representative values). }

\NormalTok{margins degree, }\FunctionTok{at}\NormalTok{(tvhours=(0 1 2 3 4 5 6 7 8 9 10) vsquish }
\NormalTok{margins, }\KeywordTok{dydx}\NormalTok{(degree) }\FunctionTok{at}\NormalTok{(tvhours=(0 1 2 3 4 5 6 7 8 9 10)) vsquish }

\CommentTok{// 3. Create a \textasciigrave{}marginsplot\textasciigrave{} for the marginal effects from \#2. }
\NormalTok{marginsplot}
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{wrap-up-9}{%
\section{Wrap-up}\label{wrap-up-9}}

\hypertarget{feedback-9}{%
\subsection{Feedback}\label{feedback-9}}

These workshops are a work in progress, please provide any feedback to: \href{mailto:help@iq.harvard.edu}{\nolinkurl{help@iq.harvard.edu}}

\hypertarget{resources-12}{%
\subsection{Resources}\label{resources-12}}

\begin{itemize}
\tightlist
\item
  IQSS

  \begin{itemize}
  \tightlist
  \item
    Workshops: \url{https://dss.iq.harvard.edu/workshop-materials}
  \item
    Data Science Services: \url{https://dss.iq.harvard.edu/}
  \item
    Research Computing Environment: \url{https://iqss.github.io/dss-rce/}
  \end{itemize}
\item
  HBS

  \begin{itemize}
  \tightlist
  \item
    Research Computing Services workshops: \url{https://training.rcs.hbs.org/workshops}
  \item
    Other HBS RCS resources: \url{https://training.rcs.hbs.org/workshop-materials}
  \item
    RCS consulting email: \url{mailto:research@hbs.edu}
  \end{itemize}
\item
  Stata

  \begin{itemize}
  \tightlist
  \item
    UCLA website: \url{http://www.ats.ucla.edu/stat/Stata/}
  \item
    Stata website: \url{http://www.stata.com/help.cgi?contents}
  \item
    Email list: \url{http://www.stata.com/statalist/}
  \end{itemize}
\end{itemize}

\hypertarget{stata-graphics}{%
\chapter{Stata Graphics}\label{stata-graphics}}

\textbf{Topics}

\begin{itemize}
\tightlist
\item
  Univariate graphs
\item
  Bivariate graphs
\end{itemize}

\hypertarget{setup-9}{%
\section{Setup}\label{setup-9}}

\hypertarget{class-structure-and-organization-3}{%
\subsection{Class structure and organization}\label{class-structure-and-organization-3}}

\begin{itemize}
\tightlist
\item
  Please feel free to ask questions at any point if they are relevant to the current topic (or if you are lost!)
\item
  Collaboration is encouraged - please introduce yourself to your neighbors!
\item
  If you are using a laptop, you will need to adjust file paths accordingly
\item
  Make comments in your Do-file - save on flash drive or email to yourself
\end{itemize}

\hypertarget{prerequisites-9}{%
\subsection{Prerequisites}\label{prerequisites-9}}

This is an intermediate-level Stata graphics workshop

\begin{itemize}
\tightlist
\item
  Assumes basic knowledge of Stata
\item
  Not appropriate for people already well familiar with graphing in Stata
\item
  If you are catching on before the rest of the class, experiment with command features described in help files
\end{itemize}

\hypertarget{goals-8}{%
\subsection{Goals}\label{goals-8}}

\begin{alert}

\textbf{We will learn about Stata graphics by practicing graphing using two real datasets.} In particular, our goals are to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Plot basic graphs in Stata
\item
  Plot two-way graphs in Stata
\end{enumerate}

\end{alert}

\hypertarget{graphing-in-stata}{%
\section{Graphing in Stata}\label{graphing-in-stata}}

\begin{alert}

\textbf{GOAL: To get familiar with how to produce graphs in Stata.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Learn about graphing strategies
\item
  Compare two examples of a bad graph and a good graph
\end{enumerate}

\end{alert}

\hypertarget{graphing-strategies}{%
\subsection{Graphing strategies}\label{graphing-strategies}}

\begin{itemize}
\tightlist
\item
  Keep it simple
\item
  Labels, labels, labels!!
\item
  Avoid cluttered graphs
\item
  Every part of the graph should be meaningful
\item
  Avoid:

  \begin{itemize}
  \tightlist
  \item
    Shading
  \item
    Distracting colors
  \item
    Decoration
  \end{itemize}
\item
  Always know what you are working with before you get started

  \begin{itemize}
  \tightlist
  \item
    Recognize scale of data
  \item
    If you are using multiple variables, how do their scales align?
  \end{itemize}
\item
  Before any graphing procedure review variables with \texttt{codebook}, \texttt{sum}, \texttt{tab}, etc.
\item
  HELPFUL STATA HINT: If you want your command to go on multiple lines use \texttt{///} at end of each line
\end{itemize}

\hypertarget{terrible-graph}{%
\subsection{Terrible graph}\label{terrible-graph}}

\includegraphics{Stata/StataGraph/images/Terrible.png}

\hypertarget{much-better-graph}{%
\subsection{Much better graph}\label{much-better-graph}}

\includegraphics{Stata/StataGraph/images/Good.png}

\hypertarget{univariate-graphics}{%
\section{Univariate graphics}\label{univariate-graphics}}

\begin{alert}

\textbf{GOAL: To learn how to graph a single continuous and categorical variable.} In particular:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Graph a continuous variable using a histogram
\item
  Graph a categorical variable using a bar graph
\end{enumerate}

\end{alert}

\hypertarget{our-first-dataset}{%
\subsection{Our first dataset}\label{our-first-dataset}}

\begin{itemize}
\tightlist
\item
  Time Magazine Public School Poll

  \begin{itemize}
  \tightlist
  \item
    Based on survey of 1,000 adults in U.S.
  \item
    Conducted in August 2010
  \item
    Questions regarding feelings about parental involvement, teachers union, current potential for reform
  \end{itemize}
\item
  Open Stata and call up the datafile for today
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Step 1: tell Stata where to find data:}
\NormalTok{cd }\StringTok{"\textasciitilde{}/StataGraphics/dataSets"}

\CommentTok{// Step 2: call up our dataset:}
\KeywordTok{use}\NormalTok{ TimePollPubSchools.dta}
\end{Highlighting}
\end{Shaded}

\hypertarget{single-continuous-variable}{%
\subsection{Single continuous variable}\label{single-continuous-variable}}

\textbf{Example: Histogram}

\begin{itemize}
\tightlist
\item
  Stata assumes you are working with continuous data
\item
  Very simple syntax:

  \begin{itemize}
  \tightlist
  \item
    \texttt{hist\ varname}
  \end{itemize}
\item
  Put a comma after your varname and start adding options

  \begin{itemize}
  \tightlist
  \item
    \texttt{bin(\#)} : change the number of bars that the graph displays
  \item
    \texttt{normal} : overlay normal curve
  \item
    \texttt{addlabels} : add actual values to bars
  \end{itemize}
\end{itemize}

\textbf{Histogram options}

\begin{itemize}
\tightlist
\item
  To change the numeric depiction of your data add these options after the comma

  \begin{itemize}
  \tightlist
  \item
    Choose one: \texttt{density}, \texttt{fraction}, \texttt{frequency}, \texttt{percent}
  \end{itemize}
\item
  Be sure to properly describe your histogram:

  \begin{itemize}
  \tightlist
  \item
    \texttt{title("insert\ name\ of\ graph")}
  \item
    \texttt{subtitle("insert\ subtitle\ of\ graph")}
  \item
    \texttt{note("insert\ note\ to\ appear\ at\ bottom\ of\ graph")}
  \item
    \texttt{caption("insert\ caption\ to\ appear\ below\ notes")}
  \end{itemize}
\end{itemize}

\textbf{Histogram example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{ F1, }\BaseNTok{bin}\NormalTok{(10) }\KeywordTok{percent} \BaseNTok{title}\NormalTok{(}\StringTok{"TITLE"}\NormalTok{) }\CommentTok{///}
  \BaseNTok{subtitle}\NormalTok{(}\StringTok{"SUBTITLE"}\NormalTok{) }\BaseNTok{caption}\NormalTok{(}\StringTok{"CAPTION"}\NormalTok{) }\KeywordTok{note}\NormalTok{(}\StringTok{"NOTES"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Stata/StataGraph/images/hist1.png}

\textbf{Axis titles \& labels}

\begin{itemize}
\tightlist
\item
  Axis title options (default is variable label):

  \begin{itemize}
  \tightlist
  \item
    \texttt{xtitle("insert\ x\ axis\ name")}
  \item
    \texttt{ytitle("insert\ y\ axis\ name")}
  \end{itemize}
\item
  Don't want axis titles?

  \begin{itemize}
  \tightlist
  \item
    \texttt{xtitle("")}
  \item
    \texttt{ytitle("")}
  \end{itemize}
\item
  Add labels to X or Y axis:

  \begin{itemize}
  \tightlist
  \item
    \texttt{xlabel("insert\ x\ axis\ label")}
  \item
    \texttt{ylabel("insert\ y\ axis\ label")}
  \end{itemize}
\item
  Tell Stata how to scale each axis

  \begin{itemize}
  \tightlist
  \item
    \texttt{xlabel("start\textbackslash{}\#(increment)end\textbackslash{}\#")}
  \item
    \texttt{xlabel(0(5)100)} This would label x-axis from 0-100 in increments of 5
  \end{itemize}
\end{itemize}

\textbf{Axis labels example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{ F1, }\BaseNTok{bin}\NormalTok{(10) }\KeywordTok{percent} \BaseNTok{title}\NormalTok{(}\StringTok{"TITLE"}\NormalTok{) }\BaseNTok{subtitle}\NormalTok{(}\StringTok{"SUBTITLE"}\NormalTok{) }\CommentTok{///}
    \BaseNTok{caption}\NormalTok{(}\StringTok{"CAPTION"}\NormalTok{) }\KeywordTok{note}\NormalTok{(}\StringTok{"NOTES"}\NormalTok{) }\CommentTok{///}
    \BaseNTok{xtitle}\NormalTok{(}\StringTok{"Here\textquotesingle{}s your x{-}axis title"}\NormalTok{) }\CommentTok{///}
    \BaseNTok{ytitle}\NormalTok{(}\StringTok{"here\textquotesingle{}s your y{-}axis title"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Stata/StataGraph/images/hist2.png}

\hypertarget{single-categorical-variable}{%
\subsection{Single categorical variable}\label{single-categorical-variable}}

\begin{itemize}
\tightlist
\item
  We can also use the \texttt{hist} command for bar graphs

  \begin{itemize}
  \tightlist
  \item
    Simply specify the option \texttt{discrete}
  \end{itemize}
\item
  Stata will produce one bar for each level (i.e.~category) of variable
\item
  Use \texttt{xlabel} command to insert names of individual categories
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{ F4, }\BaseNTok{title}\NormalTok{(}\StringTok{"Racial breakdown of Time Poll Sample"}\NormalTok{) }\BaseNTok{xtitle}\NormalTok{(}\StringTok{"Race"}\NormalTok{) }\CommentTok{///}
   \BaseNTok{ytitle}\NormalTok{(}\StringTok{"Percent"}\NormalTok{) }\KeywordTok{xlabel}\NormalTok{(1 }\StringTok{"White"}\NormalTok{ 2 }\StringTok{"Black"}\NormalTok{ 3 }\StringTok{"Asian"}\NormalTok{ 4 }\StringTok{"Hispanic"} \CommentTok{///}
\NormalTok{   5 }\StringTok{"Other"}\NormalTok{) discrete }\KeywordTok{percent} \BaseNTok{addlabels}
\end{Highlighting}
\end{Shaded}

\includegraphics{Stata/StataGraph/images/bargraph.png}

\hypertarget{exercise-0-8}{%
\subsection{Exercise 0}\label{exercise-0-8}}

\textbf{Histograms \& bar graphs}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Open the datafile, \texttt{NatNeighCrimeStudy.dta}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Create a histogram of the tract-level poverty rate (\texttt{T\_POVRTY}).
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Insert the normal curve over the histogram.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Change the numeric representation on the Y-axis to \texttt{percent}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Add appropriate titles to the overall graph and the x axis and y axis. Also, add a note that states the source of this data.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Open the datafile, \texttt{TimePollPubSchools.dta}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Create a histogram of the question, ``What grade would you give your child's school'' (\texttt{Q11}). Be sure to tell Stata that this is a categorical variable.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Format this graph so that the axes have proper titles and labels. Also, add an appropriate title to the overall graph. Add a note stating the source of the data.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 0 Solution}

\begin{alert}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// 1.  Open the datafile, \textasciigrave{}NatNeighCrimeStudy.dta\textasciigrave{}.}
\KeywordTok{use}\NormalTok{ NatNeighCrimeStudy.dta, }\KeywordTok{clear}

\CommentTok{// 2.  Create a histogram of the tract{-}level poverty rate (\textasciigrave{}T\_POVRTY\textasciigrave{}).}
\KeywordTok{hist}\NormalTok{ T\_POVRTY}

\CommentTok{// 3.  Insert the normal curve over the histogram.}
\KeywordTok{hist}\NormalTok{ T\_POVRTY, }\FunctionTok{normal}

\CommentTok{// 4.  Change the numeric representation on the Y{-}axis to \textasciigrave{}percent\textasciigrave{}.}
\KeywordTok{hist}\NormalTok{ T\_POVRTY, }\FunctionTok{normal} \KeywordTok{percent}

\CommentTok{// 5.  Add appropriate titles to the overall graph and the x axis and y axis. Also, add a note that states the source of this data.}
\KeywordTok{hist}\NormalTok{ T\_POVRTY, }\FunctionTok{normal} \KeywordTok{percent} \BaseNTok{title}\NormalTok{(}\StringTok{"Poverty Rate Distribution Among Study Participants"}\NormalTok{) }\BaseNTok{xtitle}\NormalTok{(}\StringTok{"Poverty Rate"}\NormalTok{) }\BaseNTok{ytitle}\NormalTok{(}\StringTok{"Percent"}\NormalTok{) }\KeywordTok{note}\NormalTok{(}\StringTok{"Notes: Results are based on raw data"}\NormalTok{)}

\CommentTok{// 6.  Open the datafile, \textasciigrave{}TimePollPubSchools.dta\textasciigrave{}.}
\KeywordTok{use}\NormalTok{ TimePollPubSchools.dta, }\KeywordTok{clear}

\CommentTok{// 7.  Create a histogram of the question, "What grade would you give your child\textquotesingle{}s school" (\textasciigrave{}Q11\textasciigrave{}). Be sure to tell Stata that this is a categorical variable.}
\KeywordTok{hist}\NormalTok{ Q11, discrete}

\CommentTok{// 8.  Format this graph so that the axes have proper titles and labels. Also, add an appropriate title to the overall graph. Add a note stating the source of the data.}
\KeywordTok{hist}\NormalTok{ Q11, }\BaseNTok{title}\NormalTok{(}\StringTok{"School grading breakdown of Time Poll Sample"}\NormalTok{) }\BaseNTok{xtitle}\NormalTok{(}\StringTok{"Grades"}\NormalTok{) }\BaseNTok{ytitle}\NormalTok{(}\StringTok{"Percent"}\NormalTok{) }\KeywordTok{xlabel}\NormalTok{(1 }\StringTok{"A"}\NormalTok{ 2 }\StringTok{"B"}\NormalTok{ 3 }\StringTok{"C"}\NormalTok{ 4 }\StringTok{"D"}\NormalTok{ 5 }\StringTok{"F"}\NormalTok{) }\KeywordTok{note}\NormalTok{(}\StringTok{"Notes: Data is based on a survey of 1000 adults in U.S. conducted in 2010"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{bivariate-graphics}{%
\section{Bivariate graphics}\label{bivariate-graphics}}

\begin{alert}

\textbf{GOAL: To learn how to produce two-way bivariate graphs.} In particular, to learn:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The \texttt{twoway} command
\item
  The \texttt{twoway} \texttt{title} options
\item
  The \texttt{twoway} \texttt{symbol} options
\item
  How to overlay \texttt{twoway} graphs
\end{enumerate}

\end{alert}

\hypertarget{next-dataset}{%
\subsection{Next dataset}\label{next-dataset}}

\begin{itemize}
\tightlist
\item
  National Neighborhood Crime Study (NNCS)

  \begin{itemize}
  \tightlist
  \item
    N=9593 census tracts in 2000
  \item
    Explore sources of variation in crime for communities in the United States
  \item
    Tract-level data: crime, social disorganization, disadvantage, socioeconomic inequality
  \item
    City-level data: labor market, socioeconomic inequality, population change
  \end{itemize}
\end{itemize}

\hypertarget{the-twoway-family}{%
\subsection{\texorpdfstring{The \texttt{twoway} family}{The twoway family}}\label{the-twoway-family}}

\begin{itemize}
\tightlist
\item
  \texttt{twoway} is basic Stata command for all two-way graphs
\item
  Use \texttt{twoway} anytime you want to make comparisons among variables
\item
  Can be used to combine graphs (i.e., overlay one graph with another)

  \begin{itemize}
  \tightlist
  \item
    e.g., insert line of best fit over a scatter plot
  \end{itemize}
\item
  Some basic examples:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use}\NormalTok{ NatNeighCrimeStudy.dta, }\KeywordTok{clear}

\KeywordTok{twoway} \KeywordTok{scatter}\NormalTok{ T\_PERCAP T\_VIOLNT}
\KeywordTok{twoway} \BaseNTok{dropline}\NormalTok{ T\_PERCAP T\_VIOLNT}
\KeywordTok{twoway}\NormalTok{ lfitci T\_PERCAP T\_VIOLNT}
\end{Highlighting}
\end{Shaded}

\textbf{Twoway \& the \texttt{by} statement}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{twoway} \KeywordTok{scatter}\NormalTok{ T\_PERCAP T\_VIOLNT, }\KeywordTok{by}\NormalTok{(DIVISION)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Stata/StataGraph/images/twowayby.png}

\textbf{Twoway title options}

\begin{itemize}
\tightlist
\item
  Same title options as with histogram

  \begin{itemize}
  \tightlist
  \item
    \texttt{title("insert\ name\ of\ graph")}
  \item
    \texttt{subtitle("insert\ subtitle\ of\ graph")}
  \item
    \texttt{note("insert\ note\ to\ appear\ at\ bottom\ of\ graph")}
  \item
    \texttt{caption("insert\ caption\ to\ appear\ below\ notes")}
  \end{itemize}
\end{itemize}

\textbf{Twoway title options example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{twoway} \KeywordTok{scatter}\NormalTok{ T\_PERCAP T\_VIOLNT, }\CommentTok{///}
    \BaseNTok{title}\NormalTok{(}\StringTok{"Comparison of Per Capita Income"} \CommentTok{///}
          \StringTok{"and Violent Crime Rate at Tract level"}\NormalTok{) }\CommentTok{///}
    \BaseNTok{xtitle}\NormalTok{(}\StringTok{"Violent Crime Rate"}\NormalTok{) }\BaseNTok{ytitle}\NormalTok{(}\StringTok{"Per Capita Income"}\NormalTok{) }\CommentTok{///}
    \KeywordTok{note}\NormalTok{(}\StringTok{"Source: National Neighborhood Crime Study 2000"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Twoway symbol options}

\begin{itemize}
\tightlist
\item
  A variety of symbol shapes are available: use \texttt{palette\ symbolpalette} to see them and \texttt{msymbol()} to set them
\end{itemize}

\includegraphics{Stata/StataGraph/images/Symbol.png}

\textbf{Twoway symbol options example}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{twoway} \KeywordTok{scatter}\NormalTok{ T\_PERCAP T\_VIOLNT, }\CommentTok{///}
    \BaseNTok{title}\NormalTok{(}\StringTok{"Comparison of Per Capita Income"} \CommentTok{///}
          \StringTok{"and Violent Crime Rate at Tract level"}\NormalTok{) }\CommentTok{///}
    \BaseNTok{xtitle}\NormalTok{(}\StringTok{"Violent Crime Rate"}\NormalTok{) }\BaseNTok{ytitle}\NormalTok{(}\StringTok{"Per Capita Income"}\NormalTok{) }\CommentTok{///}
    \KeywordTok{note}\NormalTok{(}\StringTok{"Source: National Neighborhood Crime Study 2000"}\NormalTok{) }\CommentTok{///}
    \BaseNTok{msymbol}\NormalTok{(Sh) mcolor(}\StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Stata/StataGraph/images/msymbol_mcolor.png}

\hypertarget{overlaying-twoway-graphs}{%
\subsection{Overlaying twoway graphs}\label{overlaying-twoway-graphs}}

\begin{itemize}
\tightlist
\item
  Very simple to combine multiple graphs by just putting each graph command in parentheses

  \begin{itemize}
  \tightlist
  \item
    \texttt{twoway\ (scatter\ var1\ var2)\ (lfit\ var1\ var2)}
  \end{itemize}
\item
  Add individual options to each graph within the parentheses
\item
  Add overall graph options as usual following the comma

  \begin{itemize}
  \tightlist
  \item
    \texttt{twoway\ (scatter\ var1\ var2)\ (lfit\ var1\ var2),\ options}
  \end{itemize}
\end{itemize}

\textbf{Overlaying points \& lines}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{twoway}\NormalTok{ (}\KeywordTok{scatter}\NormalTok{ T\_PERCAP T\_VIOLNT) }\CommentTok{///}
\NormalTok{    (}\KeywordTok{lfit}\NormalTok{ T\_PERCAP T\_VIOLNT), }\CommentTok{///}
    \BaseNTok{title}\NormalTok{(}\StringTok{"Comparison of Per Capita Income"} \CommentTok{///}
          \StringTok{"and Violent Crime Rate at Tract level"}\NormalTok{) }\CommentTok{///}
    \BaseNTok{xtitle}\NormalTok{(}\StringTok{"Violent Crime Rate"}\NormalTok{) }\BaseNTok{ytitle}\NormalTok{(}\StringTok{"Per Capita Income"}\NormalTok{) }\CommentTok{///}
    \KeywordTok{note}\NormalTok{(}\StringTok{"Source: National  Neighborhood Crime Study 2000"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\textbf{Overlaying points \& labels}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{twoway}\NormalTok{ (}\KeywordTok{scatter}\NormalTok{ T\_PERCAP T\_VIOLNT }\KeywordTok{if}\NormalTok{ T\_VIOLNT==1976, }\CommentTok{///}
    \BaseNTok{mlabel}\NormalTok{(}\StringTok{"CITY"}\NormalTok{)) (}\KeywordTok{scatter}\NormalTok{ T\_PERCAP T\_VIOLNT), }\CommentTok{///}
    \BaseNTok{title}\NormalTok{(}\StringTok{"Comparison of Per Capita Income"} \CommentTok{///}
          \StringTok{"and Violent Crime Rate at Tract level"}\NormalTok{) }\CommentTok{///}
    \KeywordTok{xlabel}\NormalTok{(0(200)2400) }\KeywordTok{note}\NormalTok{(}\StringTok{"Source: National Neighborhood"} \CommentTok{///}
                            \StringTok{"Crime Study 2000"}\NormalTok{) }\BaseNTok{legend}\NormalTok{(}\KeywordTok{off}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{twoway-line-graphs}{%
\subsection{Twoway line graphs}\label{twoway-line-graphs}}

\begin{itemize}
\tightlist
\item
  Line graphs helpful for a variety of data

  \begin{itemize}
  \tightlist
  \item
    Especially any type of time series data
  \end{itemize}
\item
  We will use data on US life expectancy from 1900-1999

  \begin{itemize}
  \tightlist
  \item
    \texttt{webuse\ uslifeexp,\ clear}
  \end{itemize}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{webuse}\NormalTok{ uslifeexp, }\KeywordTok{clear}
\KeywordTok{twoway}\NormalTok{ (}\KeywordTok{line}\NormalTok{ le\_wm }\FunctionTok{year}\NormalTok{, mcolor(}\StringTok{"red"}\NormalTok{)) }\CommentTok{///}
\NormalTok{       (}\KeywordTok{line}\NormalTok{ le\_bm }\FunctionTok{year}\NormalTok{, mcolor(}\StringTok{"green"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{Stata/StataGraph/images/linegraph1.png}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{twoway}\NormalTok{ (}\KeywordTok{line}\NormalTok{ (le\_wfemale le\_wmale le\_bf le\_bm) }\FunctionTok{year}\NormalTok{, }\CommentTok{///}
\NormalTok{       lpattern(}\BaseNTok{dot}\NormalTok{ solid }\BaseNTok{dot}\NormalTok{ solid))}
\end{Highlighting}
\end{Shaded}

\includegraphics{Stata/StataGraph/images/linegraph2.png}

\hypertarget{stata-graphing-lines}{%
\subsection{Stata graphing lines}\label{stata-graphing-lines}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{palette}\NormalTok{ linepalette}
\end{Highlighting}
\end{Shaded}

\includegraphics{Stata/StataGraph/images/linepalette.png}

\hypertarget{exercise-1-9}{%
\subsection{Exercise 1}\label{exercise-1-9}}

\textbf{The \texttt{twoway} family}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Open the datafile, \texttt{NatNeighCrimeStudy.dta}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Create a basic twoway scatterplot that compares the city unemployment rate (\texttt{C\_UNEMP}) to the percent secondary sector low-wage jobs (\texttt{C\_SSLOW})
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Generate the same scatterplot, but this time, divide the plot by the dummy variable indicating whether the city is located in the south or not (\texttt{C\_SOUTH})
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Change the color of the symbol that you use in this scatter plot
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Change the type of symbol you use to a marker of your choice
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Notice in your scatterplot that is broken down by \texttt{C\_SOUTH} that there is an outlier in the upper right hand corner of the ``Not South'' graph. Add the city name label to this marker.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#\#}
\end{Highlighting}
\end{Shaded}

{Click for Exercise 1 Solution}

\begin{alert}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// 1. Open the datafile, \textasciigrave{}NatNeighCrimeStudy.dta\textasciigrave{}.}
\KeywordTok{use}\NormalTok{ NatNeighCrimeStudy.dta, }\KeywordTok{clear}

\CommentTok{// 2.  Create a basic twoway scatterplot that compares the city unemployment rate (\textasciigrave{}C\_UNEMP\textasciigrave{}) to the percent secondary sector low{-}wage jobs (\textasciigrave{}C\_SSLOW\textasciigrave{})}
\KeywordTok{twoway} \KeywordTok{scatter}\NormalTok{ C\_UNEMP C\_SSLOW}

\CommentTok{// 3. Generate the same scatterplot, but this time, divide the plot by the dummy variable indicating whether the city is located in the south or not (\textasciigrave{}C\_SOUTH\textasciigrave{})}
\KeywordTok{twoway} \KeywordTok{scatter}\NormalTok{ C\_UNEMP C\_SSLOW, }\KeywordTok{by}\NormalTok{(C\_SOUTH)}

\CommentTok{// 4.  Change the color of the symbol that you use in this scatter plot}
\KeywordTok{twoway} \KeywordTok{scatter}\NormalTok{ C\_UNEMP C\_SSLOW, }\KeywordTok{by}\NormalTok{(C\_SOUTH) mcolor(}\StringTok{"orange"}\NormalTok{)}

\CommentTok{// 5.  Change the type of symbol you use to a marker of your choice}
\KeywordTok{twoway} \KeywordTok{scatter}\NormalTok{ C\_UNEMP C\_SSLOW, }\KeywordTok{by}\NormalTok{(C\_SOUTH) mcolor(}\StringTok{"orange"}\NormalTok{) }\BaseNTok{msymbol}\NormalTok{(diamond)}

\CommentTok{// 6.  Notice in your scatterplot that is broken down by \textasciigrave{}C\_SOUTH\textasciigrave{} that there is an outlier in the upper right hand corner of the "Not South" graph. Add the city name label to this marker.}
\KeywordTok{twoway} \KeywordTok{scatter}\NormalTok{ C\_UNEMP C\_SSLOW, }\KeywordTok{by}\NormalTok{(C\_SOUTH) }\KeywordTok{if}\NormalTok{ C\_UNEMP\textgreater{}25 mcolor(}\StringTok{"orange"}\NormalTok{) }\BaseNTok{msymbol}\NormalTok{(diamond) }\BaseNTok{mlabel}\NormalTok{(CITY)}
\KeywordTok{twoway}\NormalTok{ (}\KeywordTok{scatter}\NormalTok{ C\_UNEMP C\_SSLOW }\KeywordTok{if}\NormalTok{ T\_UNEMP\textgreater{}15 \& C\_SSLOW\textgreater{}25, }\BaseNTok{mlabel}\NormalTok{(CITY) }\KeywordTok{by}\NormalTok{(C\_SOUTH)) (}\KeywordTok{scatter}\NormalTok{ C\_UNEMP C\_SSLOW, }\KeywordTok{by}\NormalTok{(C\_SOUTH))}
\end{Highlighting}
\end{Shaded}

\end{alert}

\hypertarget{exporting-graphs}{%
\section{Exporting graphs}\label{exporting-graphs}}

\begin{alert}

\textbf{GOAL: To learn how to export graphs in Stata.}

\end{alert}

\begin{itemize}
\tightlist
\item
  From Stata, right click on image and select ``save as'' or try syntax:

  \begin{itemize}
  \tightlist
  \item
    \texttt{graph\ export\ myfig.esp,\ replace}
  \end{itemize}
\item
  In Microsoft Word: insert -\textgreater{} picture -\textgreater{} from file

  \begin{itemize}
  \tightlist
  \item
    Or, right click on graph in Stata and copy and paste into MS Word
  \end{itemize}
\end{itemize}

\hypertarget{wrap-up-10}{%
\section{Wrap-up}\label{wrap-up-10}}

\hypertarget{feedback-10}{%
\subsection{Feedback}\label{feedback-10}}

These workshops are a work in progress, please provide any feedback to: \href{mailto:help@iq.harvard.edu}{\nolinkurl{help@iq.harvard.edu}}

\hypertarget{resources-13}{%
\subsection{Resources}\label{resources-13}}

\begin{itemize}
\tightlist
\item
  IQSS

  \begin{itemize}
  \tightlist
  \item
    Workshops: \url{https://dss.iq.harvard.edu/workshop-materials}
  \item
    Data Science Services: \url{https://dss.iq.harvard.edu/}
  \item
    Research Computing Environment: \url{https://iqss.github.io/dss-rce/}
  \end{itemize}
\item
  HBS

  \begin{itemize}
  \tightlist
  \item
    Research Computing Services workshops: \url{https://training.rcs.hbs.org/workshops}
  \item
    Other HBS RCS resources: \url{https://training.rcs.hbs.org/workshop-materials}
  \item
    RCS consulting email: \url{mailto:research@hbs.edu}
  \end{itemize}
\item
  Stata

  \begin{itemize}
  \tightlist
  \item
    UCLA website: \url{http://www.ats.ucla.edu/stat/Stata/}
  \item
    Stata website: \url{http://www.stata.com/help.cgi?contents}
  \item
    Email list: \url{http://www.stata.com/statalist/}
  \end{itemize}
\end{itemize}

\end{document}
